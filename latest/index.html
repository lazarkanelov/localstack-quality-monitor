<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LocalStack Quality Report - 2026-01-11</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/@alpinejs/collapse@3.x.x/dist/cdn.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/alpinejs@3.x.x/dist/cdn.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-hcl.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-bash.min.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        dark: {
                            50: '#f8fafc',
                            100: '#f1f5f9',
                            200: '#e2e8f0',
                            300: '#cbd5e1',
                            400: '#94a3b8',
                            500: '#64748b',
                            600: '#475569',
                            700: '#334155',
                            800: '#1e293b',
                            900: '#0f172a',
                            950: '#020617'
                        }
                    }
                }
            }
        }
    </script>
    <style>
        [x-cloak] { display: none !important; }
        pre[class*="language-"] { margin: 0 !important; }
        code[class*="language-"] { font-size: 0.75rem !important; }
        .tab-content { display: none !important; }
        .tab-content.active { display: block !important; }
    </style>
</head>
<body class="bg-dark-950 text-dark-100 min-h-screen" x-data="reportData()">

    

    <!-- Header -->
    <header class="bg-dark-900 border-b border-dark-700 sticky top-0 z-40">
        <div class="px-6 py-4">
            <div class="flex items-center justify-between">
                <div>
                    <h1 class="text-xl font-semibold text-white">LocalStack Quality Report</h1>
                    <p class="text-sm text-dark-400 mt-0.5">
                        Run <span class="font-mono text-xs bg-dark-800 px-1.5 py-0.5 rounded text-dark-300">736ce5ac-820</span>
                        · 2026-01-11
                        · LocalStack <span class="text-blue-400">latest</span>
                        · Duration <span class="text-green-400">0s</span>
                    </p>
                </div>
                <div class="flex items-center space-x-3">
                    <button onclick="window.print()" class="px-4 py-2 bg-dark-800 border border-dark-600 rounded-lg text-sm font-medium hover:bg-dark-700 flex items-center space-x-2 text-dark-200">
                        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16v1a3 3 0 003 3h10a3 3 0 003-3v-1m-4-4l-4 4m0 0l-4-4m4 4V4"/></svg>
                        <span>Export</span>
                    </button>
                </div>
            </div>

            <!-- Metrics Bar -->
            <div class="flex items-center space-x-8 mt-4 pt-4 border-t border-dark-800">
                <div class="flex items-center space-x-2">
                    <div class="w-10 h-10 rounded-lg bg-dark-800 flex items-center justify-center">
                        <span class="text-lg font-bold text-white">7</span>
                    </div>
                    <div class="text-sm">
                        <div class="font-medium text-dark-200">Total</div>
                        <div class="text-dark-500 text-xs">Architectures</div>
                    </div>
                </div>
                <div class="flex items-center space-x-2">
                    <div class="w-10 h-10 rounded-lg bg-green-900/30 border border-green-800/50 flex items-center justify-center">
                        <span class="text-lg font-bold text-green-400">1</span>
                    </div>
                    <div class="text-sm">
                        <div class="font-medium text-green-400">Passed</div>
                        <div class="text-dark-500 text-xs">14% rate</div>
                    </div>
                </div>
                <div class="flex items-center space-x-2">
                    <div class="w-10 h-10 rounded-lg bg-red-900/30 border border-red-800/50 flex items-center justify-center">
                        <span class="text-lg font-bold text-red-400">6</span>
                    </div>
                    <div class="text-sm">
                        <div class="font-medium text-red-400">Failed</div>
                        <div class="text-dark-500 text-xs">86% rate</div>
                    </div>
                </div>
                
                <div class="flex-1"></div>
                <!-- Progress Bar -->
                <div class="w-48">
                    <div class="flex justify-between text-xs text-dark-400 mb-1">
                        <span>Pass Rate</span>
                        <span class="font-medium text-dark-200">14%</span>
                    </div>
                    <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                        <div class="h-full bg-gradient-to-r from-green-500 to-green-400 rounded-full" style="width: 14.285714285714285%"></div>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Charts Section -->
    <div class="px-6 py-6">
        <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
            <!-- Pass Rate Trend Chart -->
            <div class="bg-dark-900 border border-dark-700 rounded-xl p-5">
                <h3 class="text-sm font-medium text-dark-200 mb-4">Pass Rate Trend</h3>
                <div style="height: 200px;">
                    <canvas id="trendChart"></canvas>
                </div>
            </div>

            <!-- Status Distribution -->
            <div class="bg-dark-900 border border-dark-700 rounded-xl p-5">
                <h3 class="text-sm font-medium text-dark-200 mb-4">Status Distribution</h3>
                <div class="flex items-center justify-center" style="height: 200px;">
                    <canvas id="statusChart"></canvas>
                </div>
            </div>
        </div>
    </div>

    <!-- Filters & Search -->
    <div class="px-6 py-4 bg-dark-900 border-y border-dark-700">
        <div class="flex items-center space-x-4">
            <div class="relative flex-1 max-w-md">
                <svg class="absolute left-3 top-1/2 transform -translate-y-1/2 w-4 h-4 text-dark-500" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"/></svg>
                <input type="text" placeholder="Search architectures..." x-model="searchQuery"
                       class="w-full pl-10 pr-4 py-2 bg-dark-800 border border-dark-600 rounded-lg text-sm text-dark-100 placeholder-dark-500 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent">
            </div>
            <div class="flex items-center space-x-2">
                <span class="text-sm text-dark-400">Status:</span>
                <select x-model="statusFilter" class="bg-dark-800 border border-dark-600 rounded-lg px-3 py-2 text-sm text-dark-200 focus:outline-none focus:ring-2 focus:ring-blue-500">
                    <option value="all">All</option>
                    <option value="passed">Passed</option>
                    <option value="failed">Failed</option>
                </select>
            </div>
            <div class="flex items-center space-x-2">
                <span class="text-sm text-dark-400">Sort:</span>
                <select x-model="sortBy" class="bg-dark-800 border border-dark-600 rounded-lg px-3 py-2 text-sm text-dark-200 focus:outline-none focus:ring-2 focus:ring-blue-500">
                    <option value="status">Status</option>
                    <option value="name">Name</option>
                    <option value="duration">Duration</option>
                </select>
            </div>
        </div>
    </div>

    <!-- Data Table -->
    <div class="px-6 py-4">
        <div class="bg-dark-900 rounded-xl border border-dark-700 overflow-hidden">
            <table class="w-full">
                <thead class="bg-dark-800 border-b border-dark-700">
                    <tr>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase tracking-wider">Status</th>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase tracking-wider">Architecture</th>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase tracking-wider">Services</th>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase tracking-wider">Tests</th>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase tracking-wider">Duration</th>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase tracking-wider">Actions</th>
                    </tr>
                </thead>
                <tbody class="divide-y divide-dark-700">
                    <template x-for="arch in filteredArchitectures" :key="arch.hash">
                        <tr @click="openDrawer(arch)" class="hover:bg-dark-800/50 cursor-pointer transition-colors">
                            <td class="px-4 py-4">
                                <template x-if="arch.status === 'PASSED'">
                                    <span class="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-green-900/40 text-green-400 border border-green-800/50">
                                        <svg class="w-3 h-3 mr-1" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clip-rule="evenodd"/></svg>
                                        Passed
                                    </span>
                                </template>
                                <template x-if="arch.status === 'FAILED'">
                                    <span class="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-red-900/40 text-red-400 border border-red-800/50">
                                        <svg class="w-3 h-3 mr-1" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"/></svg>
                                        Failed
                                    </span>
                                </template>
                                <template x-if="arch.status === 'TIMEOUT'">
                                    <span class="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-purple-900/40 text-purple-400 border border-purple-800/50">
                                        <svg class="w-3 h-3 mr-1" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm1-12a1 1 0 10-2 0v4a1 1 0 00.293.707l2.828 2.829a1 1 0 101.415-1.415L11 9.586V6z" clip-rule="evenodd"/></svg>
                                        Timeout
                                    </span>
                                </template>
                                <template x-if="arch.status === 'ERROR'">
                                    <span class="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-gray-700/40 text-gray-400 border border-gray-600/50">
                                        <svg class="w-3 h-3 mr-1" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7 4a1 1 0 11-2 0 1 1 0 012 0zm-1-9a1 1 0 00-1 1v4a1 1 0 102 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/></svg>
                                        Error
                                    </span>
                                </template>
                                <template x-if="arch.status === 'PARTIAL'">
                                    <span class="inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium bg-yellow-900/40 text-yellow-400 border border-yellow-800/50">
                                        <svg class="w-3 h-3 mr-1" fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M8.257 3.099c.765-1.36 2.722-1.36 3.486 0l5.58 9.92c.75 1.334-.213 2.98-1.742 2.98H4.42c-1.53 0-2.493-1.646-1.743-2.98l5.58-9.92zM11 13a1 1 0 11-2 0 1 1 0 012 0zm-1-8a1 1 0 00-1 1v3a1 1 0 002 0V6a1 1 0 00-1-1z" clip-rule="evenodd"/></svg>
                                        Partial
                                    </span>
                                </template>
                            </td>
                            <td class="px-4 py-4">
                                <div class="text-sm font-medium text-dark-100 truncate max-w-xs" x-text="arch.name"></div>
                                <div class="text-xs text-dark-500 font-mono" x-text="arch.hash.slice(0,12)"></div>
                            </td>
                            <td class="px-4 py-4">
                                <div class="flex flex-wrap gap-1">
                                    <template x-for="svc in arch.services.slice(0,3)" :key="svc">
                                        <span class="px-2 py-0.5 bg-blue-900/30 text-blue-400 border border-blue-800/50 rounded text-xs" x-text="svc"></span>
                                    </template>
                                    <span x-show="arch.services.length > 3" class="text-xs text-dark-500" x-text="'+' + (arch.services.length - 3)"></span>
                                </div>
                            </td>
                            <td class="px-4 py-4">
                                <div class="flex items-center space-x-2 text-sm">
                                    <span class="text-green-400 font-medium" x-text="arch.pytest_passed"></span>
                                    <span class="text-dark-600">/</span>
                                    <span class="text-red-400 font-medium" x-text="arch.pytest_failed"></span>
                                </div>
                            </td>
                            <td class="px-4 py-4 text-sm text-dark-400" x-text="arch.duration.toFixed(1) + 's'"></td>
                            <td class="px-4 py-4">
                                <div class="flex items-center space-x-3">
                                    <a x-show="arch.arch_artifact_url" :href="arch.arch_artifact_url" target="_blank" @click.stop class="text-purple-400 hover:text-purple-300 transition-colors" title="View Terraform">
                                        <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M1 0l4.2 2.4v4.8L1 4.8zm6.6 3.8l4.2 2.4v4.8l-4.2-2.4zm-6.6 7l4.2 2.4v4.8L1 15.6zm6.6 3.8l4.2 2.4v4.8l-4.2-2.4z"/></svg>
                                    </a>
                                    <a x-show="arch.app_artifact_url" :href="arch.app_artifact_url" target="_blank" @click.stop class="text-green-400 hover:text-green-300 transition-colors" title="View App">
                                        <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4"/></svg>
                                    </a>
                                </div>
                            </td>
                        </tr>
                    </template>
                </tbody>
            </table>
        </div>
    </div>

    <!-- Service Coverage -->
    <div class="px-6 py-6">
        <h2 class="text-lg font-semibold text-white mb-4">Service Coverage</h2>
        <div class="grid grid-cols-2 md:grid-cols-5 gap-4">
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">s3</span>
                    <span class="font-bold text-lg text-red-400">25%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 25.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>1 passed</span>
                    <span>3 failed</span>
                </div>
            </div>
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">ec2</span>
                    <span class="font-bold text-lg text-red-400">0%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 0.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>0 passed</span>
                    <span>1 failed</span>
                </div>
            </div>
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">iam</span>
                    <span class="font-bold text-lg text-red-400">0%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 0.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>0 passed</span>
                    <span>5 failed</span>
                </div>
            </div>
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">lambda</span>
                    <span class="font-bold text-lg text-red-400">0%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 0.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>0 passed</span>
                    <span>5 failed</span>
                </div>
            </div>
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">cloudwatch</span>
                    <span class="font-bold text-lg text-red-400">0%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 0.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>0 passed</span>
                    <span>3 failed</span>
                </div>
            </div>
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">dynamodb</span>
                    <span class="font-bold text-lg text-red-400">0%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 0.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>0 passed</span>
                    <span>2 failed</span>
                </div>
            </div>
            
            <div class="bg-dark-900 rounded-xl border border-dark-700 p-4">
                <div class="flex items-center justify-between mb-3">
                    <span class="font-medium text-dark-200">apigateway</span>
                    <span class="font-bold text-lg text-red-400">0%</span>
                </div>
                <div class="h-2 bg-dark-700 rounded-full overflow-hidden">
                    <div class="h-full rounded-full transition-all duration-500 bg-gradient-to-r from-red-500 to-red-400" style="width: 0.0%"></div>
                </div>
                <div class="flex justify-between mt-2 text-xs text-dark-500">
                    <span>0 passed</span>
                    <span>2 failed</span>
                </div>
            </div>
            
        </div>
    </div>

    <!-- Run History -->
    
    <div class="px-6 py-6 pb-12">
        <h2 class="text-lg font-semibold text-white mb-4">Run History</h2>
        <div class="bg-dark-900 rounded-xl border border-dark-700 overflow-hidden">
            <table class="w-full">
                <thead class="bg-dark-800 border-b border-dark-700">
                    <tr>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase">Run ID</th>
                        <th class="px-4 py-3 text-left text-xs font-medium text-dark-400 uppercase">Date</th>
                        <th class="px-4 py-3 text-center text-xs font-medium text-dark-400 uppercase">Total</th>
                        <th class="px-4 py-3 text-center text-xs font-medium text-dark-400 uppercase">Passed</th>
                        <th class="px-4 py-3 text-right text-xs font-medium text-dark-400 uppercase">Pass Rate</th>
                    </tr>
                </thead>
                <tbody class="divide-y divide-dark-700">
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">85b6cfea</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-11</td>
                        <td class="px-4 py-3 text-center text-white font-medium">7</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-red-400">14%</span>
                        </td>
                    </tr>
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">96fc99cc</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-11</td>
                        <td class="px-4 py-3 text-center text-white font-medium">7</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-red-400">14%</span>
                        </td>
                    </tr>
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">cdcdbff8</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-10</td>
                        <td class="px-4 py-3 text-center text-white font-medium">1</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-green-400">100%</span>
                        </td>
                    </tr>
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">ed725da5</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-10</td>
                        <td class="px-4 py-3 text-center text-white font-medium">2</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-yellow-400">50%</span>
                        </td>
                    </tr>
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">e6686639</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-11</td>
                        <td class="px-4 py-3 text-center text-white font-medium">2</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-yellow-400">50%</span>
                        </td>
                    </tr>
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">da43d0a5</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-11</td>
                        <td class="px-4 py-3 text-center text-white font-medium">6</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-red-400">17%</span>
                        </td>
                    </tr>
                    
                    <tr class=" hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">b5aa050f</code>
                            
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-10</td>
                        <td class="px-4 py-3 text-center text-white font-medium">1</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-green-400">100%</span>
                        </td>
                    </tr>
                    
                    <tr class="bg-blue-900/10 hover:bg-dark-800/50 transition-colors">
                        <td class="px-4 py-3">
                            <code class="text-sm text-dark-300">736ce5ac</code>
                            <span class="ml-2 text-xs text-blue-400">(current)</span>
                        </td>
                        <td class="px-4 py-3 text-dark-300 text-sm">2026-01-11</td>
                        <td class="px-4 py-3 text-center text-white font-medium">7</td>
                        <td class="px-4 py-3 text-center text-green-400 font-medium">-</td>
                        <td class="px-4 py-3 text-right">
                            <span class="font-semibold text-red-400">14%</span>
                        </td>
                    </tr>
                    
                </tbody>
            </table>
        </div>
    </div>
    

    <!-- Footer -->
    <footer class="border-t border-dark-800 mt-8">
        <div class="px-6 py-6 text-center text-dark-500 text-sm">
            <p>Generated by LocalStack Quality Monitor · 2026-01-11</p>
            <p class="mt-1">
                <a href="https://localstack.cloud" target="_blank" class="text-blue-400 hover:text-blue-300">LocalStack</a>
                ·
                <a href="https://github.com/localstack/localstack" target="_blank" class="text-blue-400 hover:text-blue-300">GitHub</a>
            </p>
        </div>
    </footer>

    <!-- Slide-in Drawer -->
    <div x-show="drawerOpen" x-cloak class="fixed inset-0 z-50 overflow-hidden" @keydown.escape.window="drawerOpen = false">
        <!-- Backdrop -->
        <div x-show="drawerOpen" x-transition:enter="transition-opacity ease-out duration-300" x-transition:enter-start="opacity-0" x-transition:enter-end="opacity-100"
             x-transition:leave="transition-opacity ease-in duration-200" x-transition:leave-start="opacity-100" x-transition:leave-end="opacity-0"
             class="absolute inset-0 bg-black/60 backdrop-blur-sm" @click="drawerOpen = false"></div>

        <!-- Drawer Panel -->
        <div class="absolute inset-y-0 right-0 max-w-2xl w-full flex">
            <div x-show="drawerOpen" x-transition:enter="transform transition ease-out duration-300" x-transition:enter-start="translate-x-full" x-transition:enter-end="translate-x-0"
                 x-transition:leave="transform transition ease-in duration-200" x-transition:leave-start="translate-x-0" x-transition:leave-end="translate-x-full"
                 class="w-full bg-dark-900 border-l border-dark-700 shadow-2xl overflow-y-auto">

                <template x-if="selectedArch">
                    <div>
                        <!-- Drawer Header -->
                        <div class="sticky top-0 bg-dark-900 border-b border-dark-700 px-6 py-4 flex items-center justify-between z-10">
                            <div class="min-w-0 flex-1">
                                <div class="flex items-center space-x-2">
                                    <template x-if="selectedArch.status === 'PASSED'">
                                        <span class="w-3 h-3 rounded-full bg-green-500 flex-shrink-0"></span>
                                    </template>
                                    <template x-if="selectedArch.status === 'FAILED'">
                                        <span class="w-3 h-3 rounded-full bg-red-500 flex-shrink-0"></span>
                                    </template>
                                    <template x-if="selectedArch.status === 'TIMEOUT'">
                                        <span class="w-3 h-3 rounded-full bg-purple-500 flex-shrink-0"></span>
                                    </template>
                                    <template x-if="selectedArch.status === 'ERROR'">
                                        <span class="w-3 h-3 rounded-full bg-gray-500 flex-shrink-0"></span>
                                    </template>
                                    <template x-if="selectedArch.status === 'PARTIAL'">
                                        <span class="w-3 h-3 rounded-full bg-yellow-500 flex-shrink-0"></span>
                                    </template>
                                    <h2 class="text-lg font-semibold text-white truncate" x-text="selectedArch.name"></h2>
                                </div>
                                <p class="text-sm text-dark-400 font-mono truncate" x-text="selectedArch.hash"></p>
                            </div>
                            <button @click="drawerOpen = false" class="p-2 hover:bg-dark-800 rounded-lg transition-colors flex-shrink-0 ml-4">
                                <svg class="w-5 h-5 text-dark-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12"/></svg>
                            </button>
                        </div>

                        <!-- Drawer Content -->
                        <div class="px-6 py-4 space-y-6">
                            <!-- Quick Actions -->
                            <div class="flex space-x-3" x-show="selectedArch.arch_artifact_url || selectedArch.app_artifact_url">
                                <a x-show="selectedArch.arch_artifact_url" :href="selectedArch.arch_artifact_url" target="_blank" class="flex-1 px-4 py-3 bg-purple-900/30 border border-purple-800/50 text-purple-400 rounded-lg text-sm font-medium text-center hover:bg-purple-900/50 transition-colors flex items-center justify-center space-x-2">
                                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                                    <span>View Terraform Repo</span>
                                </a>
                                <a x-show="selectedArch.app_artifact_url" :href="selectedArch.app_artifact_url" target="_blank" class="flex-1 px-4 py-3 bg-green-900/30 border border-green-800/50 text-green-400 rounded-lg text-sm font-medium text-center hover:bg-green-900/50 transition-colors flex items-center justify-center space-x-2">
                                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                                    <span>View App Repo</span>
                                </a>
                            </div>

                            <!-- Services -->
                            <div x-show="selectedArch.services && selectedArch.services.length > 0">
                                <h3 class="text-sm font-medium text-dark-300 mb-3">Services</h3>
                                <div class="flex flex-wrap gap-2">
                                    <template x-for="svc in selectedArch.services" :key="svc">
                                        <span class="px-3 py-1.5 bg-blue-900/30 text-blue-400 border border-blue-800/50 rounded-lg text-sm" x-text="svc"></span>
                                    </template>
                                </div>
                            </div>

                            <!-- Failure Analysis -->
                            <template x-if="selectedArch.failure_analysis && selectedArch.failure_analysis.error_message">
                                <div class="bg-red-950/30 border border-red-900/50 rounded-xl p-4">
                                    <h3 class="text-sm font-medium text-red-400 mb-2 flex items-center">
                                        <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-3L13.732 4c-.77-1.333-2.694-1.333-3.464 0L3.34 16c-.77 1.333.192 3 1.732 3z"/></svg>
                                        Failure Analysis
                                    </h3>
                                    <p class="text-sm text-red-300 font-mono bg-dark-950/50 p-3 rounded-lg break-words" x-text="selectedArch.failure_analysis.error_message"></p>
                                    <div class="flex flex-wrap gap-2 mt-3">
                                        <span x-show="selectedArch.failure_analysis.affected_service" class="px-2 py-1 bg-purple-900/30 text-purple-400 border border-purple-800/50 rounded text-xs" x-text="selectedArch.failure_analysis.affected_service"></span>
                                        <span x-show="selectedArch.failure_analysis.aws_error_code" class="px-2 py-1 bg-red-900/30 text-red-400 border border-red-800/50 rounded text-xs font-mono" x-text="selectedArch.failure_analysis.aws_error_code"></span>
                                    </div>
                                </div>
                            </template>

                            <!-- Steps to Reproduce (for failed architectures) -->
                            <template x-if="selectedArch.status !== 'PASSED'">
                                <div class="bg-dark-800 rounded-xl p-4 border border-dark-700">
                                    <h3 class="text-sm font-medium text-dark-200 mb-3 flex items-center">
                                        <svg class="w-5 h-5 mr-2 text-blue-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5H7a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2V7a2 2 0 00-2-2h-2M9 5a2 2 0 002 2h2a2 2 0 002-2M9 5a2 2 0 012-2h2a2 2 0 012 2m-3 7h3m-3 4h3m-6-4h.01M9 16h.01"/></svg>
                                        Steps to Reproduce
                                    </h3>
                                    <ol class="text-sm text-dark-300 space-y-2 list-decimal list-inside">
                                        <li>Clone the architecture repository:
                                            <template x-if="selectedArch.arch_artifact_url">
                                                <pre class="mt-1 bg-dark-950 text-dark-300 p-2 rounded text-xs overflow-x-auto"><code x-text="'git clone ' + selectedArch.arch_artifact_url.replace('/tree/main/', '.git\ncd ') + '/' + selectedArch.hash"></code></pre>
                                            </template>
                                            <template x-if="!selectedArch.arch_artifact_url && selectedArch.source_url">
                                                <pre class="mt-1 bg-dark-950 text-dark-300 p-2 rounded text-xs overflow-x-auto"><code x-text="'# Source: ' + selectedArch.source_url"></code></pre>
                                            </template>
                                        </li>
                                        <li>Start LocalStack:
                                            <pre class="mt-1 bg-dark-950 text-dark-300 p-2 rounded text-xs overflow-x-auto"><code>localstack start -d</code></pre>
                                        </li>
                                        <li>Initialize and apply Terraform:
                                            <pre class="mt-1 bg-dark-950 text-dark-300 p-2 rounded text-xs overflow-x-auto"><code>tflocal init
tflocal apply -auto-approve</code></pre>
                                        </li>
                                        <template x-if="selectedArch.app_artifact_url">
                                            <li>Run the test application:
                                                <pre class="mt-1 bg-dark-950 text-dark-300 p-2 rounded text-xs overflow-x-auto"><code>cd ../apps/<span x-text="selectedArch.hash"></span>
pip install -r requirements.txt
pytest -v</code></pre>
                                            </li>
                                        </template>
                                    </ol>
                                </div>
                            </template>

                            <!-- Test Results -->
                            <div class="bg-dark-800 rounded-xl p-4">
                                <h3 class="text-sm font-medium text-dark-300 mb-3">Test Results</h3>
                                <div class="grid grid-cols-4 gap-3 text-center">
                                    <div class="bg-dark-900 rounded-lg p-3 border border-dark-700">
                                        <div class="text-2xl font-bold text-white" x-text="selectedArch.pytest_passed + selectedArch.pytest_failed"></div>
                                        <div class="text-xs text-dark-500">Total</div>
                                    </div>
                                    <div class="bg-green-900/20 rounded-lg p-3 border border-green-800/30">
                                        <div class="text-2xl font-bold text-green-400" x-text="selectedArch.pytest_passed"></div>
                                        <div class="text-xs text-dark-500">Passed</div>
                                    </div>
                                    <div class="bg-red-900/20 rounded-lg p-3 border border-red-800/30">
                                        <div class="text-2xl font-bold text-red-400" x-text="selectedArch.pytest_failed"></div>
                                        <div class="text-xs text-dark-500">Failed</div>
                                    </div>
                                    <div class="bg-dark-900 rounded-lg p-3 border border-dark-700">
                                        <div class="text-2xl font-bold" :class="selectedArch.pytest_failed === 0 ? 'text-green-400' : 'text-red-400'" x-text="selectedArch.pytest_passed + selectedArch.pytest_failed > 0 ? Math.round(selectedArch.pytest_passed / (selectedArch.pytest_passed + selectedArch.pytest_failed) * 100) + '%' : 'N/A'"></div>
                                        <div class="text-xs text-dark-500">Pass Rate</div>
                                    </div>
                                </div>
                            </div>

                            <!-- Pytest Output -->
                            <div x-data="{ open: false }" x-show="selectedArch.pytest_output && selectedArch.pytest_output.length > 0">
                                <button @click="open = !open" class="w-full flex items-center justify-between text-left py-2">
                                    <h3 class="text-sm font-medium text-dark-300 flex items-center">
                                        <svg class="w-5 h-5 mr-2 text-yellow-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12l2 2 4-4m6 2a9 9 0 11-18 0 9 9 0 0118 0z"/></svg>
                                        Pytest Output
                                    </h3>
                                    <svg :class="open ? 'rotate-180' : ''" class="w-5 h-5 text-dark-500 transition-transform" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
                                </button>
                                <div x-show="open" x-collapse class="mt-3">
                                    <pre class="bg-dark-950 text-dark-300 p-3 rounded-lg text-xs overflow-x-auto border border-dark-700 whitespace-pre-wrap break-words max-h-96 overflow-y-auto"><code x-text="selectedArch.pytest_output"></code></pre>
                                </div>
                            </div>

                            <!-- Terraform Files -->
                            <div x-data="{ open: false }" x-show="selectedArch.terraform_files && Object.keys(selectedArch.terraform_files).length > 0">
                                <button @click="open = !open" class="w-full flex items-center justify-between text-left py-2">
                                    <h3 class="text-sm font-medium text-dark-300 flex items-center">
                                        <svg class="w-5 h-5 mr-2 text-purple-400" fill="currentColor" viewBox="0 0 24 24"><path d="M1 0l4.2 2.4v4.8L1 4.8zm6.6 3.8l4.2 2.4v4.8l-4.2-2.4zm-6.6 7l4.2 2.4v4.8L1 15.6zm6.6 3.8l4.2 2.4v4.8l-4.2-2.4z"/></svg>
                                        Terraform Files
                                        <span class="ml-2 text-dark-500 font-normal" x-text="'(' + Object.keys(selectedArch.terraform_files).length + ')'"></span>
                                    </h3>
                                    <svg :class="open ? 'rotate-180' : ''" class="w-5 h-5 text-dark-500 transition-transform" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
                                </button>
                                <div x-show="open" x-collapse class="mt-3 space-y-3">
                                    <template x-for="(content, filename) in selectedArch.terraform_files" :key="filename">
                                        <div class="bg-dark-950 rounded-lg overflow-hidden border border-dark-700">
                                            <div class="px-3 py-2 bg-dark-800 text-dark-300 text-xs font-mono border-b border-dark-700" x-text="filename"></div>
                                            <pre class="p-3 text-sm overflow-x-auto max-h-96 overflow-y-auto"><code class="language-hcl" x-text="content"></code></pre>
                                        </div>
                                    </template>
                                </div>
                            </div>

                            <!-- App Files -->
                            <div x-data="{ open: false }" x-show="selectedArch.app_files && Object.keys(selectedArch.app_files).length > 0">
                                <button @click="open = !open" class="w-full flex items-center justify-between text-left py-2">
                                    <h3 class="text-sm font-medium text-dark-300 flex items-center">
                                        <svg class="w-5 h-5 mr-2 text-green-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4"/></svg>
                                        Test Application
                                        <span class="ml-2 text-dark-500 font-normal" x-text="'(' + Object.keys(selectedArch.app_files).length + ')'"></span>
                                    </h3>
                                    <svg :class="open ? 'rotate-180' : ''" class="w-5 h-5 text-dark-500 transition-transform" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
                                </button>
                                <div x-show="open" x-collapse class="mt-3 space-y-3">
                                    <template x-for="(content, filename) in selectedArch.app_files" :key="filename">
                                        <div class="bg-dark-950 rounded-lg overflow-hidden border border-dark-700">
                                            <div class="px-3 py-2 bg-dark-800 text-dark-300 text-xs font-mono border-b border-dark-700" x-text="filename"></div>
                                            <pre class="p-3 text-sm overflow-x-auto max-h-96 overflow-y-auto"><code class="language-python" x-text="content"></code></pre>
                                        </div>
                                    </template>
                                </div>
                            </div>

                            <!-- Logs -->
                            <div x-data="{ open: false }" x-show="selectedArch.terraform_output || selectedArch.logs">
                                <button @click="open = !open" class="w-full flex items-center justify-between text-left py-2">
                                    <h3 class="text-sm font-medium text-dark-300 flex items-center">
                                        <svg class="w-5 h-5 mr-2 text-dark-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 10h16M4 14h16M4 18h16"/></svg>
                                        Logs &amp; Output
                                    </h3>
                                    <svg :class="open ? 'rotate-180' : ''" class="w-5 h-5 text-dark-500 transition-transform" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>
                                </button>
                                <div x-show="open" x-collapse class="mt-3 space-y-3">
                                    <div x-show="selectedArch.terraform_output">
                                        <div class="text-xs font-medium text-dark-500 mb-1">Terraform Output</div>
                                        <pre class="bg-dark-950 text-dark-300 p-3 rounded-lg text-xs overflow-x-auto max-h-96 overflow-y-auto border border-dark-700 whitespace-pre-wrap break-words"><code x-text="selectedArch.terraform_output"></code></pre>
                                    </div>
                                    <div x-show="selectedArch.logs">
                                        <div class="text-xs font-medium text-dark-500 mb-1">Container Logs</div>
                                        <pre class="bg-dark-950 text-dark-300 p-3 rounded-lg text-xs overflow-x-auto max-h-96 overflow-y-auto border border-dark-700 whitespace-pre-wrap break-words"><code x-text="selectedArch.logs"></code></pre>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </template>
            </div>
        </div>
    </div>

    <script>
        function reportData() {
            return {
                searchQuery: '',
                statusFilter: 'all',
                sortBy: 'status',
                drawerOpen: false,
                selectedArch: null,
                architectures: [{"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/5f63fc2a95796608", "app_files": {"app.py": "import boto3\nimport os\nimport time\nimport logging\nfrom typing import Dict, List, Optional, Tuple, Any\nfrom dataclasses import dataclass\nfrom botocore.exceptions import ClientError\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass NetworkResource:\n    \"\"\"Represents a network resource with its attributes.\"\"\"\n    id: str\n    name: str\n    cidr: Optional[str] = None\n    availability_zone: Optional[str] = None\n    state: Optional[str] = None\n    tags: Optional[Dict[str, str]] = None\n\n\n@dataclass\nclass InstanceDeployment:\n    \"\"\"Represents an EC2 instance deployment configuration.\"\"\"\n    name: str\n    subnet_id: str\n    security_group_ids: List[str]\n    instance_type: str = \"t3.micro\"\n    ami_id: str = \"ami-0c02fb55956c7d316\"\n    user_data: Optional[str] = None\n\n\nclass NetworkInfrastructureManager:\n    \"\"\"Manages network infrastructure operations and EC2 deployments.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the network infrastructure manager.\"\"\"\n        self.aws_config = {\n            \"endpoint_url\": os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\"),\n            \"region_name\": \"us-east-1\",\n            \"aws_access_key_id\": \"test\",\n            \"aws_secret_access_key\": \"test\"\n        }\n        self.ec2_client = boto3.client(\"ec2\", **self.aws_config)\n        self.ec2_resource = boto3.resource(\"ec2\", **self.aws_config)\n        \n    def discover_vpc_infrastructure(self, vpc_name: str) -\u003e Dict[str, Any]:\n        \"\"\"Discover and catalog VPC infrastructure components.\n        \n        Args:\n            vpc_name: Name of the VPC to discover\n            \n        Returns:\n            Dictionary containing VPC infrastructure details\n        \"\"\"\n        try:\n            # Find VPC by name\n            vpcs = self.ec2_client.describe_vpcs(\n                Filters=[{\"Name\": \"tag:Name\", \"Values\": [vpc_name]}]\n            )\n            \n            if not vpcs[\"Vpcs\"]:\n                raise ValueError(f\"VPC with name \u0027{vpc_name}\u0027 not found\")\n            \n            vpc = vpcs[\"Vpcs\"][0]\n            vpc_id = vpc[\"VpcId\"]\n            \n            logger.info(f\"Discovered VPC: {vpc_id} ({vpc_name})\")\n            \n            # Discover subnets\n            subnets_response = self.ec2_client.describe_subnets(\n                Filters=[{\"Name\": \"vpc-id\", \"Values\": [vpc_id]}]\n            )\n            \n            infrastructure = {\n                \"vpc\": NetworkResource(\n                    id=vpc_id,\n                    name=vpc_name,\n                    cidr=vpc[\"CidrBlock\"],\n                    state=vpc[\"State\"],\n                    tags=self._extract_tags(vpc.get(\"Tags\", []))\n                ),\n                \"subnets\": {\n                    \"public\": [],\n                    \"private\": []\n                },\n                \"internet_gateway\": None,\n                \"nat_gateways\": [],\n                \"route_tables\": []\n            }\n            \n            # Categorize subnets\n            for subnet in subnets_response[\"Subnets\"]:\n                subnet_obj = NetworkResource(\n                    id=subnet[\"SubnetId\"],\n                    name=self._get_tag_value(subnet.get(\"Tags\", []), \"Name\"),\n                    cidr=subnet[\"CidrBlock\"],\n                    availability_zone=subnet[\"AvailabilityZone\"],\n                    state=subnet[\"State\"],\n                    tags=self._extract_tags(subnet.get(\"Tags\", []))\n                )\n                \n                # Determine if subnet is public or private based on route table\n                if subnet[\"MapPublicIpOnLaunch\"]:\n                    infrastructure[\"subnets\"][\"public\"].append(subnet_obj)\n                else:\n                    infrastructure[\"subnets\"][\"private\"].append(subnet_obj)\n            \n            # Discover Internet Gateway\n            igws = self.ec2_client.describe_internet_gateways(\n                Filters=[{\"Name\": \"attachment.vpc-id\", \"Values\": [vpc_id]}]\n            )\n            \n            if igws[\"InternetGateways\"]:\n                igw = igws[\"InternetGateways\"][0]\n                infrastructure[\"internet_gateway\"] = NetworkResource(\n                    id=igw[\"InternetGatewayId\"],\n                    name=self._get_tag_value(igw.get(\"Tags\", []), \"Name\"),\n                    tags=self._extract_tags(igw.get(\"Tags\", []))\n                )\n            \n            # Discover NAT Gateways\n            nat_gws = self.ec2_client.describe_nat_gateways(\n                Filters=[{\"Name\": \"vpc-id\", \"Values\": [vpc_id]}]\n            )\n            \n            for nat_gw in nat_gws[\"NatGateways\"]:\n                if nat_gw[\"State\"] != \"deleted\":\n                    infrastructure[\"nat_gateways\"].append(\n                        NetworkResource(\n                            id=nat_gw[\"NatGatewayId\"],\n                            name=self._get_tag_value(nat_gw.get(\"Tags\", []), \"Name\"),\n                            tags=self._extract_tags(nat_gw.get(\"Tags\", []))\n                        )\n                    )\n            \n            logger.info(f\"Infrastructure discovery complete: {len(infrastructure[\u0027subnets\u0027][\u0027public\u0027])} public subnets, {len(infrastructure[\u0027subnets\u0027][\u0027private\u0027])} private subnets\")\n            return infrastructure\n            \n        except ClientError as e:\n            logger.error(f\"AWS error during infrastructure discovery: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Error discovering infrastructure: {e}\")\n            raise\n    \n    def create_security_group(self, vpc_id: str, name: str, description: str, \n                            ingress_rules: List[Dict[str, Any]]) -\u003e str:\n        \"\"\"Create a security group with specified rules.\n        \n        Args:\n            vpc_id: VPC ID to create the security group in\n            name: Security group name\n            description: Security group description\n            ingress_rules: List of ingress rules\n            \n        Returns:\n            Security group ID\n        \"\"\"\n        try:\n            response = self.ec2_client.create_security_group(\n                GroupName=name,\n                Description=description,\n                VpcId=vpc_id,\n                TagSpecifications=[\n                    {\n                        \"ResourceType\": \"security-group\",\n                        \"Tags\": [\n                            {\"Key\": \"Name\", \"Value\": name}\n                        ]\n                    }\n                ]\n            )\n            \n            sg_id = response[\"GroupId\"]\n            logger.info(f\"Created security group: {sg_id} ({name})\")\n            \n            # Add ingress rules\n            if ingress_rules:\n                self.ec2_client.authorize_security_group_ingress(\n                    GroupId=sg_id,\n                    IpPermissions=ingress_rules\n                )\n                logger.info(f\"Added {len(ingress_rules)} ingress rules to {sg_id}\")\n            \n            return sg_id\n            \n        except ClientError as e:\n            if e.response[\"Error\"][\"Code\"] == \"InvalidGroup.Duplicate\":\n                logger.warning(f\"Security group {name} already exists\")\n                # Find existing security group\n                sgs = self.ec2_client.describe_security_groups(\n                    Filters=[\n                        {\"Name\": \"group-name\", \"Values\": [name]},\n                        {\"Name\": \"vpc-id\", \"Values\": [vpc_id]}\n                    ]\n                )\n                return sgs[\"SecurityGroups\"][0][\"GroupId\"]\n            logger.error(f\"Error creating security group: {e}\")\n            raise\n    \n    def deploy_multi_tier_application(self, infrastructure: Dict[str, Any], \n                                    app_config: Dict[str, Any]) -\u003e Dict[str, List[str]]:\n        \"\"\"Deploy a multi-tier application across the network infrastructure.\n        \n        Args:\n            infrastructure: Infrastructure details from discovery\n            app_config: Application deployment configuration\n            \n        Returns:\n            Dictionary mapping tier names to instance IDs\n        \"\"\"\n        deployments = {}\n        \n        try:\n            vpc_id = infrastructure[\"vpc\"].id\n            \n            # Create security groups for different tiers\n            security_groups = self._create_tier_security_groups(vpc_id)\n            \n            # Deploy web tier in public subnets\n            if \"web\" in app_config:\n                web_instances = self._deploy_tier(\n                    \"web\",\n                    infrastructure[\"subnets\"][\"public\"],\n                    security_groups[\"web\"],\n                    app_config[\"web\"]\n                )\n                deployments[\"web\"] = web_instances\n            \n            # Deploy app tier in private subnets (app type)\n            if \"app\" in app_config:\n                app_subnets = [\n                    subnet for subnet in infrastructure[\"subnets\"][\"private\"]\n                    if subnet.tags and subnet.tags.get(\"Tier\") == \"app\"\n                ]\n                app_instances = self._deploy_tier(\n                    \"app\",\n                    app_subnets,\n                    security_groups[\"app\"],\n                    app_config[\"app\"]\n                )\n                deployments[\"app\"] = app_instances\n            \n            # Deploy database tier in private subnets (db type)\n            if \"database\" in app_config:\n                db_subnets = [\n                    subnet for subnet in infrastructure[\"subnets\"][\"private\"]\n                    if subnet.tags and subnet.tags.get(\"Tier\") == \"database\"\n                ]\n                db_instances = self._deploy_tier(\n                    \"database\",\n                    db_subnets,\n                    security_groups[\"database\"],\n                    app_config[\"database\"]\n                )\n                deployments[\"database\"] = db_instances\n            \n            logger.info(f\"Multi-tier deployment complete: {sum(len(instances) for instances in deployments.values())} total instances\")\n            return deployments\n            \n        except Exception as e:\n            logger.error(f\"Error during multi-tier deployment: {e}\")\n            raise\n    \n    def validate_network_connectivity(self, infrastructure: Dict[str, Any]) -\u003e Dict[str, bool]:\n        \"\"\"Validate network connectivity between different tiers.\n        \n        Args:\n            infrastructure: Infrastructure details\n            \n        Returns:\n            Dictionary of connectivity test results\n        \"\"\"\n        results = {}\n        \n        try:\n            vpc_id = infrastructure[\"vpc\"].id\n            \n            # Test 1: VPC DNS resolution\n            results[\"vpc_dns_enabled\"] = self._check_vpc_dns_settings(vpc_id)\n            \n            # Test 2: Public subnet internet connectivity\n            results[\"public_internet_access\"] = self._validate_public_internet_access(\n                infrastructure[\"subnets\"][\"public\"]\n            )\n            \n            # Test 3: Private subnet NAT gateway connectivity\n            results[\"private_nat_access\"] = self._validate_private_nat_access(\n                infrastructure[\"subnets\"][\"private\"],\n                infrastructure[\"nat_gateways\"]\n            )\n            \n            # Test 4: Cross-AZ connectivity\n            results[\"cross_az_connectivity\"] = self._validate_cross_az_connectivity(\n                infrastructure[\"subnets\"]\n            )\n            \n            # Test 5: Security group isolation\n            results[\"security_isolation\"] = self._validate_security_isolation(vpc_id)\n            \n            logger.info(f\"Network connectivity validation complete: {sum(results.values())}/{len(results)} tests passed\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"Error during network validation: {e}\")\n            raise\n    \n    def cleanup_deployment(self, instance_ids: List[str]) -\u003e bool:\n        \"\"\"Clean up deployed instances and associated resources.\n        \n        Args:\n            instance_ids: List of instance IDs to terminate\n            \n        Returns:\n            True if cleanup successful\n        \"\"\"\n        try:\n            if instance_ids:\n                self.ec2_client.terminate_instances(InstanceIds=instance_ids)\n                logger.info(f\"Initiated termination of {len(instance_ids)} instances\")\n                \n                # Wait for instances to terminate\n                waiter = self.ec2_client.get_waiter(\u0027instance_terminated\u0027)\n                waiter.wait(InstanceIds=instance_ids, WaiterConfig={\u0027Delay\u0027: 5, \u0027MaxAttempts\u0027: 20})\n                logger.info(\"All instances terminated successfully\")\n            \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Error during cleanup: {e}\")\n            return False\n    \n    def _extract_tags(self, tag_list: List[Dict[str, str]]) -\u003e Dict[str, str]:\n        \"\"\"Extract tags from AWS tag list format.\"\"\"\n        return {tag[\"Key\"]: tag[\"Value\"] for tag in tag_list}\n    \n    def _get_tag_value(self, tag_list: List[Dict[str, str]], key: str) -\u003e Optional[str]:\n        \"\"\"Get specific tag value from AWS tag list.\"\"\"\n        for tag in tag_list:\n            if tag[\"Key\"] == key:\n                return tag[\"Value\"]\n        return None\n    \n    def _create_tier_security_groups(self, vpc_id: str) -\u003e Dict[str, str]:\n        \"\"\"Create security groups for different application tiers.\"\"\"\n        security_groups = {}\n        \n        # Web tier security group (HTTP/HTTPS from internet)\n        web_rules = [\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 80,\n                \"ToPort\": 80,\n                \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\", \"Description\": \"HTTP from internet\"}]\n            },\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 443,\n                \"ToPort\": 443,\n                \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\", \"Description\": \"HTTPS from internet\"}]\n            }\n        ]\n        \n        security_groups[\"web\"] = self.create_security_group(\n            vpc_id, \"web-tier-sg\", \"Security group for web tier\", web_rules\n        )\n        \n        # App tier security group (access from web tier)\n        app_rules = [\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 8080,\n                \"ToPort\": 8080,\n                \"UserIdGroupPairs\": [{\"GroupId\": security_groups[\"web\"], \"Description\": \"App port from web tier\"}]\n            }\n        ]\n        \n        security_groups[\"app\"] = self.create_security_group(\n            vpc_id, \"app-tier-sg\", \"Security group for app tier\", app_rules\n        )\n        \n        # Database tier security group (access from app tier)\n        db_rules = [\n            {\n                \"IpProtocol\": \"tcp\",\n                \"FromPort\": 3306,\n                \"ToPort\": 3306,\n                \"UserIdGroupPairs\": [{\"GroupId\": security_groups[\"app\"], \"Description\": \"MySQL from app tier\"}]\n            }\n        ]\n        \n        security_groups[\"database\"] = self.create_security_group(\n            vpc_id, \"db-tier-sg\", \"Security group for database tier\", db_rules\n        )\n        \n        return security_groups\n    \n    def _deploy_tier(self, tier_name: str, subnets: List[NetworkResource], \n                    security_group_id: str, config: Dict[str, Any]) -\u003e List[str]:\n        \"\"\"Deploy instances for a specific tier.\"\"\"\n        instance_ids = []\n        \n        instances_per_subnet = config.get(\"instances_per_subnet\", 1)\n        instance_type = config.get(\"instance_type\", \"t3.micro\")\n        ami_id = config.get(\"ami_id\", \"ami-0c02fb55956c7d316\")\n        \n        for subnet in subnets:\n            for i in range(instances_per_subnet):\n                try:\n                    response = self.ec2_client.run_instances(\n                        ImageId=ami_id,\n                        MinCount=1,\n                        MaxCount=1,\n                        InstanceType=instance_type,\n                        SubnetId=subnet.id,\n                        SecurityGroupIds=[security_group_id],\n                        TagSpecifications=[\n                            {\n                                \"ResourceType\": \"instance\",\n                                \"Tags\": [\n                                    {\"Key\": \"Name\", \"Value\": f\"{tier_name}-{subnet.availability_zone}-{i+1}\"},\n                                    {\"Key\": \"Tier\", \"Value\": tier_name},\n                                    {\"Key\": \"Environment\", \"Value\": \"test\"}\n                                ]\n                            }\n                        ]\n                    )\n                    \n                    instance_id = response[\"Instances\"][0][\"InstanceId\"]\n                    instance_ids.append(instance_id)\n                    logger.info(f\"Launched {tier_name} instance: {instance_id} in {subnet.id}\")\n                    \n                except ClientError as e:\n                    logger.error(f\"Error launching instance in {subnet.id}: {e}\")\n        \n        return instance_ids\n    \n    def _check_vpc_dns_settings(self, vpc_id: str) -\u003e bool:\n        \"\"\"Check VPC DNS settings.\"\"\"\n        try:\n            response = self.ec2_client.describe_vpcs(VpcIds=[vpc_id])\n            vpc = response[\"Vpcs\"][0]\n            return vpc[\"EnableDnsSupport\"] and vpc[\"EnableDnsHostnames\"]\n        except Exception:\n            return False\n    \n    def _validate_public_internet_access(self, public_subnets: List[NetworkResource]) -\u003e bool:\n        \"\"\"Validate public subnets have internet access via IGW.\"\"\"\n        for subnet in public_subnets:\n            if not subnet.id:\n                continue\n            \n            try:\n                # Check route tables for internet gateway route\n                route_tables = self.ec2_client.describe_route_tables(\n                    Filters=[\n                        {\"Name\": \"association.subnet-id\", \"Values\": [subnet.id]}\n                    ]\n                )\n                \n                for rt in route_tables[\"RouteTables\"]:\n                    for route in rt[\"Routes\"]:\n                        if (route.get(\"DestinationCidrBlock\") == \"0.0.0.0/0\" and \n                            \"GatewayId\" in route and route[\"GatewayId\"].startswith(\"igw-\")):\n                            return True\n                            \n            except Exception:\n                continue\n        \n        return False\n    \n    def _validate_private_nat_access(self, private_subnets: List[NetworkResource], \n                                   nat_gateways: List[NetworkResource]) -\u003e bool:\n        \"\"\"Validate private subnets have NAT gateway access.\"\"\"\n        return len(nat_gateways) \u003e 0 and len(private_subnets) \u003e 0\n    \n    def _validate_cross_az_connectivity(self, subnets: Dict[str, List[NetworkResource]]) -\u003e bool:\n        \"\"\"Validate cross-AZ connectivity.\"\"\"\n        all_azs = set()\n        for subnet_list in subnets.values():\n            for subnet in subnet_list:\n                if subnet.availability_zone:\n                    all_azs.add(subnet.availability_zone)\n        \n        # Should have subnets in multiple AZs for high availability\n        return len(all_azs) \u003e= 2\n    \n    def _validate_security_isolation(self, vpc_id: str) -\u003e bool:\n        \"\"\"Validate security group isolation between tiers.\"\"\"\n        try:\n            # Check if multiple security groups exist (indicating tier separation)\n            response = self.ec2_client.describe_security_groups(\n                Filters=[{\"Name\": \"vpc-id\", \"Values\": [vpc_id]}]\n            )\n            # Should have more than just the default security group\n            return len(response[\"SecurityGroups\"]) \u003e 1\n        except Exception:\n            return False\n\n\ndef create_network_manager() -\u003e NetworkInfrastructureManager:\n    \"\"\"Create a network infrastructure manager instance.\"\"\"\n    return NetworkInfrastructureManager()", "conftest.py": "import os\nimport boto3\nimport pytest\nfrom typing import Dict, Any\n\n\n@pytest.fixture(scope=\"session\")\ndef aws_config() -\u003e Dict[str, str]:\n    \"\"\"AWS configuration for LocalStack.\"\"\"\n    return {\n        \"endpoint_url\": os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\"),\n        \"region_name\": \"us-east-1\",\n        \"aws_access_key_id\": \"test\",\n        \"aws_secret_access_key\": \"test\"\n    }\n\n\n@pytest.fixture(scope=\"session\")\ndef ec2_client(aws_config):\n    \"\"\"EC2 client for LocalStack.\"\"\"\n    return boto3.client(\"ec2\", **aws_config)\n\n\n@pytest.fixture(scope=\"session\")\ndef vpc_name() -\u003e str:\n    \"\"\"VPC name from Terraform configuration.\"\"\"\n    return \"test-vpc\"\n\n\n@pytest.fixture(scope=\"session\")\ndef infrastructure_config() -\u003e Dict[str, Any]:\n    \"\"\"Infrastructure configuration that matches Terraform variables.\"\"\"\n    return {\n        \"vpc\": {\n            \"name\": \"test-vpc\",\n            \"cidr\": \"10.0.0.0/16\",\n            \"tags\": {\"Environment\": \"test\", \"Project\": \"networking\"}\n        },\n        \"subnets\": {\n            \"public\": {\n                \"web-subnet-1a\": {\n                    \"name\": \"web-subnet-1a\",\n                    \"cidr\": \"10.0.1.0/24\",\n                    \"az\": \"us-east-1a\",\n                    \"type\": \"web\",\n                    \"tags\": {\"Tier\": \"web\"}\n                },\n                \"web-subnet-1b\": {\n                    \"name\": \"web-subnet-1b\",\n                    \"cidr\": \"10.0.2.0/24\",\n                    \"az\": \"us-east-1b\",\n                    \"type\": \"web\",\n                    \"tags\": {\"Tier\": \"web\"}\n                }\n            },\n            \"private\": {\n                \"app-subnet-1a\": {\n                    \"name\": \"app-subnet-1a\",\n                    \"cidr\": \"10.0.11.0/24\",\n                    \"az\": \"us-east-1a\",\n                    \"type\": \"app\",\n                    \"nat_gateway\": \"AZ\",\n                    \"tags\": {\"Tier\": \"app\"}\n                },\n                \"app-subnet-1b\": {\n                    \"name\": \"app-subnet-1b\",\n                    \"cidr\": \"10.0.12.0/24\",\n                    \"az\": \"us-east-1b\",\n                    \"type\": \"app\",\n                    \"nat_gateway\": \"AZ\",\n                    \"tags\": {\"Tier\": \"app\"}\n                },\n                \"db-subnet-1a\": {\n                    \"name\": \"db-subnet-1a\",\n                    \"cidr\": \"10.0.21.0/24\",\n                    \"az\": \"us-east-1a\",\n                    \"type\": \"db\",\n                    \"nat_gateway\": \"SINGLE\",\n                    \"tags\": {\"Tier\": \"database\"}\n                },\n                \"db-subnet-1b\": {\n                    \"name\": \"db-subnet-1b\",\n                    \"cidr\": \"10.0.22.0/24\",\n                    \"az\": \"us-east-1b\",\n                    \"type\": \"db\",\n                    \"nat_gateway\": \"SINGLE\",\n                    \"tags\": {\"Tier\": \"database\"}\n                }\n            }\n        }\n    }\n\n\n@pytest.fixture(scope=\"session\")\ndef test_instances_config() -\u003e Dict[str, Any]:\n    \"\"\"Configuration for test EC2 instances.\"\"\"\n    return {\n        \"ami_id\": \"ami-0c02fb55956c7d316\",  # Amazon Linux 2 AMI\n        \"instance_type\": \"t3.micro\",\n        \"key_pair_name\": \"test-key-pair\"\n    }", "requirements.txt": "boto3\u003e=1.34.0\npytest\u003e=7.4.0\npytest-asyncio\u003e=0.21.0\nbotocore\u003e=1.34.0", "test_app.py": "import pytest\nimport time\nfrom typing import Dict, List, Any\nfrom app import NetworkInfrastructureManager, NetworkResource\n\n\nclass TestNetworkInfrastructure:\n    \"\"\"Test suite for network infrastructure management and deployments.\"\"\"\n    \n    def test_vpc_infrastructure_exists(self, ec2_client, infrastructure_config):\n        \"\"\"Test that VPC infrastructure components exist after Terraform apply.\"\"\"\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Check VPC exists\n        vpcs = ec2_client.describe_vpcs(\n            Filters=[{\"Name\": \"tag:Name\", \"Values\": [vpc_name]}]\n        )\n        assert len(vpcs[\"Vpcs\"]) == 1, f\"VPC \u0027{vpc_name}\u0027 should exist\"\n        \n        vpc = vpcs[\"Vpcs\"][0]\n        assert vpc[\"State\"] == \"available\", \"VPC should be in available state\"\n        assert vpc[\"CidrBlock\"] == infrastructure_config[\"vpc\"][\"cidr\"]\n        \n        # Check Internet Gateway exists\n        igws = ec2_client.describe_internet_gateways(\n            Filters=[{\"Name\": \"attachment.vpc-id\", \"Values\": [vpc[\"VpcId\"]]}]\n        )\n        assert len(igws[\"InternetGateways\"]) == 1, \"Internet Gateway should exist\"\n        assert igws[\"InternetGateways\"][0][\"State\"] == \"available\"\n    \n    def test_subnet_configuration_validation(self, ec2_client, infrastructure_config):\n        \"\"\"Test that subnets are configured correctly according to specification.\"\"\"\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Get VPC ID\n        vpcs = ec2_client.describe_vpcs(\n            Filters=[{\"Name\": \"tag:Name\", \"Values\": [vpc_name]}]\n        )\n        vpc_id = vpcs[\"Vpcs\"][0][\"VpcId\"]\n        \n        # Get all subnets\n        subnets = ec2_client.describe_subnets(\n            Filters=[{\"Name\": \"vpc-id\", \"Values\": [vpc_id]}]\n        )\n        \n        subnet_count = len(subnets[\"Subnets\"])\n        expected_count = (len(infrastructure_config[\"subnets\"][\"public\"]) + \n                         len(infrastructure_config[\"subnets\"][\"private\"]))\n        assert subnet_count == expected_count, f\"Expected {expected_count} subnets, found {subnet_count}\"\n        \n        # Verify subnet properties\n        subnet_by_name = {}\n        for subnet in subnets[\"Subnets\"]:\n            name = next((tag[\"Value\"] for tag in subnet.get(\"Tags\", []) \n                        if tag[\"Key\"] == \"Name\"), None)\n            if name:\n                subnet_by_name[name] = subnet\n        \n        # Check public subnets\n        for subnet_key, subnet_config in infrastructure_config[\"subnets\"][\"public\"].items():\n            subnet_name = subnet_config[\"name\"]\n            assert subnet_name in subnet_by_name, f\"Public subnet \u0027{subnet_name}\u0027 should exist\"\n            \n            subnet = subnet_by_name[subnet_name]\n            assert subnet[\"CidrBlock\"] == subnet_config[\"cidr\"]\n            assert subnet[\"AvailabilityZone\"] == subnet_config[\"az\"]\n            assert subnet[\"MapPublicIpOnLaunch\"] is True, \"Public subnets should map public IPs\"\n        \n        # Check private subnets\n        for subnet_key, subnet_config in infrastructure_config[\"subnets\"][\"private\"].items():\n            subnet_name = subnet_config[\"name\"]\n            assert subnet_name in subnet_by_name, f\"Private subnet \u0027{subnet_name}\u0027 should exist\"\n            \n            subnet = subnet_by_name[subnet_name]\n            assert subnet[\"CidrBlock\"] == subnet_config[\"cidr\"]\n            assert subnet[\"AvailabilityZone\"] == subnet_config[\"az\"]\n    \n    def test_infrastructure_discovery_workflow(self, infrastructure_config):\n        \"\"\"Test the complete infrastructure discovery workflow.\"\"\"\n        manager = NetworkInfrastructureManager()\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Discover infrastructure\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        \n        # Validate discovery results\n        assert infrastructure[\"vpc\"].name == vpc_name\n        assert infrastructure[\"vpc\"].cidr == infrastructure_config[\"vpc\"][\"cidr\"]\n        assert infrastructure[\"vpc\"].state == \"available\"\n        \n        # Check subnet categorization\n        assert len(infrastructure[\"subnets\"][\"public\"]) \u003e 0, \"Should discover public subnets\"\n        assert len(infrastructure[\"subnets\"][\"private\"]) \u003e 0, \"Should discover private subnets\"\n        \n        # Verify subnet details\n        all_subnets = infrastructure[\"subnets\"][\"public\"] + infrastructure[\"subnets\"][\"private\"]\n        for subnet in all_subnets:\n            assert subnet.id is not None\n            assert subnet.name is not None\n            assert subnet.cidr is not None\n            assert subnet.availability_zone is not None\n            assert subnet.state == \"available\"\n        \n        # Check Internet Gateway\n        assert infrastructure[\"internet_gateway\"] is not None\n        assert infrastructure[\"internet_gateway\"].id.startswith(\"igw-\")\n    \n    def test_security_group_creation_and_rules(self, infrastructure_config):\n        \"\"\"Test security group creation with proper tier isolation.\"\"\"\n        manager = NetworkInfrastructureManager()\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Discover infrastructure to get VPC ID\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        vpc_id = infrastructure[\"vpc\"].id\n        \n        # Create web tier security group\n        web_sg_id = manager.create_security_group(\n            vpc_id=vpc_id,\n            name=\"test-web-sg\",\n            description=\"Test web tier security group\",\n            ingress_rules=[\n                {\n                    \"IpProtocol\": \"tcp\",\n                    \"FromPort\": 80,\n                    \"ToPort\": 80,\n                    \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\"}]\n                },\n                {\n                    \"IpProtocol\": \"tcp\",\n                    \"FromPort\": 443,\n                    \"ToPort\": 443,\n                    \"IpRanges\": [{\"CidrIp\": \"0.0.0.0/0\"}]\n                }\n            ]\n        )\n        \n        assert web_sg_id is not None\n        assert web_sg_id.startswith(\"sg-\")\n        \n        # Verify security group rules\n        response = manager.ec2_client.describe_security_groups(GroupIds=[web_sg_id])\n        security_group = response[\"SecurityGroups\"][0]\n        \n        assert len(security_group[\"IpPermissions\"]) == 2\n        \n        # Check HTTP rule\n        http_rule = next((rule for rule in security_group[\"IpPermissions\"] \n                         if rule[\"FromPort\"] == 80), None)\n        assert http_rule is not None\n        assert http_rule[\"IpProtocol\"] == \"tcp\"\n        assert \"0.0.0.0/0\" in [ip_range[\"CidrIp\"] for ip_range in http_rule[\"IpRanges\"]]\n        \n        # Check HTTPS rule\n        https_rule = next((rule for rule in security_group[\"IpPermissions\"] \n                          if rule[\"FromPort\"] == 443), None)\n        assert https_rule is not None\n        assert https_rule[\"IpProtocol\"] == \"tcp\"\n    \n    def test_multi_tier_application_deployment(self, infrastructure_config):\n        \"\"\"Test deploying a complete multi-tier application.\"\"\"\n        manager = NetworkInfrastructureManager()\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Discover infrastructure\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        \n        # Define application configuration\n        app_config = {\n            \"web\": {\n                \"instances_per_subnet\": 1,\n                \"instance_type\": \"t3.micro\",\n                \"ami_id\": \"ami-0c02fb55956c7d316\"\n            },\n            \"app\": {\n                \"instances_per_subnet\": 1,\n                \"instance_type\": \"t3.micro\",\n                \"ami_id\": \"ami-0c02fb55956c7d316\"\n            },\n            \"database\": {\n                \"instances_per_subnet\": 1,\n                \"instance_type\": \"t3.micro\",\n                \"ami_id\": \"ami-0c02fb55956c7d316\"\n            }\n        }\n        \n        # Deploy application\n        deployments = manager.deploy_multi_tier_application(infrastructure, app_config)\n        \n        try:\n            # Validate deployment results\n            assert \"web\" in deployments, \"Web tier should be deployed\"\n            assert \"app\" in deployments, \"App tier should be deployed\"\n            assert \"database\" in deployments, \"Database tier should be deployed\"\n            \n            # Check instance counts\n            web_instances = deployments[\"web\"]\n            app_instances = deployments[\"app\"]\n            db_instances = deployments[\"database\"]\n            \n            assert len(web_instances) \u003e 0, \"Web tier should have instances\"\n            assert len(app_instances) \u003e 0, \"App tier should have instances\"\n            assert len(db_instances) \u003e 0, \"Database tier should have instances\"\n            \n            # Verify instances are running\n            all_instance_ids = web_instances + app_instances + db_instances\n            \n            response = manager.ec2_client.describe_instances(InstanceIds=all_instance_ids)\n            running_count = 0\n            for reservation in response[\"Reservations\"]:\n                for instance in reservation[\"Instances\"]:\n                    if instance[\"State\"][\"Name\"] in [\"pending\", \"running\"]:\n                        running_count += 1\n            \n            assert running_count == len(all_instance_ids), \"All instances should be pending or running\"\n            \n            # Validate instance placement\n            for reservation in response[\"Reservations\"]:\n                for instance in reservation[\"Instances\"]:\n                    tier_tag = next((tag[\"Value\"] for tag in instance.get(\"Tags\", []) \n                                   if tag[\"Key\"] == \"Tier\"), None)\n                    assert tier_tag in [\"web\", \"app\", \"database\"], \"Instance should have valid tier tag\"\n                    \n                    # Web instances should be in public subnets\n                    if tier_tag == \"web\":\n                        public_subnet_ids = [s.id for s in infrastructure[\"subnets\"][\"public\"]]\n                        assert instance[\"SubnetId\"] in public_subnet_ids, \"Web instances should be in public subnets\"\n                    \n                    # App and DB instances should be in private subnets\n                    elif tier_tag in [\"app\", \"database\"]:\n                        private_subnet_ids = [s.id for s in infrastructure[\"subnets\"][\"private\"]]\n                        assert instance[\"SubnetId\"] in private_subnet_ids, \"App/DB instances should be in private subnets\"\n        \n        finally:\n            # Clean up instances\n            all_instance_ids = []\n            for tier_instances in deployments.values():\n                all_instance_ids.extend(tier_instances)\n            \n            if all_instance_ids:\n                manager.cleanup_deployment(all_instance_ids)\n    \n    def test_network_connectivity_validation(self, infrastructure_config):\n        \"\"\"Test comprehensive network connectivity validation.\"\"\"\n        manager = NetworkInfrastructureManager()\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Discover infrastructure\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        \n        # Run connectivity validation\n        results = manager.validate_network_connectivity(infrastructure)\n        \n        # Validate test results\n        assert isinstance(results, dict), \"Results should be a dictionary\"\n        assert len(results) \u003e 0, \"Should have connectivity test results\"\n        \n        # Check specific connectivity tests\n        assert \"vpc_dns_enabled\" in results, \"Should test VPC DNS settings\"\n        assert \"public_internet_access\" in results, \"Should test public internet access\"\n        assert \"cross_az_connectivity\" in results, \"Should test cross-AZ connectivity\"\n        \n        # VPC should have DNS enabled\n        assert results[\"vpc_dns_enabled\"] is True, \"VPC should have DNS support enabled\"\n        \n        # Should have cross-AZ connectivity (multiple AZs)\n        assert results[\"cross_az_connectivity\"] is True, \"Should have subnets in multiple AZs\"\n        \n        # Log results for debugging\n        for test_name, test_result in results.items():\n            print(f\"Connectivity test \u0027{test_name}\u0027: {\u0027PASS\u0027 if test_result else \u0027FAIL\u0027}\")\n    \n    def test_high_availability_deployment_pattern(self, infrastructure_config):\n        \"\"\"Test deploying applications across multiple availability zones for high availability.\"\"\"\n        manager = NetworkInfrastructureManager()\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Discover infrastructure\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        \n        # Count availability zones\n        public_azs = set(subnet.availability_zone for subnet in infrastructure[\"subnets\"][\"public\"])\n        private_azs = set(subnet.availability_zone for subnet in infrastructure[\"subnets\"][\"private\"])\n        \n        assert len(public_azs) \u003e= 2, \"Should have public subnets in at least 2 AZs for HA\"\n        assert len(private_azs) \u003e= 2, \"Should have private subnets in at least 2 AZs for HA\"\n        \n        # Deploy HA configuration\n        app_config = {\n            \"web\": {\n                \"instances_per_subnet\": 1,  # One instance per subnet for HA\n                \"instance_type\": \"t3.micro\",\n                \"ami_id\": \"ami-0c02fb55956c7d316\"\n            }\n        }\n        \n        deployments = manager.deploy_multi_tier_application(infrastructure, app_config)\n        \n        try:\n            web_instances = deployments[\"web\"]\n            \n            # Verify instances are distributed across AZs\n            response = manager.ec2_client.describe_instances(InstanceIds=web_instances)\n            instance_azs = set()\n            \n            for reservation in response[\"Reservations\"]:\n                for instance in reservation[\"Instances\"]:\n                    instance_azs.add(instance[\"Placement\"][\"AvailabilityZone\"])\n            \n            assert len(instance_azs) \u003e= 2, \"Web instances should be distributed across multiple AZs\"\n            \n        finally:\n            # Clean up\n            all_instance_ids = []\n            for tier_instances in deployments.values():\n                all_instance_ids.extend(tier_instances)\n            \n            if all_instance_ids:\n                manager.cleanup_deployment(all_instance_ids)\n    \n    def test_nat_gateway_configuration(self, infrastructure_config):\n        \"\"\"Test NAT Gateway configuration for private subnet internet access.\"\"\"\n        manager = NetworkInfrastructureManager()\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        \n        # Discover infrastructure\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        \n        # Check NAT Gateway presence\n        nat_gateways = infrastructure[\"nat_gateways\"]\n        \n        if len(infrastructure[\"subnets\"][\"private\"]) \u003e 0:\n            # Should have NAT Gateways for private subnet internet access\n            # Note: This depends on the Terraform configuration actually creating NAT Gateways\n            print(f\"Found {len(nat_gateways)} NAT Gateway(s)\")\n            \n            # Verify NAT Gateway placement in public subnets\n            if nat_gateways:\n                public_subnet_ids = [s.id for s in infrastructure[\"subnets\"][\"public\"]]\n                \n                nat_gateway_details = manager.ec2_client.describe_nat_gateways(\n                    NatGatewayIds=[ng.id for ng in nat_gateways]\n                )\n                \n                for nat_gw in nat_gateway_details[\"NatGateways\"]:\n                    assert nat_gw[\"SubnetId\"] in public_subnet_ids, \"NAT Gateway should be in public subnet\"\n                    assert nat_gw[\"State\"] in [\"pending\", \"available\"], \"NAT Gateway should be available\"\n    \n    def test_error_handling_and_resilience(self, infrastructure_config):\n        \"\"\"Test error handling and resilience of the network management system.\"\"\"\n        manager = NetworkInfrastructureManager()\n        \n        # Test 1: Invalid VPC name\n        with pytest.raises(ValueError, match=\"VPC with name .* not found\"):\n            manager.discover_vpc_infrastructure(\"nonexistent-vpc\")\n        \n        # Test 2: Duplicate security group creation\n        vpc_name = infrastructure_config[\"vpc\"][\"name\"]\n        infrastructure = manager.discover_vpc_infrastructure(vpc_name)\n        vpc_id = infrastructure[\"vpc\"].id\n        \n        # Create security group\n        sg_name = \"test-duplicate-sg\"\n        sg_id_1 = manager.create_security_group(\n            vpc_id=vpc_id,\n            name=sg_name,\n            description=\"Test duplicate security group\",\n            ingress_rules=[]\n        )\n        \n        # Try to create same security group again (should handle gracefully)\n        sg_id_2 = manager.create_security_group(\n            vpc_id=vpc_id,\n            name=sg_name,\n            description=\"Test duplicate security group\",\n            ingress_rules=[]\n        )\n        \n        assert sg_id_1 == sg_id_2, \"Should return existing security group ID\"\n        \n        # Test 3: Cleanup with empty instance list\n        result = manager.cleanup_deployment([])\n        assert result is True, \"Cleanup should handle empty instance list gracefully\""}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/5f63fc2a95796608", "duration": 313.063749, "failure_analysis": {"affected_resource": null, "affected_service": null, "aws_error_code": null, "category": "failed", "error_message": null, "is_localstack_issue": true}, "hash": "5f63fc2a95796608", "logs": "21:06.112  INFO --- [et.reactor-3] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:06.116  INFO --- [et.reactor-4] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:16.128  INFO --- [et.reactor-1] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:16.132  INFO --- [et.reactor-5] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:26.144  INFO --- [et.reactor-2] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:26.147  INFO --- [et.reactor-0] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:36.163  INFO --- [et.reactor-4] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:36.166  INFO --- [et.reactor-7] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:46.184  INFO --- [et.reactor-1] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:46.187  INFO --- [et.reactor-6] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:56.195  INFO --- [et.reactor-3] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:21:56.198  INFO --- [et.reactor-0] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:06.212  INFO --- [et.reactor-7] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:06.216  INFO --- [et.reactor-5] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:16.229  INFO --- [et.reactor-6] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:16.232  INFO --- [et.reactor-2] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:26.247  INFO --- [et.reactor-3] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:26.251  INFO --- [et.reactor-4] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:36.264  INFO --- [et.reactor-1] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:36.267  INFO --- [et.reactor-5] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:46.275  INFO --- [et.reactor-2] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:46.278  INFO --- [et.reactor-0] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:56.284  INFO --- [et.reactor-7] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:22:56.297  INFO --- [et.reactor-4] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:06.312  INFO --- [et.reactor-1] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:06.314  INFO --- [et.reactor-6] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:16.329  INFO --- [et.reactor-0] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:16.333  INFO --- [et.reactor-3] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:26.344  INFO --- [et.reactor-7] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:26.347  INFO --- [et.reactor-5] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:36.363  INFO --- [et.reactor-2] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:36.366  INFO --- [et.reactor-6] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:46.375  INFO --- [et.reactor-3] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:46.378  INFO --- [et.reactor-4] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:56.385  INFO --- [et.reactor-1] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:23:56.388  INFO --- [et.reactor-5] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:06.404  INFO --- [et.reactor-2] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:06.407  INFO --- [et.reactor-0] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:16.422  INFO --- [et.reactor-4] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:16.425  INFO --- [et.reactor-7] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:26.432  INFO --- [et.reactor-5] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:26.435  INFO --- [et.reactor-6] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:36.438  INFO --- [et.reactor-0] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:36.442  INFO --- [et.reactor-3] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:46.445  INFO --- [et.reactor-7] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n2026-01-11T18:24:46.449  INFO --- [et.reactor-1] localstack.request.aws     : AWS ec2.DescribeSubnets =\u003e 200\n", "name": "ViktorUJ/vpc", "original_format": null, "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["ec2"], "source_type": "terraform_registry", "source_url": "https://registry.terraform.io/modules/ViktorUJ/vpc/aws/1.1.0", "status": "FAILED", "terraform_files": {"data.tf": "data \"aws_availability_zones\" \"available\" {}\n", "locals.tf": "locals {\n  az_mapping = {\n    for idx, az in data.aws_availability_zones.available.names : az =\u003e\n    data.aws_availability_zones.available.zone_ids[idx]\n  }\n\n  az_id_to_az = { for az, az_id in local.az_mapping : az_id =\u003e az }\n\n  normalized_public_subnets_all = {\n    for k, v in var.subnets.public : k =\u003e merge(v, {\n      az = lookup(local.az_id_to_az, v.az, v.az) # modify AZ ID to AZ\n    })\n  }\n\n  normalized_private_subnets_all = {\n    for k, v in var.subnets.private : k =\u003e merge(v, {\n      az = lookup(local.az_id_to_az, v.az, v.az) # modify AZ ID to AZ\n    })\n  }\n\n  # group by type and create a list of identifiers\n  private_subnets_by_type = {\n    for type in distinct([for k, v in local.normalized_private_subnets_all : v.type]) : type =\u003e {\n      ids  = [for k, v in local.normalized_private_subnets_all : aws_subnet.private[k].id if v.type == type]\n      keys = [for k, v in local.normalized_private_subnets_all : k if v.type == type]\n    }\n  }\n\n  public_subnets_by_type = {\n    for type in distinct([for k, v in var.subnets.public : v.type]) : type =\u003e {\n      ids  = [for k, v in local.normalized_public_subnets_all : aws_subnet.public[k].id if v.type == type]\n      keys = [for k, v in local.normalized_public_subnets_all : k if v.type == type]\n    }\n  }\n\n  private_subnets_by_az_output = {\n    for az in distinct([for subnet in local.normalized_private_subnets_all : subnet.az]) : az =\u003e [\n      for subnet_key, subnet in local.normalized_private_subnets_all : aws_subnet.private[subnet_key].id\n      if subnet.az == az\n    ]\n  }\n\n  public_subnets_by_az_output = {\n    for az in distinct([for subnet in local.normalized_public_subnets_all : subnet.az]) : az =\u003e [\n      for subnet_key, subnet in local.normalized_public_subnets_all : aws_subnet.public[subnet_key].id\n      if subnet.az == az\n    ]\n  }\n\n\n  private_subnets_by_az_id = {\n    for az_id in distinct([for subnet in local.normalized_private_subnets_all : lookup(local.az_mapping, subnet.az)]) : az_id =\u003e [\n      for subnet_key, subnet in local.normalized_private_subnets_all : aws_subnet.private[subnet_key].id\n      if lookup(local.az_mapping, subnet.az) == az_id\n    ]\n  }\n\n  public_subnets_by_az_id = {\n    for az_id in distinct([for subnet in local.normalized_public_subnets_all : lookup(local.az_mapping, subnet.az)]) : az_id =\u003e [\n      for subnet_key, subnet in local.normalized_public_subnets_all : aws_subnet.public[subnet_key].id\n      if lookup(local.az_mapping, subnet.az) == az_id\n    ]\n  }\n}\n", "main.tf": "", "outputs.tf": "# inputs\noutput \"tags_default\" {\n  description = \"Default tags\"\n  value       = var.tags_default\n}\n\noutput \"subnets_var\" {\n  description = \"for test\"\n  value       = var.subnets\n}\noutput \"vpc_var\" {\n  value = var.vpc\n}\n\n# vpc\noutput \"vpc_raw\" {\n  value = try(aws_vpc.default, null)\n}\n\n\n# debug\noutput \"az_mapping\" {\n  value = local.az_mapping\n}\n\n\n#subnets public\n\noutput \"normalized_public_subnets_all\" {\n  value = local.normalized_public_subnets_all\n}\n\noutput \"subnets_public_raw\" {\n  value = try(aws_subnet.public, null)\n}\noutput \"public_subnets_by_type\" {\n  value = local.public_subnets_by_type\n}\n\noutput \"public_subnets_by_az\" {\n  value = local.public_subnets_by_az_output\n}\n\noutput \"public_subnets_by_az_id\" {\n  value = local.public_subnets_by_az_id\n}\n#subnets private\noutput \"normalized_private_subnets_all\" {\n  value = local.normalized_private_subnets_all\n}\n\noutput \"subnets_private_raw\" {\n  value = try(aws_subnet.private, null)\n}\n\noutput \"private_subnets_by_type\" {\n  value = local.private_subnets_by_type\n}\n\noutput \"private_subnets_by_az\" {\n  value = local.private_subnets_by_az_output\n}\n\noutput \"private_subnets_by_az_id\" {\n  value = local.private_subnets_by_az_id\n}\n\n# NACL\noutput \"nacl_default_rules_raw\" {\n  value = aws_network_acl_rule.default\n}\noutput \"public_nacl_raw\" {\n  value = try(aws_network_acl.public, null)\n\n}\noutput \"public_nacl_rules_raw\" {\n  value = aws_network_acl_rule.public_rules\n}\n\n\noutput \"private_nacl_raw\" {\n  value = try(aws_network_acl.private, null)\n}\noutput \"private_nacl_rules_raw\" {\n  value = aws_network_acl_rule.private_rules\n}\n\n# NAT Gateway\n\noutput \"nat_gateway_single_raw\" {\n  value = try(aws_nat_gateway.SINGLE_nat_gateway, null)\n}\n\noutput \"nat_gateway_subnet_raw\" {\n  value = try(aws_nat_gateway.SUBNET_nat_gateway, null)\n}\n\noutput \"nat_gateway_az_raw\" {\n  value = try(aws_nat_gateway.az_nat_gateway, null)\n}\n\n# Route Table\noutput \"route_table_private_raw\" {\n  value = try(aws_route_table.private, null)\n}\n\noutput \"route_table_public_raw\" {\n  value = try(aws_route_table.public, null)\n}\n", "subnets_private.tf": "resource \"aws_subnet\" \"private\" {\n  vpc_id                  = aws_vpc.default.id\n  for_each                = local.normalized_private_subnets_all\n  map_public_ip_on_launch = \"false\"\n  cidr_block              = each.value.cidr\n\n  assign_ipv6_address_on_creation                = each.value.assign_ipv6_address_on_creation\n  customer_owned_ipv4_pool                       = each.value.customer_owned_ipv4_pool != \"\" ? each.value.customer_owned_ipv4_pool : null\n  enable_dns64                                   = each.value.enable_dns64\n  enable_resource_name_dns_aaaa_record_on_launch = each.value.enable_resource_name_dns_aaaa_record_on_launch\n  enable_resource_name_dns_a_record_on_launch    = each.value.enable_resource_name_dns_a_record_on_launch\n  ipv6_cidr_block                                = each.value.ipv6_cidr_block != \"\" ? each.value.ipv6_cidr_block : null\n  ipv6_native                                    = each.value.ipv6_native\n  map_customer_owned_ip_on_launch                = each.value.map_customer_owned_ip_on_launch ? each.value.map_customer_owned_ip_on_launch : null\n  outpost_arn                                    = each.value.outpost_arn != \"\" ? each.value.outpost_arn : null\n  private_dns_hostname_type_on_launch            = each.value.private_dns_hostname_type_on_launch != \"\" ? each.value.private_dns_hostname_type_on_launch : null\n\n\n\n  availability_zone = each.value.az\n\n  tags = merge(var.tags_default, { \"Name\" = each.value.name }, { \"type\" = each.value.type }, { \"subnet_key\" = each.key }, { \"access_type\" = \"private\" }, each.value.tags)\n}\n\n\n\n\nresource \"aws_route_table\" \"private\" {\n  for_each = local.normalized_private_subnets_all\n  vpc_id   = aws_vpc.default.id\n  tags     = merge(var.tags_default, { \"Name\" = each.value.name }, { \"type\" = each.value.type }, { \"subnet_key\" = each.key }, { \"access_type\" = \"private\" }, each.value.tags)\n}\n\nresource \"aws_route_table_association\" \"private\" {\n  for_each       = local.normalized_private_subnets_all\n  route_table_id = aws_route_table.private[\"${each.key}\"].id\n  subnet_id      = aws_subnet.private[\"${each.key}\"].id\n}\n\n# \u003c Az NAT Gateway\nlocals {\n  normalized_private_subnets_AZ = {\n    for k, v in var.subnets.private : k =\u003e merge(v, {\n      az = lookup(local.az_id_to_az, v.az, v.az) # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c AZ ID \u0432 AZ, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\n    })\n    if v.nat_gateway == \"AZ\" # \u0424\u0438\u043b\u044c\u0442\u0440\u0443\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u043f\u043e\u0434\u0441\u0435\u0442\u0438, \u0433\u0434\u0435 nat_gateway = \"AZ\"\n  }\n\n\n\n  private_subnets_by_az = {\n    for az in distinct([for s in local.normalized_private_subnets_AZ : s.az]) :\n    az =\u003e {\n      ids  = [for k, s in local.normalized_private_subnets_AZ : aws_subnet.private[k].id if s.az == az]\n      keys = [for k, s in local.normalized_private_subnets_AZ : k if s.az == az]\n    }\n  }\n}\n\nresource \"aws_nat_gateway\" \"az_nat_gateway\" {\n  for_each = local.private_subnets_by_az\n\n  allocation_id = length(keys(var.existing_eip_ids_az)) == 0 ? aws_eip.az_nat_gateway_eip[each.key].id : var.existing_eip_ids_az[each.key]\n  subnet_id     = local.public_subnets_by_az_output[each.key][0]\n  tags          = merge(var.tags_default, { \"Name\" = \"az_nat_gateway-${each.key}\" })\n}\n\nresource \"aws_eip\" \"az_nat_gateway_eip\" {\n  for_each = length(keys(var.existing_eip_ids_az)) == 0 ? {\n    for az, data in local.private_subnets_by_az : az =\u003e az\n  } : {}\n  domain = \"vpc\"\n  tags   = merge(var.tags_default, { \"Name\" = \"az_nat_gateway-${each.key}\" })\n}\n\nlocals {\n  flat_private_subnet_keys = flatten([\n    for az, data in local.private_subnets_by_az : [\n      for key in data.keys : {\n        key = key\n        az  = az\n        id  = \"${az}-${key}\"\n      }\n    ]\n  ])\n\n  routes_map_private_subnet_az = {\n    for entry in local.flat_private_subnet_keys : entry.id =\u003e {\n      key = entry.key\n      az  = entry.az\n    }\n  }\n}\n\nresource \"aws_route\" \"private_route_az\" {\n\n  for_each = local.routes_map_private_subnet_az\n\n  route_table_id         = aws_route_table.private[each.value.key].id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.az_nat_gateway[each.value.az].id\n}\n\n\n\n\n# Az NAT Gateway \u003e\n\n\n\n# \u003c SUBNET NAT Gateway\n\nlocals {\n  normalized_private_subnets_SUBNET = {\n    for k, v in var.subnets.private : k =\u003e merge(v, {\n      az = lookup(local.az_id_to_az, v.az, v.az) # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c AZ ID \u0432 AZ, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\n    })\n    if v.nat_gateway == \"SUBNET\" # \u0424\u0438\u043b\u044c\u0442\u0440\u0443\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u043f\u043e\u0434\u0441\u0435\u0442\u0438, \u0433\u0434\u0435 nat_gateway = \"SUBNET\"\n  }\n\n\n}\n\n\nresource \"aws_eip\" \"SUBNET_nat_gateway_eip\" {\n  for_each = local.normalized_private_subnets_SUBNET\n  tags     = merge(var.tags_default, { \"Name\" = \"SUBNET_nat_gateway-${each.key}\" })\n  domain   = \"vpc\"\n}\n\nresource \"aws_nat_gateway\" \"SUBNET_nat_gateway\" {\n  for_each = local.normalized_private_subnets_SUBNET\n\n  allocation_id = aws_eip.SUBNET_nat_gateway_eip[each.key].id\n  subnet_id     = local.public_subnets_by_az_output[each.value.az][0]\n  tags          = merge(var.tags_default, { \"Name\" = \"SUBNET_nat_gateway-${each.key}\" })\n}\n\n\nresource \"aws_route\" \"private_route_SUBNET\" {\n\n  for_each               = local.normalized_private_subnets_SUBNET\n  route_table_id         = aws_route_table.private[each.key].id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.SUBNET_nat_gateway[each.key].id\n}\n\n\n# SUBNET NAT Gateway \u003e\n\n\n# \u003c SINGLE NAT Gateway\n\nlocals {\n  normalized_private_subnets_SINGLE = {\n    for k, v in var.subnets.private : k =\u003e merge(v, {\n      az = lookup(local.az_id_to_az, v.az, v.az) # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c AZ ID \u0432 AZ, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\n    })\n    if v.nat_gateway == \"SINGLE\" # \u0424\u0438\u043b\u044c\u0442\u0440\u0443\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u043f\u043e\u0434\u0441\u0435\u0442\u0438, \u0433\u0434\u0435 nat_gateway = \"SUBNET\"\n  }\n\n  normalized_public_subnets_DEFAULT = {\n    for k, v in var.subnets.public : k =\u003e merge(v, {\n      az = lookup(local.az_id_to_az, v.az, v.az) # \u041f\u0440\u0435\u043e\u0431\u0440\u0430\u0437\u0443\u0435\u043c AZ ID \u0432 AZ, \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e\n    })\n    if v.nat_gateway == \"DEFAULT\" # \u0424\u0438\u043b\u044c\u0442\u0440\u0443\u0435\u043c \u0442\u043e\u043b\u044c\u043a\u043e \u0442\u0435 \u043f\u043e\u0434\u0441\u0435\u0442\u0438, \u0433\u0434\u0435 nat_gateway = \"DEFAULT\"\n  }\n  normalized_public_subnets_DEFAULT_keys             = keys(local.normalized_public_subnets_DEFAULT)\n  normalized_public_subnets_DEFAULT_first_subnet_key = length(local.normalized_public_subnets_DEFAULT_keys) \u003e 0 ? local.normalized_public_subnets_DEFAULT_keys[0] : null\n\n  normalized_public_subnets_DEFAULT_selected = {\n    for k, v in local.normalized_public_subnets_DEFAULT :\n    k =\u003e v if k == local.normalized_public_subnets_DEFAULT_first_subnet_key\n  }\n}\n\n\nresource \"aws_eip\" \"SINGLE_nat_gateway_eip\" {\n  for_each = local.normalized_public_subnets_DEFAULT_selected\n  tags     = merge(var.tags_default, { \"Name\" = \"SINGLE_nat_gateway-${each.key}\" })\n  domain   = \"vpc\"\n}\n\n\n\nresource \"aws_nat_gateway\" \"SINGLE_nat_gateway\" {\n  for_each = local.normalized_public_subnets_DEFAULT_selected\n\n  allocation_id = aws_eip.SINGLE_nat_gateway_eip[each.key].id\n  subnet_id     = aws_subnet.public[each.key].id\n  tags          = merge(var.tags_default, { \"Name\" = \"SINGLE_nat_gateway-${each.key}\" })\n}\n\n\nresource \"aws_route\" \"private_route_SINGLE\" {\n\n  for_each               = local.normalized_private_subnets_SINGLE\n  route_table_id         = aws_route_table.private[each.key].id\n  destination_cidr_block = \"0.0.0.0/0\"\n  nat_gateway_id         = aws_nat_gateway.SINGLE_nat_gateway[\"${local.normalized_public_subnets_DEFAULT_first_subnet_key}\"].id\n}\n\n#  SINGLE NAT Gateway  \u003e\n\n\n# NACL\n\n# Local variable to flatten all NACL rules for private subnets\nlocals {\n  private_nacl_rules = flatten([\n    for subnet_key, subnet in var.subnets.private : [\n      for rule_key, rule in subnet.nacl : {\n        subnet_key = subnet_key\n        rule_key   = rule_key\n        rule       = rule\n      }\n    ]\n  ])\n}\n\n# Create a Network ACL for each private subnet if nacl is defined\nresource \"aws_network_acl\" \"private\" {\n  for_each = {\n    for subnet_key, subnet in var.subnets.private :\n    subnet_key =\u003e subnet\n    if length(subnet.nacl) \u003e 0\n  }\n\n  vpc_id = aws_vpc.default.id\n\n  tags = merge(var.tags_default, {\n    \"Name\" = \"${each.value.name}-nacl\"\n  })\n}\n\n# Create Network ACL rules for each private subnet\u0027s NACL\nresource \"aws_network_acl_rule\" \"private_rules\" {\n  for_each = {\n    for rule in local.private_nacl_rules :\n    \"${rule.subnet_key}-${rule.rule_key}-${rule.rule.rule_number}\" =\u003e rule\n    if length(var.subnets.private[rule.subnet_key].nacl) \u003e 0\n  }\n\n  network_acl_id  = aws_network_acl.private[each.value.subnet_key].id\n  rule_number     = each.value.rule.rule_number\n  egress          = each.value.rule.egress == \"true\" ? true : false\n  protocol        = each.value.rule.protocol\n  rule_action     = each.value.rule.rule_action\n  cidr_block      = each.value.rule.cidr_block != \"\" ? each.value.rule.cidr_block : null\n  from_port       = each.value.rule.from_port != \"\" ? tonumber(each.value.rule.from_port) : null\n  to_port         = each.value.rule.to_port != \"\" ? tonumber(each.value.rule.to_port) : null\n  icmp_code       = each.value.rule.icmp_code != \"\" ? tonumber(each.value.rule.icmp_code) : null\n  icmp_type       = each.value.rule.icmp_type != \"\" ? tonumber(each.value.rule.icmp_type) : null\n  ipv6_cidr_block = each.value.rule.ipv6_cidr_block != \"\" ? each.value.rule.ipv6_cidr_block : null\n}\n\n# Associate the NACL with each private subnet if NACL is defined\nresource \"aws_network_acl_association\" \"private_association\" {\n  for_each = {\n    for subnet_key, subnet in var.subnets.private :\n    subnet_key =\u003e subnet\n    if length(subnet.nacl) \u003e 0\n  }\n\n  subnet_id      = aws_subnet.private[each.key].id\n  network_acl_id = aws_network_acl.private[each.key].id\n}\n", "subnets_pub.tf": "resource \"aws_subnet\" \"public\" {\n  vpc_id                  = aws_vpc.default.id\n  for_each                = local.normalized_public_subnets_all\n  map_public_ip_on_launch = each.value.map_public_ip_on_launch\n  cidr_block              = each.value.cidr\n\n  assign_ipv6_address_on_creation                = each.value.assign_ipv6_address_on_creation\n  customer_owned_ipv4_pool                       = each.value.customer_owned_ipv4_pool != \"\" ? each.value.customer_owned_ipv4_pool : null\n  enable_dns64                                   = each.value.enable_dns64\n  enable_resource_name_dns_aaaa_record_on_launch = each.value.enable_resource_name_dns_aaaa_record_on_launch\n  enable_resource_name_dns_a_record_on_launch    = each.value.enable_resource_name_dns_a_record_on_launch\n  ipv6_cidr_block                                = each.value.ipv6_cidr_block != \"\" ? each.value.ipv6_cidr_block : null\n  ipv6_native                                    = each.value.ipv6_native\n  map_customer_owned_ip_on_launch                = each.value.map_customer_owned_ip_on_launch ? each.value.map_customer_owned_ip_on_launch : null\n  outpost_arn                                    = each.value.outpost_arn != \"\" ? each.value.outpost_arn : null\n  private_dns_hostname_type_on_launch            = each.value.private_dns_hostname_type_on_launch != \"\" ? each.value.private_dns_hostname_type_on_launch : null\n\n\n  availability_zone_id = length(regexall(\"^[a-z]{2}-\", each.value.az)) == 0 ? each.value.az : null\n  availability_zone    = length(regexall(\"^[a-z]{2}-\", each.value.az)) \u003e 0 ? each.value.az : null\n\n  tags = merge(var.tags_default, { \"Name\" = each.value.name }, { \"type\" = each.value.type }, { \"subnet_key\" = each.key }, { \"access_type\" = \"public\" }, each.value.tags)\n}\n\nresource \"aws_route_table\" \"public\" {\n  vpc_id = aws_vpc.default.id\n  tags   = merge(var.tags_default, { \"access_type\" = \"public\" })\n}\n\nresource \"aws_route\" \"public\" {\n  route_table_id         = aws_route_table.public.id\n  destination_cidr_block = \"0.0.0.0/0\"\n  gateway_id             = aws_internet_gateway.default.id\n\n  timeouts {\n    create = \"5m\"\n  }\n}\n\n\nresource \"aws_route_table_association\" \"pub\" {\n  for_each       = var.subnets.public\n  route_table_id = aws_route_table.public.id\n  subnet_id      = aws_subnet.public[\"${each.key}\"].id\n}\n\n\n\n# Local variable to flatten all NACL rules for public subnets\nlocals {\n  public_nacl_rules = flatten([\n    for subnet_key, subnet in local.normalized_public_subnets_all : [\n      for rule_key, rule in subnet.nacl : {\n        subnet_key = subnet_key\n        rule_key   = rule_key\n        rule       = rule\n      }\n      if length(subnet.nacl) \u003e 0\n    ]\n  ])\n}\n\n# Create a Network ACL for each public subnet if nacl is defined and contains rules\nresource \"aws_network_acl\" \"public\" {\n  for_each = {\n    for subnet_key, subnet in local.normalized_public_subnets_all :\n    subnet_key =\u003e subnet\n    if length(subnet.nacl) \u003e 0\n  }\n\n  vpc_id = aws_vpc.default.id\n\n  tags = merge(var.tags_default, {\n    \"Name\" = \"${each.value.name}-nacl\"\n  })\n}\n\n# Create Network ACL rules for each public subnet\u0027s NACL\nresource \"aws_network_acl_rule\" \"public_rules\" {\n  for_each = {\n    for rule in local.public_nacl_rules :\n    \"${rule.subnet_key}-${rule.rule_key}-${rule.rule.rule_number}\" =\u003e rule\n    if length(var.subnets.public[rule.subnet_key].nacl) \u003e 0\n  }\n\n  network_acl_id  = aws_network_acl.public[each.value.subnet_key].id\n  rule_number     = each.value.rule.rule_number\n  egress          = each.value.rule.egress == \"true\" ? true : false\n  protocol        = each.value.rule.protocol\n  rule_action     = each.value.rule.rule_action\n  cidr_block      = each.value.rule.cidr_block != \"\" ? each.value.rule.cidr_block : null\n  from_port       = each.value.rule.from_port != \"\" ? tonumber(each.value.rule.from_port) : null\n  to_port         = each.value.rule.to_port != \"\" ? tonumber(each.value.rule.to_port) : null\n  icmp_code       = each.value.rule.icmp_code != \"\" ? tonumber(each.value.rule.icmp_code) : null\n  icmp_type       = each.value.rule.icmp_type != \"\" ? tonumber(each.value.rule.icmp_type) : null\n  ipv6_cidr_block = each.value.rule.ipv6_cidr_block != \"\" ? each.value.rule.ipv6_cidr_block : null\n}\n\n# Associate the NACL with each public subnet if NACL is defined and contains rules\nresource \"aws_network_acl_association\" \"public_association\" {\n  for_each = {\n    for subnet_key, subnet in local.normalized_public_subnets_all :\n    subnet_key =\u003e subnet\n    if length(subnet.nacl) \u003e 0\n  }\n\n  subnet_id      = aws_subnet.public[each.key].id\n  network_acl_id = aws_network_acl.public[each.key].id\n}\n", "variables.tf": "variable \"vpc\" {\n  type = object({\n    name                  = string\n    cidr                  = string\n    secondary_cidr_blocks = optional(list(string), [])\n    tags                  = optional(map(string), {})\n    instance_tenancy      = optional(string, \"default\") # default, dedicated\n    enable_dns_support    = optional(bool, true)        # true, false\n    enable_dns_hostnames  = optional(bool, true)        # true, false\n    nacl_default = optional(map(object({\n      egress      = string # true, false\n      rule_number = string # ACL entries are processed in ascending order by rule number\n      rule_action = string # allow | deny\n      from_port   = optional(string, \"\")\n      to_port     = optional(string, \"\")\n      icmp_code   = optional(string, \"\")\n      # (Optional) ICMP protocol: The ICMP type. Required if specifying ICMP for the protocolE.g., -1\n      icmp_type = optional(string, \"\")\n      # (Optional) ICMP protocol: The ICMP code. Required if specifying ICMP for the protocolE.g., -1\n      protocol   = string # A value of -1 means all protocols , tcp  - 6 ,\n      cidr_block = optional(string, \"\")\n      # The network range to allow or deny, in CIDR notation (for example 172.16.0.0/24 ).\n      ipv6_cidr_block = optional(string, \"\")\n\n    })), {})\n    dhcp_options = optional(object({\n      domain_name                       = optional(string, \"\")\n      domain_name_servers               = optional(list(string), [])\n      ntp_servers                       = optional(list(string), [])\n      netbios_name_servers              = optional(list(string), [])\n      netbios_node_type                 = optional(string, \"\")    # 1, 2, 4, 8  . default 2 . http://www.ietf.org/rfc/rfc2132.txt\n      ipv6_address_preferred_lease_time = optional(string, \"140\") # 140 .. 2147483647 seconds . default 140\n      tags                              = optional(map(string), {})\n    }), {})\n  })\n\n  # Validation for CIDR format\n  validation {\n    condition     = can(cidrsubnet(var.vpc.cidr, 0, 0))\n    error_message = \"Invalid CIDR block format for VPC. CIDR block must be a valid subnet, e.g., 10.0.0.0/16.\"\n  }\n\n  # Validation for netbios_node_type field\n  validation {\n    condition = var.vpc.dhcp_options.netbios_node_type == \"\" || contains([\n      \"1\", \"2\", \"4\", \"8\"\n    ], var.vpc.dhcp_options.netbios_node_type)\n    error_message = \"Invalid value for netbios_node_type. Must be one of: 1, 2, 4, 8.\"\n  }\n\n  # Validation for ipv6_address_preferred_lease_time\n  validation {\n    condition = (\n      var.vpc.dhcp_options.ipv6_address_preferred_lease_time == \"\" ||\n      (\n        length(var.vpc.dhcp_options.ipv6_address_preferred_lease_time) \u003e 0 \u0026\u0026\n        can(tonumber(var.vpc.dhcp_options.ipv6_address_preferred_lease_time)) \u0026\u0026\n        tonumber(var.vpc.dhcp_options.ipv6_address_preferred_lease_time) \u003e= 140 \u0026\u0026\n        tonumber(var.vpc.dhcp_options.ipv6_address_preferred_lease_time) \u003c= 2147483647\n      )\n    )\n    error_message = \"Invalid value for ipv6_address_preferred_lease_time. Must be a number between 140 and 2147483647 seconds.\"\n  }\n}\n\nvariable \"tags_default\" {\n  type    = map(string)\n  default = {}\n}\n\n\nvariable \"subnets\" {\n  type = object({\n    public = optional(map(object({\n      name = string\n      cidr = string\n      az   = string # Availability Zone or Availability Zone ID\n      tags = optional(map(string), {})\n      type = optional(string, \"public\") # any sort key for grouping . example , DB , WEB , APP , etc\n\n      assign_ipv6_address_on_creation                = optional(bool, false)\n      customer_owned_ipv4_pool                       = optional(string, \"\")\n      enable_dns64                                   = optional(bool, false)\n      enable_resource_name_dns_aaaa_record_on_launch = optional(bool, false)\n      enable_resource_name_dns_a_record_on_launch    = optional(bool, true)\n      ipv6_cidr_block                                = optional(string, \"\")\n      ipv6_native                                    = optional(bool, false)\n      map_customer_owned_ip_on_launch                = optional(bool, false)\n      map_public_ip_on_launch                        = optional(bool, true)\n      outpost_arn                                    = optional(string, \"\")\n      private_dns_hostname_type_on_launch            = optional(string, \"ip-name\") #  The type of hostnames to assign to instances in the subnet at launch. For IPv6-only subnets, an instance DNS name must be based on the instance ID. For dual-stack and IPv4-only subnets, you can specify whether DNS names use the instance IPv4 address or the instance ID . Valid values:  ip-name, resource-name.\n      nat_gateway                                    = optional(string, \"\")        #  DEFAULT - default nat gateway for all AZ  with SINGLE value\n      nacl = optional(map(object({\n        egress          = string # true, false\n        rule_number     = string # ACL entries are processed in ascending order by rule number\n        rule_action     = string # allow | deny\n        from_port       = optional(string, \"\")\n        to_port         = optional(string, \"\")\n        icmp_code       = optional(string, \"\") # (Optional) ICMP protocol: The ICMP type. Required if specifying ICMP for the protocolE.g., -1\n        icmp_type       = optional(string, \"\") # (Optional) ICMP protocol: The ICMP code. Required if specifying ICMP for the protocolE.g., -1\n        protocol        = string               # A value of -1 means all protocols , tcp  - 6 ,\n        cidr_block      = optional(string, \"\") # The network range to allow or deny, in CIDR notation (for example 172.16.0.0/24 ).\n        ipv6_cidr_block = optional(string, \"\")\n\n      })), {})\n\n    })))\n    private = optional(map(object({\n      name                                           = string\n      cidr                                           = string\n      az                                             = string # Availability Zone or Availability Zone ID\n      tags                                           = optional(map(string), {})\n      type                                           = optional(string, \"private\") # any sort key for grouping . example , DB , WEB , APP , etc\n      nat_gateway                                    = optional(string, \"AZ\")      # AZ - nat gateway for  each AZ , SINGLE - single nat gateway for all AZ (for this option you need to set nat_gateway=DEFAULT in one of the public networks)  ,SUBNET - dedicate nat gateway for each  subnet with SUBNET  type   ,  NONE - no nat gateway\n      assign_ipv6_address_on_creation                = optional(bool, false)\n      customer_owned_ipv4_pool                       = optional(string, \"\")\n      enable_dns64                                   = optional(bool, false)\n      enable_resource_name_dns_aaaa_record_on_launch = optional(bool, false)\n      enable_resource_name_dns_a_record_on_launch    = optional(bool, false)\n      ipv6_cidr_block                                = optional(string, \"\")\n      ipv6_native                                    = optional(bool, false)\n      map_customer_owned_ip_on_launch                = optional(bool, false)\n      map_public_ip_on_launch                        = optional(bool, true)\n      outpost_arn                                    = optional(string, \"\")\n      private_dns_hostname_type_on_launch            = optional(string, \"ip-name\") #  The type of hostnames to assign to instances in the subnet at launch. For IPv6-only subnets, an instance DNS name must be based on the instance ID. For dual-stack and IPv4-only subnets, you can specify whether DNS names use the instance IPv4 address or the instance ID . Valid values:  ip-name, resource-name.\n      nacl = optional(map(object({\n        egress          = string # true, false\n        rule_number     = string # ACL entries are processed in ascending order by rule number\n        rule_action     = string # allow | deny\n        from_port       = optional(string, \"\")\n        to_port         = optional(string, \"\")\n        icmp_code       = optional(string, \"\") # (Optional) ICMP protocol: The ICMP type. Required if specifying ICMP for the protocolE.g., -1\n        icmp_type       = optional(string, \"\") # (Optional) ICMP protocol: The ICMP code. Required if specifying ICMP for the protocolE.g., -1\n        protocol        = string               # A value of -1 means all protocols , tcp  - 6 ,\n        cidr_block      = optional(string, \"\") # The network range to allow or deny, in CIDR notation (for example 172.16.0.0/24 ).\n        ipv6_cidr_block = optional(string, \"\")\n\n      })), {})\n\n    })))\n  })\n  default = {\n    public  = {}\n    private = {}\n  }\n\n  validation {\n    condition = alltrue([\n      for _, subnet in coalesce(var.subnets.private, {}) : contains([\"AZ\", \"SINGLE\", \"DEFAULT\", \"SUBNET\", \"NONE\"], subnet.nat_gateway)\n    ])\n    error_message = \"nat_gateway must be one of: AZ, SINGLE, DEFAULT, SUBNET, NONE.\"\n  }\n\n  validation {\n    condition = alltrue([\n      for _, subnet in coalesce(var.subnets.private, {}) : can(cidrsubnet(subnet.cidr, 0, 0))\n    ])\n    error_message = \"Invalid CIDR block format. CIDR block must be a valid subnet, e.g., 10.10.16.0/24.\"\n  }\n\n  validation {\n    condition = alltrue([\n      for _, subnet in coalesce(var.subnets.private, {}) : contains([\"ip-name\", \"resource-name\"], subnet.private_dns_hostname_type_on_launch)\n    ])\n    error_message = \"Invalid value for private_dns_hostname_type_on_launch. Must be one of: ip-name, resource-name.\"\n  }\n\n  validation {\n    condition = alltrue([\n      for _, subnet in coalesce(var.subnets.public, {}) : can(cidrsubnet(subnet.cidr, 0, 0))\n    ])\n    error_message = \"Invalid CIDR block format. CIDR block must be a valid subnet, e.g., 10.10.16.0/24.\"\n  }\n\n  validation {\n    condition = alltrue([\n      for _, subnet in coalesce(var.subnets.public, {}) : contains([\"ip-name\", \"resource-name\"], subnet.private_dns_hostname_type_on_launch)\n    ])\n    error_message = \"Invalid value for private_dns_hostname_type_on_launch. Must be one of: ip-name, resource-name.\"\n  }\n}\n\nvariable \"existing_eip_ids_az\" {\n  description = \"A map of existing Elastic IPs IDs to associate with the NAT Gateways where key is the AZ, value is the EIP ID\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition = alltrue([\n      for az, eip in var.existing_eip_ids_az : can(regex(\"^eipalloc-[0-9a-fA-F]{17}$\", eip))\n    ])\n    error_message = \"Each value in existing_eip_ids_az must be a valid Elastic IP ID (eipalloc-xxxxxxxxxxxxxxxxx).\"\n  }\n\n  validation {\n    condition = alltrue([\n      for az, eip in var.existing_eip_ids_az : can(regex(\"^[a-z]{2}-[a-z]+-[0-9]{1}[a-z]$\", az))\n    ])\n    error_message = \"Each key in existing_eip_ids_az must be a valid Availability Zone (e.g., eu-west-1a).\"\n  }\n}\n", "versions.tf": "terraform {\n  required_version = \"\u003e= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"\u003e= 5.46\"\n    }\n  }\n}\n", "vpc.tf": "resource \"aws_vpc\" \"default\" {\n  cidr_block           = var.vpc.cidr\n  enable_dns_support   = var.vpc.enable_dns_support\n  enable_dns_hostnames = var.vpc.enable_dns_hostnames\n  tags                 = merge(var.tags_default, { \"Name\" = var.vpc.name }, var.vpc.tags)\n}\n\nresource \"aws_internet_gateway\" \"default\" {\n  vpc_id = aws_vpc.default.id\n  tags   = merge(var.tags_default, { \"Name\" = var.vpc.name }, var.vpc.tags)\n}\n\nresource \"aws_vpc_ipv4_cidr_block_association\" \"default\" {\n  for_each   = toset(var.vpc.secondary_cidr_blocks)\n  vpc_id     = aws_vpc.default.id\n  cidr_block = each.value\n}\n\nresource \"aws_network_acl_rule\" \"default\" {\n  for_each        = var.vpc.nacl_default\n  network_acl_id  = aws_vpc.default.default_network_acl_id\n  rule_number     = each.value.rule_number\n  egress          = each.value.egress\n  protocol        = each.value.protocol\n  rule_action     = each.value.rule_action\n  cidr_block      = each.value.cidr_block != \"\" ? each.value.cidr_block : null\n  from_port       = each.value.from_port != \"\" ? each.value.from_port : null\n  to_port         = each.value.to_port != \"\" ? each.value.to_port : null\n  ipv6_cidr_block = each.value.ipv6_cidr_block != \"\" ? each.value.ipv6_cidr_block : null\n}\n\n\nlocals {\n  # Check if any DHCP option is defined (for strings and lists)\n  dhcp_options_defined = (\n    var.vpc.dhcp_options.domain_name != \"\" ||\n    length(var.vpc.dhcp_options.domain_name_servers) \u003e 0 ||\n    length(var.vpc.dhcp_options.ntp_servers) \u003e 0 ||\n    length(var.vpc.dhcp_options.netbios_name_servers) \u003e 0 ||\n    var.vpc.dhcp_options.netbios_node_type != \"\" ||\n    var.vpc.dhcp_options.ipv6_address_preferred_lease_time != \"140\"\n  )\n}\n\nresource \"aws_vpc_dhcp_options\" \"default\" {\n  for_each                          = local.dhcp_options_defined ? toset([\"enable\"]) : toset([])\n  domain_name                       = var.vpc.dhcp_options.domain_name != \"\" ? var.vpc.dhcp_options.domain_name : null\n  domain_name_servers               = length(var.vpc.dhcp_options.domain_name_servers) \u003e 0 ? var.vpc.dhcp_options.domain_name_servers : null\n  ntp_servers                       = length(var.vpc.dhcp_options.ntp_servers) \u003e 0 ? var.vpc.dhcp_options.ntp_servers : null\n  netbios_name_servers              = length(var.vpc.dhcp_options.netbios_name_servers) \u003e 0 ? var.vpc.dhcp_options.netbios_name_servers : null\n  netbios_node_type                 = var.vpc.dhcp_options.netbios_node_type != \"\" ? var.vpc.dhcp_options.netbios_node_type : null\n  ipv6_address_preferred_lease_time = var.vpc.dhcp_options.ipv6_address_preferred_lease_time != \"140\" ? var.vpc.dhcp_options.ipv6_address_preferred_lease_time : null\n  tags                              = merge(var.tags_default, { \"Name\" = var.vpc.name }, var.vpc.tags)\n}\n\nresource \"aws_vpc_dhcp_options_association\" \"default\" {\n  for_each        = local.dhcp_options_defined ? toset([\"enable\"]) : toset([])\n  vpc_id          = aws_vpc.default.id\n  dhcp_options_id = aws_vpc_dhcp_options.default[each.key].id\n}\n"}, "terraform_output": "Terraform timed out", "test_cases": [{"description": "Test that VPC infrastructure components exist after Terraform apply.", "name": "test_vpc_infrastructure_exists", "readable_name": "Vpc Infrastructure Exists"}, {"description": "Test that subnets are configured correctly according to specification.", "name": "test_subnet_configuration_validation", "readable_name": "Subnet Configuration Validation"}, {"description": "Test the complete infrastructure discovery workflow.", "name": "test_infrastructure_discovery_workflow", "readable_name": "Infrastructure Discovery Workflow"}, {"description": "Test security group creation with proper tier isolation.", "name": "test_security_group_creation_and_rules", "readable_name": "Security Group Creation And Rules"}, {"description": "Test deploying a complete multi-tier application.", "name": "test_multi_tier_application_deployment", "readable_name": "Multi Tier Application Deployment"}, {"description": "Test comprehensive network connectivity validation.", "name": "test_network_connectivity_validation", "readable_name": "Network Connectivity Validation"}, {"description": "Test deploying applications across multiple availability zones for high availability.", "name": "test_high_availability_deployment_pattern", "readable_name": "High Availability Deployment Pattern"}, {"description": "Test NAT Gateway configuration for private subnet internet access.", "name": "test_nat_gateway_configuration", "readable_name": "Nat Gateway Configuration"}, {"description": "Test error handling and resilience of the network management system.", "name": "test_error_handling_and_resilience", "readable_name": "Error Handling And Resilience"}], "test_features": ["AWS SDK", "Assertions", "Fixtures"]}, {"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/d02637494b9688ec", "app_files": {"app.py": "import boto3\nimport json\nimport logging\nimport os\nimport time\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime, timedelta\n\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass TransactionProcessor:\n    \"\"\"A realistic transaction processing system using EventBridge and Lambda.\n    \n    This application simulates a financial transaction processing pipeline where:\n    1. Transaction events are published to EventBridge\n    2. Events matching EU location pattern (EUR-*) trigger Lambda processing\n    3. Lambda function processes transactions for fraud detection and compliance\n    4. Results are logged and can be queried\n    \"\"\"\n    \n    def __init__(self, endpoint_url: Optional[str] = None):\n        self.endpoint_url = endpoint_url or os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n        \n        # Initialize AWS clients\n        self.events_client = boto3.client(\n            \"events\",\n            endpoint_url=self.endpoint_url,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.lambda_client = boto3.client(\n            \"lambda\",\n            endpoint_url=self.endpoint_url,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.logs_client = boto3.client(\n            \"logs\",\n            endpoint_url=self.endpoint_url,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n    \n    def publish_transaction_event(self, transaction_data: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Publish a transaction event to EventBridge.\n        \n        Args:\n            transaction_data: Dictionary containing transaction details\n            \n        Returns:\n            Response from EventBridge put_events call\n        \"\"\"\n        event_entry = {\n            \"Source\": \"custom.myApp\",\n            \"DetailType\": \"transaction\",\n            \"Detail\": json.dumps(transaction_data),\n            \"Time\": datetime.utcnow()\n        }\n        \n        try:\n            response = self.events_client.put_events(\n                Entries=[event_entry]\n            )\n            logger.info(f\"Published transaction event: {transaction_data.get(\u0027transactionId\u0027)}\")\n            return response\n        except Exception as e:\n            logger.error(f\"Failed to publish event: {e}\")\n            raise\n    \n    def batch_publish_transactions(self, transactions: List[Dict[str, Any]]) -\u003e List[Dict[str, Any]]:\n        \"\"\"Publish multiple transaction events in batch.\n        \n        Args:\n            transactions: List of transaction dictionaries\n            \n        Returns:\n            List of responses from EventBridge\n        \"\"\"\n        responses = []\n        \n        # EventBridge supports up to 10 events per batch\n        batch_size = 10\n        \n        for i in range(0, len(transactions), batch_size):\n            batch = transactions[i:i + batch_size]\n            \n            entries = []\n            for transaction in batch:\n                entry = {\n                    \"Source\": \"custom.myApp\",\n                    \"DetailType\": \"transaction\",\n                    \"Detail\": json.dumps(transaction),\n                    \"Time\": datetime.utcnow()\n                }\n                entries.append(entry)\n            \n            try:\n                response = self.events_client.put_events(Entries=entries)\n                responses.append(response)\n                logger.info(f\"Published batch of {len(entries)} transactions\")\n            except Exception as e:\n                logger.error(f\"Failed to publish batch: {e}\")\n                raise\n        \n        return responses\n    \n    def invoke_lambda_directly(self, payload: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Directly invoke the Lambda function for testing.\n        \n        Args:\n            payload: Event payload to send to Lambda\n            \n        Returns:\n            Lambda function response\n        \"\"\"\n        try:\n            response = self.lambda_client.invoke(\n                FunctionName=\"ConsumerFunction\",\n                InvocationType=\"RequestResponse\",\n                Payload=json.dumps(payload)\n            )\n            \n            result = json.loads(response[\u0027Payload\u0027].read().decode(\u0027utf-8\u0027))\n            logger.info(f\"Lambda invocation successful: {result}\")\n            return result\n        except Exception as e:\n            logger.error(f\"Lambda invocation failed: {e}\")\n            raise\n    \n    def get_lambda_logs(self, minutes_back: int = 10) -\u003e List[str]:\n        \"\"\"Retrieve recent Lambda function logs.\n        \n        Args:\n            minutes_back: How many minutes back to search for logs\n            \n        Returns:\n            List of log messages\n        \"\"\"\n        log_group_name = \"/aws/lambda/ConsumerFunction\"\n        \n        try:\n            # Get log streams\n            streams_response = self.logs_client.describe_log_streams(\n                logGroupName=log_group_name,\n                orderBy=\"LastEventTime\",\n                descending=True,\n                limit=5\n            )\n            \n            log_messages = []\n            \n            # Get recent log events\n            start_time = int((datetime.utcnow() - timedelta(minutes=minutes_back)).timestamp() * 1000)\n            \n            for stream in streams_response.get(\u0027logStreams\u0027, []):\n                try:\n                    events_response = self.logs_client.get_log_events(\n                        logGroupName=log_group_name,\n                        logStreamName=stream[\u0027logStreamName\u0027],\n                        startTime=start_time\n                    )\n                    \n                    for event in events_response.get(\u0027events\u0027, []):\n                        log_messages.append(event[\u0027message\u0027].strip())\n                        \n                except Exception as stream_error:\n                    logger.warning(f\"Could not get events from stream {stream[\u0027logStreamName\u0027]}: {stream_error}\")\n                    continue\n            \n            return log_messages\n            \n        except Exception as e:\n            logger.warning(f\"Could not retrieve logs: {e}\")\n            return []\n    \n    def check_infrastructure(self) -\u003e Dict[str, bool]:\n        \"\"\"Check if all required AWS resources exist.\n        \n        Returns:\n            Dictionary showing status of each resource\n        \"\"\"\n        status = {}\n        \n        # Check Lambda function\n        try:\n            self.lambda_client.get_function(FunctionName=\"ConsumerFunction\")\n            status[\u0027lambda_function\u0027] = True\n        except Exception:\n            status[\u0027lambda_function\u0027] = False\n        \n        # Check EventBridge rule\n        try:\n            rules = self.events_client.list_rules(NamePrefix=\"eventbridge-lambda-\")\n            status[\u0027eventbridge_rule\u0027] = len(rules.get(\u0027Rules\u0027, [])) \u003e 0\n        except Exception:\n            status[\u0027eventbridge_rule\u0027] = False\n        \n        return status\n    \n    def simulate_fraud_detection_workflow(self) -\u003e Dict[str, Any]:\n        \"\"\"Simulate a complete fraud detection workflow.\n        \n        This creates a realistic scenario where:\n        1. Multiple transactions are processed\n        2. EU transactions trigger Lambda processing (due to EUR- location prefix)\n        3. High-value transactions are flagged for review\n        4. Processing results are collected\n        \n        Returns:\n            Summary of the workflow execution\n        \"\"\"\n        # Sample transactions with different risk profiles\n        transactions = [\n            {\n                \"transactionId\": \"txn-001\",\n                \"amount\": 150.00,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-AMSTERDAM\",\n                \"merchantId\": \"merchant-retail-001\",\n                \"merchantCategory\": \"grocery\",\n                \"timestamp\": datetime.utcnow().isoformat(),\n                \"customerId\": \"customer-123\"\n            },\n            {\n                \"transactionId\": \"txn-002\",\n                \"amount\": 5000.00,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-BERLIN\",\n                \"merchantId\": \"merchant-luxury-002\",\n                \"merchantCategory\": \"jewelry\",\n                \"timestamp\": datetime.utcnow().isoformat(),\n                \"customerId\": \"customer-456\"\n            },\n            {\n                \"transactionId\": \"txn-003\",\n                \"amount\": 25.50,\n                \"currency\": \"USD\",\n                \"location\": \"USD-NEWYORK\",\n                \"merchantId\": \"merchant-cafe-003\",\n                \"merchantCategory\": \"restaurant\",\n                \"timestamp\": datetime.utcnow().isoformat(),\n                \"customerId\": \"customer-789\"\n            },\n            {\n                \"transactionId\": \"txn-004\",\n                \"amount\": 15000.00,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-ZURICH\",\n                \"merchantId\": \"merchant-auto-004\",\n                \"merchantCategory\": \"automotive\",\n                \"timestamp\": datetime.utcnow().isoformat(),\n                \"customerId\": \"customer-101\"\n            }\n        ]\n        \n        logger.info(\"Starting fraud detection workflow simulation...\")\n        \n        # Publish all transactions\n        publish_responses = self.batch_publish_transactions(transactions)\n        \n        # Wait for processing\n        time.sleep(5)\n        \n        # Get processing logs\n        logs = self.get_lambda_logs(minutes_back=2)\n        \n        # Count expected EU transactions (should have triggered Lambda)\n        eu_transactions = [t for t in transactions if t[\u0027location\u0027].startswith(\u0027EUR-\u0027)]\n        \n        workflow_summary = {\n            \"total_transactions_published\": len(transactions),\n            \"eu_transactions_count\": len(eu_transactions),\n            \"publish_responses\": publish_responses,\n            \"processing_logs\": logs,\n            \"high_value_transactions\": [\n                t for t in eu_transactions if t[\u0027amount\u0027] \u003e 1000\n            ]\n        }\n        \n        logger.info(f\"Workflow completed. EU transactions: {len(eu_transactions)}, Logs captured: {len(logs)}\")\n        \n        return workflow_summary\n    \n    def create_transaction(self, customer_id: str, amount: float, location: str, \n                          merchant_id: str, merchant_category: str = \"general\") -\u003e Dict[str, Any]:\n        \"\"\"Create and publish a single transaction.\n        \n        Args:\n            customer_id: Customer identifier\n            amount: Transaction amount\n            location: Transaction location (format: CURRENCY-CITY)\n            merchant_id: Merchant identifier\n            merchant_category: Category of merchant\n            \n        Returns:\n            Transaction data that was published\n        \"\"\"\n        transaction = {\n            \"transactionId\": f\"txn-{int(time.time())}\",\n            \"amount\": amount,\n            \"currency\": location.split(\u0027-\u0027)[0],\n            \"location\": location,\n            \"merchantId\": merchant_id,\n            \"merchantCategory\": merchant_category,\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"customerId\": customer_id\n        }\n        \n        self.publish_transaction_event(transaction)\n        return transaction", "conftest.py": "import pytest\nimport boto3\nimport os\nimport json\nfrom typing import Generator\n\n\n@pytest.fixture(scope=\"session\")\ndef aws_credentials():\n    \"\"\"Set up AWS credentials for LocalStack.\"\"\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"test\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"test\"\n    os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n\n\n@pytest.fixture(scope=\"session\")\ndef localstack_endpoint() -\u003e str:\n    \"\"\"Get LocalStack endpoint URL.\"\"\"\n    return os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n\n\n@pytest.fixture(scope=\"session\")\ndef lambda_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create Lambda client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"lambda\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n\n@pytest.fixture(scope=\"session\")\ndef events_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create EventBridge client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"events\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n\n@pytest.fixture(scope=\"session\")\ndef iam_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create IAM client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"iam\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n\n@pytest.fixture(scope=\"session\")\ndef cloudwatch_logs_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create CloudWatch Logs client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"logs\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n\n@pytest.fixture(scope=\"function\")\ndef sample_transaction_events():\n    \"\"\"Sample transaction events for testing.\"\"\"\n    return [\n        {\n            \"version\": \"0\",\n            \"id\": \"test-event-1\",\n            \"detail-type\": \"transaction\",\n            \"source\": \"custom.myApp\",\n            \"account\": \"123456789012\",\n            \"time\": \"2023-01-01T12:00:00Z\",\n            \"region\": \"us-east-1\",\n            \"detail\": {\n                \"transactionId\": \"txn-001\",\n                \"amount\": 1500.00,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-PARIS\",\n                \"merchantId\": \"merchant-123\",\n                \"timestamp\": \"2023-01-01T12:00:00Z\"\n            }\n        },\n        {\n            \"version\": \"0\",\n            \"id\": \"test-event-2\",\n            \"detail-type\": \"transaction\",\n            \"source\": \"custom.myApp\",\n            \"account\": \"123456789012\",\n            \"time\": \"2023-01-01T12:05:00Z\",\n            \"region\": \"us-east-1\",\n            \"detail\": {\n                \"transactionId\": \"txn-002\",\n                \"amount\": 250.75,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-LONDON\",\n                \"merchantId\": \"merchant-456\",\n                \"timestamp\": \"2023-01-01T12:05:00Z\"\n            }\n        },\n        {\n            \"version\": \"0\",\n            \"id\": \"test-event-3\",\n            \"detail-type\": \"transaction\",\n            \"source\": \"custom.myApp\",\n            \"account\": \"123456789012\",\n            \"time\": \"2023-01-01T12:10:00Z\",\n            \"region\": \"us-east-1\",\n            \"detail\": {\n                \"transactionId\": \"txn-003\",\n                \"amount\": 5000.00,\n                \"currency\": \"USD\",\n                \"location\": \"USD-NEWYORK\",\n                \"merchantId\": \"merchant-789\",\n                \"timestamp\": \"2023-01-01T12:10:00Z\"\n            }\n        }\n    ]", "requirements.txt": "boto3\u003e=1.34.0\npytest\u003e=7.4.0\npytest-asyncio\u003e=0.21.0\ntyping-extensions\u003e=4.8.0", "test_app.py": "import pytest\nimport json\nimport time\nfrom datetime import datetime\nfrom typing import Dict, Any\n\nfrom app import TransactionProcessor\n\n\nclass TestTransactionProcessor:\n    \"\"\"Integration tests for the transaction processing system.\"\"\"\n    \n    @pytest.fixture\n    def processor(self, localstack_endpoint):\n        \"\"\"Create a TransactionProcessor instance.\"\"\"\n        return TransactionProcessor(endpoint_url=localstack_endpoint)\n    \n    def test_infrastructure_exists(self, processor):\n        \"\"\"Test that all required AWS resources exist after Terraform deployment.\"\"\"\n        status = processor.check_infrastructure()\n        \n        assert status[\u0027lambda_function\u0027] is True, \"Lambda function \u0027ConsumerFunction\u0027 should exist\"\n        assert status[\u0027eventbridge_rule\u0027] is True, \"EventBridge rule should exist\"\n    \n    def test_lambda_function_properties(self, processor, lambda_client):\n        \"\"\"Test Lambda function configuration and properties.\"\"\"\n        response = lambda_client.get_function(FunctionName=\"ConsumerFunction\")\n        \n        config = response[\u0027Configuration\u0027]\n        assert config[\u0027FunctionName\u0027] == \"ConsumerFunction\"\n        assert config[\u0027Runtime\u0027] == \"nodejs24.x\"\n        assert config[\u0027Handler\u0027] == \"app.handler\"\n        assert \u0027Role\u0027 in config\n        \n        # Test function can be invoked\n        test_event = {\n            \"version\": \"0\",\n            \"id\": \"test-event\",\n            \"detail-type\": \"transaction\",\n            \"source\": \"custom.myApp\",\n            \"detail\": {\n                \"transactionId\": \"test-001\",\n                \"amount\": 100.0,\n                \"location\": \"EUR-TEST\"\n            }\n        }\n        \n        result = processor.invoke_lambda_directly(test_event)\n        assert result is not None\n    \n    def test_eventbridge_rule_configuration(self, processor, events_client):\n        \"\"\"Test EventBridge rule is configured correctly.\"\"\"\n        rules = events_client.list_rules(NamePrefix=\"eventbridge-lambda-\")\n        \n        assert len(rules[\u0027Rules\u0027]) \u003e 0, \"Should have at least one EventBridge rule\"\n        \n        rule = rules[\u0027Rules\u0027][0]\n        event_pattern = json.loads(rule[\u0027EventPattern\u0027])\n        \n        # Verify event pattern matches Terraform configuration\n        assert event_pattern[\u0027detail-type\u0027] == [\u0027transaction\u0027]\n        assert event_pattern[\u0027source\u0027] == [\u0027custom.myApp\u0027]\n        assert \u0027detail\u0027 in event_pattern\n        assert \u0027location\u0027 in event_pattern[\u0027detail\u0027]\n        assert event_pattern[\u0027detail\u0027][\u0027location\u0027][0][\u0027prefix\u0027] == \u0027EUR-\u0027\n        \n        # Check rule targets\n        targets = events_client.list_targets_by_rule(Rule=rule[\u0027Name\u0027])\n        assert len(targets[\u0027Targets\u0027]) \u003e 0, \"Rule should have targets\"\n        \n        # Verify Lambda is a target\n        lambda_target = next((t for t in targets[\u0027Targets\u0027] if \u0027lambda\u0027 in t[\u0027Arn\u0027].lower()), None)\n        assert lambda_target is not None, \"Lambda should be a target of the rule\"\n    \n    def test_single_transaction_publishing(self, processor):\n        \"\"\"Test publishing a single transaction event.\"\"\"\n        transaction = {\n            \"transactionId\": \"test-single-001\",\n            \"amount\": 250.00,\n            \"currency\": \"EUR\",\n            \"location\": \"EUR-PARIS\",\n            \"merchantId\": \"merchant-001\",\n            \"timestamp\": datetime.utcnow().isoformat()\n        }\n        \n        response = processor.publish_transaction_event(transaction)\n        \n        assert \u0027Entries\u0027 in response\n        assert len(response[\u0027Entries\u0027]) == 1\n        assert response[\u0027Entries\u0027][0][\u0027EventId\u0027] is not None\n        assert response[\u0027FailedEntryCount\u0027] == 0\n    \n    def test_batch_transaction_publishing(self, processor, sample_transaction_events):\n        \"\"\"Test publishing multiple transactions in batch.\"\"\"\n        # Extract transaction details from sample events\n        transactions = [event[\u0027detail\u0027] for event in sample_transaction_events]\n        \n        responses = processor.batch_publish_transactions(transactions)\n        \n        assert len(responses) \u003e 0, \"Should have at least one batch response\"\n        \n        total_published = 0\n        total_failed = 0\n        \n        for response in responses:\n            total_published += len(response[\u0027Entries\u0027])\n            total_failed += response[\u0027FailedEntryCount\u0027]\n        \n        assert total_published == len(transactions), \"All transactions should be published\"\n        assert total_failed == 0, \"No transactions should fail\"\n    \n    def test_eu_transaction_filtering(self, processor):\n        \"\"\"Test that only EU transactions (EUR- prefix) trigger Lambda processing.\"\"\"\n        # Create transactions with different location prefixes\n        transactions = [\n            {\n                \"transactionId\": \"test-eu-001\",\n                \"amount\": 100.00,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-LONDON\",  # Should trigger Lambda\n                \"merchantId\": \"merchant-eu\",\n                \"timestamp\": datetime.utcnow().isoformat()\n            },\n            {\n                \"transactionId\": \"test-us-001\",\n                \"amount\": 200.00,\n                \"currency\": \"USD\",\n                \"location\": \"USD-NEWYORK\",  # Should NOT trigger Lambda\n                \"merchantId\": \"merchant-us\",\n                \"timestamp\": datetime.utcnow().isoformat()\n            },\n            {\n                \"transactionId\": \"test-eu-002\",\n                \"amount\": 300.00,\n                \"currency\": \"EUR\",\n                \"location\": \"EUR-BERLIN\",  # Should trigger Lambda\n                \"merchantId\": \"merchant-eu2\",\n                \"timestamp\": datetime.utcnow().isoformat()\n            }\n        ]\n        \n        # Publish transactions\n        processor.batch_publish_transactions(transactions)\n        \n        # Wait for processing\n        time.sleep(3)\n        \n        # Get logs to verify processing\n        logs = processor.get_lambda_logs(minutes_back=2)\n        \n        # Should have some log entries if EU transactions were processed\n        eu_transactions = [t for t in transactions if t[\u0027location\u0027].startswith(\u0027EUR-\u0027)]\n        \n        if len(eu_transactions) \u003e 0:\n            # If we have EU transactions, we should see some processing activity\n            # Note: In LocalStack, the actual filtering happens at EventBridge level\n            assert len(logs) \u003e= 0  # Logs may be empty in LocalStack, but no errors should occur\n    \n    def test_high_value_transaction_detection(self, processor):\n        \"\"\"Test detection and handling of high-value transactions.\"\"\"\n        high_value_transaction = {\n            \"transactionId\": \"test-highval-001\",\n            \"amount\": 10000.00,  # High value\n            \"currency\": \"EUR\",\n            \"location\": \"EUR-ZURICH\",\n            \"merchantId\": \"merchant-luxury\",\n            \"merchantCategory\": \"jewelry\",\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"customerId\": \"customer-vip\"\n        }\n        \n        response = processor.publish_transaction_event(high_value_transaction)\n        \n        assert response[\u0027FailedEntryCount\u0027] == 0\n        \n        # Test direct Lambda invocation with high-value transaction\n        test_event = {\n            \"version\": \"0\",\n            \"id\": \"high-value-test\",\n            \"detail-type\": \"transaction\",\n            \"source\": \"custom.myApp\",\n            \"detail\": high_value_transaction\n        }\n        \n        result = processor.invoke_lambda_directly(test_event)\n        # Lambda should process the event without errors\n        assert result is not None\n    \n    def test_complete_fraud_detection_workflow(self, processor):\n        \"\"\"Test the complete end-to-end fraud detection workflow.\"\"\"\n        workflow_result = processor.simulate_fraud_detection_workflow()\n        \n        # Verify workflow execution\n        assert workflow_result[\u0027total_transactions_published\u0027] \u003e 0\n        assert workflow_result[\u0027eu_transactions_count\u0027] \u003e 0\n        assert len(workflow_result[\u0027publish_responses\u0027]) \u003e 0\n        \n        # Check that high-value EU transactions were identified\n        high_value_txns = workflow_result[\u0027high_value_transactions\u0027]\n        assert len(high_value_txns) \u003e 0, \"Should identify high-value transactions\"\n        \n        # Verify all high-value transactions are indeed high-value and EU\n        for txn in high_value_txns:\n            assert txn[\u0027amount\u0027] \u003e 1000, \"High-value transaction should have amount \u003e 1000\"\n            assert txn[\u0027location\u0027].startswith(\u0027EUR-\u0027), \"High-value transactions should be EU transactions\"\n        \n        # Verify publishing was successful\n        for response in workflow_result[\u0027publish_responses\u0027]:\n            assert response[\u0027FailedEntryCount\u0027] == 0, \"No events should fail to publish\"\n    \n    def test_transaction_creation_helper(self, processor):\n        \"\"\"Test the transaction creation helper method.\"\"\"\n        transaction = processor.create_transaction(\n            customer_id=\"test-customer-001\",\n            amount=500.00,\n            location=\"EUR-MILAN\",\n            merchant_id=\"merchant-fashion\",\n            merchant_category=\"clothing\"\n        )\n        \n        assert transaction[\u0027customerId\u0027] == \"test-customer-001\"\n        assert transaction[\u0027amount\u0027] == 500.00\n        assert transaction[\u0027location\u0027] == \"EUR-MILAN\"\n        assert transaction[\u0027currency\u0027] == \"EUR\"  # Derived from location\n        assert transaction[\u0027merchantId\u0027] == \"merchant-fashion\"\n        assert transaction[\u0027merchantCategory\u0027] == \"clothing\"\n        assert \u0027transactionId\u0027 in transaction\n        assert \u0027timestamp\u0027 in transaction\n    \n    def test_error_handling_invalid_transaction(self, processor):\n        \"\"\"Test error handling with invalid transaction data.\"\"\"\n        # Test with missing required fields\n        invalid_transaction = {\n            \"amount\": \"not-a-number\",  # Invalid amount\n            \"location\": \"\",  # Empty location\n        }\n        \n        # Should not raise exception, but may produce warnings in logs\n        try:\n            processor.publish_transaction_event(invalid_transaction)\n        except Exception:\n            # If it does raise an exception, that\u0027s also acceptable behavior\n            pass\n    \n    def test_lambda_invocation_with_edge_cases(self, processor):\n        \"\"\"Test Lambda function with edge case scenarios.\"\"\"\n        edge_cases = [\n            # Zero amount transaction\n            {\n                \"version\": \"0\",\n                \"detail-type\": \"transaction\",\n                \"source\": \"custom.myApp\",\n                \"detail\": {\n                    \"transactionId\": \"edge-zero\",\n                    \"amount\": 0.00,\n                    \"location\": \"EUR-TEST\"\n                }\n            },\n            # Very large amount\n            {\n                \"version\": \"0\",\n                \"detail-type\": \"transaction\",\n                \"source\": \"custom.myApp\",\n                \"detail\": {\n                    \"transactionId\": \"edge-large\",\n                    \"amount\": 999999.99,\n                    \"location\": \"EUR-TEST\"\n                }\n            },\n            # Missing optional fields\n            {\n                \"version\": \"0\",\n                \"detail-type\": \"transaction\",\n                \"source\": \"custom.myApp\",\n                \"detail\": {\n                    \"transactionId\": \"edge-minimal\",\n                    \"amount\": 50.00,\n                    \"location\": \"EUR-TEST\"\n                    # Missing merchantId, timestamp, etc.\n                }\n            }\n        ]\n        \n        for i, test_case in enumerate(edge_cases):\n            try:\n                result = processor.invoke_lambda_directly(test_case)\n                assert result is not None, f\"Edge case {i} should return a result\"\n            except Exception as e:\n                # Log the exception but don\u0027t fail the test\n                # Lambda might handle edge cases differently\n                print(f\"Edge case {i} produced exception: {e}\")"}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/d02637494b9688ec", "duration": 9.768624, "failure_analysis": {"affected_resource": null, "affected_service": "Lambda", "aws_error_code": null, "category": "failed", "error_message": "expected runtime to be one of [\"nodejs\" \"nodejs4.3\" \"nodejs6.10\" \"nodejs8.10\" \"nodejs10.x\" \"nodejs12.x\" \"nodejs14.x\" \"nodejs16.x\" \"java8\" \"java8.al2\" \"java11\" \"python2.7\" \"python3.6\" \"python3.7\" \"python3.8\" \"python3.9\" \"dotnetcore1.0\" \"dotnetcore2.0\" \"dotnetcore2.1\" \"dotnetcore3.1\" \"dotnet6\" \"dotnet", "is_localstack_issue": true}, "hash": "d02637494b9688ec", "logs": "\nLocalStack version: 4.12.1.dev56\nLocalStack build date: 2026-01-09\nLocalStack build git hash: 0b2a5d188\n\nReady.\n", "name": "aws-samples/serverless-patterns/eventbridge-lambda-terraform", "original_format": null, "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["iam", "lambda", "cloudwatch"], "source_type": "github_repos", "source_url": "https://github.com/aws-samples/serverless-patterns/tree/main/eventbridge-lambda-terraform", "status": "FAILED", "terraform_files": {"main.tf": "terraform {\n  required_providers {\n\taws = {\n\t  source  = \"hashicorp/aws\"\n\t  version = \"~\u003e 5.0\"\n\t}\n  }\n\n  required_version = \"\u003e= 0.14.9\"\n}\n\nprovider \"aws\" {\n  profile = \"default\"\n  region  = \"us-east-1\"\n}\n\nresource \"aws_lambda_function\" \"lambda_function\" {\n  function_name    = \"ConsumerFunction\"\n  filename         = data.archive_file.lambda_zip_file.output_path\n  source_code_hash = data.archive_file.lambda_zip_file.output_base64sha256\n  handler          = \"app.handler\"\n  role             = aws_iam_role.lambda_iam_role.arn\n  runtime          = \"nodejs24.x\"\n}\n\ndata \"archive_file\" \"lambda_zip_file\" {\n  type        = \"zip\"\n  source_file = \"${path.module}/src/app.js\"\n  output_path = \"${path.module}/lambda.zip\"\n}\n\ndata \"aws_iam_policy\" \"lambda_basic_execution_role_policy\" {\n  name = \"AWSLambdaBasicExecutionRole\"\n}\n\nresource \"aws_iam_role\" \"lambda_iam_role\" {\n  name_prefix         = \"EventBridgeLambdaRole-\"\n\n  assume_role_policy = \u003c\u003cEOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n\t{\n\t  \"Action\": \"sts:AssumeRole\",\n\t  \"Principal\": {\n\t\t\"Service\": \"lambda.amazonaws.com\"\n\t  },\n\t  \"Effect\": \"Allow\",\n\t  \"Sid\": \"\"\n\t}\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy_attachment\" \"lambda_basic_execution\" {\n  role       = aws_iam_role.lambda_iam_role.name\n  policy_arn = data.aws_iam_policy.lambda_basic_execution_role_policy.arn\n}\n\nresource \"aws_cloudwatch_event_rule\" \"event_rule\" {\n\tname_prefix = \"eventbridge-lambda-\"\n  event_pattern = \u003c\u003cEOF\n{\n  \"detail-type\": [\"transaction\"],\n  \"source\": [\"custom.myApp\"],\n  \"detail\": {\n\t\"location\": [{\n\t  \"prefix\": \"EUR-\"\n\t}]\n  }\n}\nEOF\n}\n\nresource \"aws_cloudwatch_event_target\" \"target_lambda_function\" {\n  rule = aws_cloudwatch_event_rule.event_rule.name\n  arn  = aws_lambda_function.lambda_function.arn\n}\n\nresource \"aws_lambda_permission\" \"allow_cloudwatch\" {\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.lambda_function.function_name\n  principal     = \"events.amazonaws.com\"\n  source_arn    = aws_cloudwatch_event_rule.event_rule.arn\n}\n\noutput \"ConsumerFunction\" {\n  value       = aws_lambda_function.lambda_function.arn\n  description = \"ConsumerFunction function name\"\n}\n"}, "terraform_output": "Apply failed:\nSTDOUT: \u2577\n\u2502 Error: expected runtime to be one of [\"nodejs\" \"nodejs4.3\" \"nodejs6.10\" \"nodejs8.10\" \"nodejs10.x\" \"nodejs12.x\" \"nodejs14.x\" \"nodejs16.x\" \"java8\" \"java8.al2\" \"java11\" \"python2.7\" \"python3.6\" \"python3.7\" \"python3.8\" \"python3.9\" \"dotnetcore1.0\" \"dotnetcore2.0\" \"dotnetcore2.1\" \"dotnetcore3.1\" \"dotnet6\" \"dotnet8\" \"nodejs4.3-edge\" \"go1.x\" \"ruby2.5\" \"ruby2.7\" \"provided\" \"provided.al2\" \"nodejs18.x\" \"python3.10\" \"java17\" \"ruby3.2\" \"ruby3.3\" \"ruby3.4\" \"python3.11\" \"nodejs20.x\" \"provided.al2023\" \"python3.12\" \"java21\" \"python3.13\" \"nodejs22.x\"], got nodejs24.x\n\u2502 \n\u2502   with aws_lambda_function.lambda_function,\n\u2502   on main.tf line 23, in resource \"aws_lambda_function\" \"lambda_function\":\n\u2502   23:   runtime          = \"nodejs24.x\"\n\u2502 \n\u2575\n::error::Terraform exited with code 1.\n\nSTDERR: ", "test_cases": [{"description": "Test that all required AWS resources exist after Terraform deployment.", "name": "test_infrastructure_exists", "readable_name": "Infrastructure Exists"}, {"description": "Test Lambda function configuration and properties.", "name": "test_lambda_function_properties", "readable_name": "Lambda Function Properties"}, {"description": "Test EventBridge rule is configured correctly.", "name": "test_eventbridge_rule_configuration", "readable_name": "Eventbridge Rule Configuration"}, {"description": "Test publishing a single transaction event.", "name": "test_single_transaction_publishing", "readable_name": "Single Transaction Publishing"}, {"description": "Test publishing multiple transactions in batch.", "name": "test_batch_transaction_publishing", "readable_name": "Batch Transaction Publishing"}, {"description": "Test that only EU transactions (EUR- prefix) trigger Lambda processing.", "name": "test_eu_transaction_filtering", "readable_name": "Eu Transaction Filtering"}, {"description": "Test detection and handling of high-value transactions.", "name": "test_high_value_transaction_detection", "readable_name": "High Value Transaction Detection"}, {"description": "Test the complete end-to-end fraud detection workflow.", "name": "test_complete_fraud_detection_workflow", "readable_name": "Complete Fraud Detection Workflow"}, {"description": "Test the transaction creation helper method.", "name": "test_transaction_creation_helper", "readable_name": "Transaction Creation Helper"}, {"description": "Test error handling with invalid transaction data.", "name": "test_error_handling_invalid_transaction", "readable_name": "Error Handling Invalid Transaction"}, {"description": "Test Lambda function with edge case scenarios.", "name": "test_lambda_invocation_with_edge_cases", "readable_name": "Lambda Invocation With Edge Cases"}], "test_features": ["AWS SDK", "Assertions", "EventBridge", "Fixtures", "Lambda Invocation", "SNS Operations"]}, {"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/ad03f95fc72b1791", "app_files": {"app.py": "import json\nimport logging\nimport requests\nimport boto3\nimport os\nfrom typing import Dict, Any, List, Optional\nfrom decimal import Decimal\nfrom botocore.exceptions import ClientError\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass MovieCatalogService:\n    \"\"\"A movie catalog service that manages movies via API Gateway and DynamoDB.\"\"\"\n    \n    def __init__(self, localstack_endpoint: str = None):\n        self.endpoint_url = localstack_endpoint or os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n        self.region = \"us-east-1\"\n        \n        # Initialize AWS clients\n        self.dynamodb = boto3.resource(\n            \"dynamodb\",\n            endpoint_url=self.endpoint_url,\n            region_name=self.region,\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.apigateway = boto3.client(\n            \"apigatewayv2\",\n            endpoint_url=self.endpoint_url,\n            region_name=self.region,\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.lambda_client = boto3.client(\n            \"lambda\",\n            endpoint_url=self.endpoint_url,\n            region_name=self.region,\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.table_name = \"Movies\"\n        self.api_endpoint = None\n        \n    def discover_api_endpoint(self) -\u003e str:\n        \"\"\"Discover the API Gateway endpoint dynamically.\"\"\"\n        try:\n            # List APIs to find the one with the expected name pattern\n            response = self.apigateway.get_apis()\n            \n            for api in response.get(\u0027Items\u0027, []):\n                if \u0027apigw-http-lambda\u0027 in api[\u0027Name\u0027]:\n                    api_id = api[\u0027ApiId\u0027]\n                    # Construct the endpoint URL\n                    self.api_endpoint = f\"{self.endpoint_url.rstrip(\u0027/\u0027)}/{api_id}/movies\"\n                    logger.info(f\"Discovered API endpoint: {self.api_endpoint}\")\n                    return self.api_endpoint\n            \n            raise ValueError(\"API Gateway not found\")\n            \n        except Exception as e:\n            logger.error(f\"Error discovering API endpoint: {str(e)}\")\n            raise\n    \n    def add_movie_via_api(self, movie_data: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Add a movie through the API Gateway endpoint.\"\"\"\n        if not self.api_endpoint:\n            self.discover_api_endpoint()\n        \n        try:\n            # Convert any Decimal values to float for JSON serialization\n            json_data = json.loads(json.dumps(movie_data, default=self._decimal_converter))\n            \n            response = requests.post(\n                self.api_endpoint,\n                json=json_data,\n                headers={\"Content-Type\": \"application/json\"},\n                timeout=30\n            )\n            \n            logger.info(f\"API Response Status: {response.status_code}\")\n            logger.info(f\"API Response Body: {response.text}\")\n            \n            if response.status_code == 200:\n                return response.json()\n            else:\n                raise Exception(f\"API request failed with status {response.status_code}: {response.text}\")\n                \n        except Exception as e:\n            logger.error(f\"Error adding movie via API: {str(e)}\")\n            raise\n    \n    def get_movie_from_db(self, year: int, title: str) -\u003e Optional[Dict[str, Any]]:\n        \"\"\"Retrieve a movie directly from DynamoDB.\"\"\"\n        try:\n            table = self.dynamodb.Table(self.table_name)\n            response = table.get_item(\n                Key={\n                    \u0027year\u0027: year,\n                    \u0027title\u0027: title\n                }\n            )\n            \n            item = response.get(\u0027Item\u0027)\n            if item:\n                # Convert Decimal values to float for easier handling\n                return json.loads(json.dumps(item, default=self._decimal_converter))\n            return None\n            \n        except Exception as e:\n            logger.error(f\"Error retrieving movie from DB: {str(e)}\")\n            raise\n    \n    def get_movies_by_year(self, year: int) -\u003e List[Dict[str, Any]]:\n        \"\"\"Get all movies for a specific year.\"\"\"\n        try:\n            table = self.dynamodb.Table(self.table_name)\n            response = table.query(\n                KeyConditionExpression=boto3.dynamodb.conditions.Key(\u0027year\u0027).eq(year)\n            )\n            \n            items = response.get(\u0027Items\u0027, [])\n            return [json.loads(json.dumps(item, default=self._decimal_converter)) for item in items]\n            \n        except Exception as e:\n            logger.error(f\"Error getting movies by year: {str(e)}\")\n            raise\n    \n    def update_movie_rating(self, year: int, title: str, new_rating: float) -\u003e bool:\n        \"\"\"Update a movie\u0027s rating.\"\"\"\n        try:\n            table = self.dynamodb.Table(self.table_name)\n            \n            response = table.update_item(\n                Key={\n                    \u0027year\u0027: year,\n                    \u0027title\u0027: title\n                },\n                UpdateExpression=\"SET info.rating = :rating\",\n                ExpressionAttributeValues={\n                    \u0027:rating\u0027: Decimal(str(new_rating))\n                },\n                ReturnValues=\"UPDATED_NEW\"\n            )\n            \n            return \u0027Attributes\u0027 in response\n            \n        except Exception as e:\n            logger.error(f\"Error updating movie rating: {str(e)}\")\n            raise\n    \n    def bulk_import_movies(self, movies: List[Dict[str, Any]]) -\u003e Dict[str, int]:\n        \"\"\"Bulk import multiple movies via API.\"\"\"\n        results = {\n            \u0027success\u0027: 0,\n            \u0027failed\u0027: 0,\n            \u0027errors\u0027: []\n        }\n        \n        for movie in movies:\n            try:\n                self.add_movie_via_api(movie)\n                results[\u0027success\u0027] += 1\n                logger.info(f\"Successfully imported: {movie[\u0027title\u0027]} ({movie[\u0027year\u0027]})\")\n            except Exception as e:\n                results[\u0027failed\u0027] += 1\n                error_msg = f\"Failed to import {movie[\u0027title\u0027]} ({movie[\u0027year\u0027]}): {str(e)}\"\n                results[\u0027errors\u0027].append(error_msg)\n                logger.error(error_msg)\n        \n        return results\n    \n    def get_top_rated_movies(self, min_rating: float = 8.0) -\u003e List[Dict[str, Any]]:\n        \"\"\"Get all movies with rating above the threshold.\"\"\"\n        try:\n            table = self.dynamodb.Table(self.table_name)\n            response = table.scan(\n                FilterExpression=boto3.dynamodb.conditions.Attr(\u0027info.rating\u0027).gte(Decimal(str(min_rating)))\n            )\n            \n            items = response.get(\u0027Items\u0027, [])\n            # Sort by rating descending\n            sorted_items = sorted(items, key=lambda x: float(x.get(\u0027info\u0027, {}).get(\u0027rating\u0027, 0)), reverse=True)\n            \n            return [json.loads(json.dumps(item, default=self._decimal_converter)) for item in sorted_items]\n            \n        except Exception as e:\n            logger.error(f\"Error getting top rated movies: {str(e)}\")\n            raise\n    \n    def validate_movie_schema(self, movie_data: Dict[str, Any]) -\u003e bool:\n        \"\"\"Validate movie data structure.\"\"\"\n        required_fields = [\u0027year\u0027, \u0027title\u0027, \u0027info\u0027]\n        \n        for field in required_fields:\n            if field not in movie_data:\n                raise ValueError(f\"Missing required field: {field}\")\n        \n        if not isinstance(movie_data[\u0027year\u0027], int):\n            raise ValueError(\"Year must be an integer\")\n            \n        if not isinstance(movie_data[\u0027title\u0027], str) or not movie_data[\u0027title\u0027].strip():\n            raise ValueError(\"Title must be a non-empty string\")\n            \n        if not isinstance(movie_data[\u0027info\u0027], dict):\n            raise ValueError(\"Info must be a dictionary\")\n        \n        return True\n    \n    def get_movie_statistics(self) -\u003e Dict[str, Any]:\n        \"\"\"Get statistics about the movie collection.\"\"\"\n        try:\n            table = self.dynamodb.Table(self.table_name)\n            response = table.scan()\n            \n            items = response.get(\u0027Items\u0027, [])\n            \n            if not items:\n                return {\n                    \u0027total_movies\u0027: 0,\n                    \u0027average_rating\u0027: 0,\n                    \u0027genres\u0027: {},\n                    \u0027years\u0027: {}\n                }\n            \n            total_movies = len(items)\n            ratings = []\n            genres = {}\n            years = {}\n            \n            for item in items:\n                # Extract rating\n                rating = item.get(\u0027info\u0027, {}).get(\u0027rating\u0027)\n                if rating:\n                    ratings.append(float(rating))\n                \n                # Extract genre\n                genre = item.get(\u0027info\u0027, {}).get(\u0027genre\u0027)\n                if genre:\n                    genres[genre] = genres.get(genre, 0) + 1\n                \n                # Extract year\n                year = item.get(\u0027year\u0027)\n                if year:\n                    years[str(year)] = years.get(str(year), 0) + 1\n            \n            avg_rating = sum(ratings) / len(ratings) if ratings else 0\n            \n            return {\n                \u0027total_movies\u0027: total_movies,\n                \u0027average_rating\u0027: round(avg_rating, 2),\n                \u0027genres\u0027: genres,\n                \u0027years\u0027: years\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting movie statistics: {str(e)}\")\n            raise\n    \n    def _decimal_converter(self, obj):\n        \"\"\"Convert Decimal objects to float for JSON serialization.\"\"\"\n        if isinstance(obj, Decimal):\n            return float(obj)\n        raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n    \n    def health_check(self) -\u003e Dict[str, bool]:\n        \"\"\"Check the health of all components.\"\"\"\n        health = {\n            \u0027dynamodb\u0027: False,\n            \u0027api_gateway\u0027: False,\n            \u0027lambda\u0027: False\n        }\n        \n        # Check DynamoDB\n        try:\n            table = self.dynamodb.Table(self.table_name)\n            table.table_status\n            health[\u0027dynamodb\u0027] = True\n        except Exception:\n            pass\n        \n        # Check API Gateway\n        try:\n            self.discover_api_endpoint()\n            health[\u0027api_gateway\u0027] = True\n        except Exception:\n            pass\n        \n        # Check Lambda (by trying to list functions)\n        try:\n            response = self.lambda_client.list_functions()\n            lambda_functions = [f for f in response.get(\u0027Functions\u0027, []) if \u0027pattern-movies-post\u0027 in f[\u0027FunctionName\u0027]]\n            health[\u0027lambda\u0027] = len(lambda_functions) \u003e 0\n        except Exception:\n            pass\n        \n        return health", "conftest.py": "import pytest\nimport boto3\nimport os\nimport logging\nfrom typing import Dict, Any\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@pytest.fixture(scope=\"session\")\ndef aws_credentials():\n    \"\"\"Mocked AWS Credentials for LocalStack.\"\"\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"test\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"test\"\n    os.environ[\"AWS_SECURITY_TOKEN\"] = \"test\"\n    os.environ[\"AWS_SESSION_TOKEN\"] = \"test\"\n\n@pytest.fixture(scope=\"session\")\ndef localstack_endpoint():\n    \"\"\"LocalStack endpoint URL.\"\"\"\n    return os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n\n@pytest.fixture(scope=\"session\")\ndef dynamodb_client(aws_credentials, localstack_endpoint):\n    \"\"\"DynamoDB client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"dynamodb\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef dynamodb_resource(aws_credentials, localstack_endpoint):\n    \"\"\"DynamoDB resource configured for LocalStack.\"\"\"\n    return boto3.resource(\n        \"dynamodb\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef lambda_client(aws_credentials, localstack_endpoint):\n    \"\"\"Lambda client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"lambda\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef s3_client(aws_credentials, localstack_endpoint):\n    \"\"\"S3 client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"s3\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef apigateway_client(aws_credentials, localstack_endpoint):\n    \"\"\"API Gateway v2 client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"apigatewayv2\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef iam_client(aws_credentials, localstack_endpoint):\n    \"\"\"IAM client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"iam\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef cloudwatch_client(aws_credentials, localstack_endpoint):\n    \"\"\"CloudWatch Logs client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"logs\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef terraform_outputs():\n    \"\"\"Expected Terraform resource names and configuration.\"\"\"\n    return {\n        \"dynamodb_table\": \"Movies\",\n        \"s3_bucket_prefix\": \"apigw-lambda-ddb\",\n        \"lambda_name_prefix\": \"pattern-movies-post\",\n        \"apigw_name_prefix\": \"apigw-http-lambda\",\n        \"region\": \"us-east-1\"\n    }\n\n@pytest.fixture(scope=\"session\")\ndef sample_movies():\n    \"\"\"Sample movie data for testing.\"\"\"\n    return [\n        {\n            \"year\": 2023,\n            \"title\": \"The Amazing Adventure\",\n            \"info\": {\n                \"genre\": \"Action\",\n                \"director\": \"John Smith\",\n                \"rating\": 8.5,\n                \"plot\": \"An epic adventure story\"\n            }\n        },\n        {\n            \"year\": 2022,\n            \"title\": \"Comedy Night\",\n            \"info\": {\n                \"genre\": \"Comedy\",\n                \"director\": \"Jane Doe\",\n                \"rating\": 7.8,\n                \"plot\": \"A hilarious comedy\"\n            }\n        },\n        {\n            \"year\": 2024,\n            \"title\": \"Future Sci-Fi\",\n            \"info\": {\n                \"genre\": \"Sci-Fi\",\n                \"director\": \"Alex Johnson\",\n                \"rating\": 9.1,\n                \"plot\": \"A futuristic thriller\"\n            }\n        }\n    ]", "requirements.txt": "boto3==1.34.0\npytest==7.4.3\npytest-asyncio==0.21.1\nrequests==2.31.0\nbotocore==1.34.0", "test_app.py": "import pytest\nimport json\nimport time\nfrom typing import Dict, Any\nfrom decimal import Decimal\nfrom app import MovieCatalogService\n\nclass TestMovieCatalogService:\n    \"\"\"Integration tests for the Movie Catalog Service.\"\"\"\n    \n    @pytest.fixture(autouse=True)\n    def setup(self, localstack_endpoint, sample_movies):\n        \"\"\"Setup test instance and data.\"\"\"\n        self.service = MovieCatalogService(localstack_endpoint)\n        self.sample_movies = sample_movies\n        \n        # Small delay to ensure infrastructure is ready\n        time.sleep(2)\n    \n    def test_infrastructure_health_check(self):\n        \"\"\"Test that all infrastructure components are healthy and accessible.\"\"\"\n        health = self.service.health_check()\n        \n        assert health[\u0027dynamodb\u0027] is True, \"DynamoDB table should be accessible\"\n        assert health[\u0027api_gateway\u0027] is True, \"API Gateway should be accessible\"\n        assert health[\u0027lambda\u0027] is True, \"Lambda function should be accessible\"\n    \n    def test_discover_api_endpoint(self):\n        \"\"\"Test API Gateway endpoint discovery.\"\"\"\n        endpoint = self.service.discover_api_endpoint()\n        \n        assert endpoint is not None, \"Should discover API endpoint\"\n        assert \u0027movies\u0027 in endpoint, \"Endpoint should contain movies path\"\n        assert self.service.api_endpoint == endpoint, \"Should set instance endpoint\"\n    \n    def test_add_single_movie_via_api(self):\n        \"\"\"Test adding a single movie through API Gateway.\"\"\"\n        movie = self.sample_movies[0].copy()\n        \n        # Add movie via API\n        result = self.service.add_movie_via_api(movie)\n        \n        assert result is not None, \"Should return response\"\n        assert \u0027message\u0027 in result or \u0027statusCode\u0027 in result, \"Should have valid response structure\"\n        \n        # Verify movie was stored in DynamoDB\n        stored_movie = self.service.get_movie_from_db(movie[\u0027year\u0027], movie[\u0027title\u0027])\n        assert stored_movie is not None, \"Movie should be stored in database\"\n        assert stored_movie[\u0027year\u0027] == movie[\u0027year\u0027], \"Year should match\"\n        assert stored_movie[\u0027title\u0027] == movie[\u0027title\u0027], \"Title should match\"\n        assert stored_movie[\u0027info\u0027][\u0027genre\u0027] == movie[\u0027info\u0027][\u0027genre\u0027], \"Genre should match\"\n    \n    def test_bulk_movie_import(self):\n        \"\"\"Test bulk importing multiple movies.\"\"\"\n        results = self.service.bulk_import_movies(self.sample_movies)\n        \n        assert results[\u0027success\u0027] == len(self.sample_movies), f\"Should import all {len(self.sample_movies)} movies successfully\"\n        assert results[\u0027failed\u0027] == 0, \"Should have no failures\"\n        assert len(results[\u0027errors\u0027]) == 0, \"Should have no errors\"\n        \n        # Verify all movies are in database\n        for movie in self.sample_movies:\n            stored_movie = self.service.get_movie_from_db(movie[\u0027year\u0027], movie[\u0027title\u0027])\n            assert stored_movie is not None, f\"Movie {movie[\u0027title\u0027]} should be stored\"\n    \n    def test_movie_retrieval_and_querying(self):\n        \"\"\"Test retrieving and querying movies from the database.\"\"\"\n        # First, import test data\n        self.service.bulk_import_movies(self.sample_movies)\n        \n        # Test getting movies by year\n        movies_2023 = self.service.get_movies_by_year(2023)\n        assert len(movies_2023) \u003e 0, \"Should find movies from 2023\"\n        assert all(movie[\u0027year\u0027] == 2023 for movie in movies_2023), \"All movies should be from 2023\"\n        \n        # Test getting specific movie\n        specific_movie = self.service.get_movie_from_db(2022, \"Comedy Night\")\n        assert specific_movie is not None, \"Should find specific movie\"\n        assert specific_movie[\u0027info\u0027][\u0027genre\u0027] == \"Comedy\", \"Genre should match\"\n    \n    def test_movie_rating_update(self):\n        \"\"\"Test updating movie ratings.\"\"\"\n        # Import a movie first\n        movie = self.sample_movies[0].copy()\n        self.service.add_movie_via_api(movie)\n        \n        # Update rating\n        new_rating = 9.5\n        success = self.service.update_movie_rating(movie[\u0027year\u0027], movie[\u0027title\u0027], new_rating)\n        assert success is True, \"Rating update should succeed\"\n        \n        # Verify update\n        updated_movie = self.service.get_movie_from_db(movie[\u0027year\u0027], movie[\u0027title\u0027])\n        assert updated_movie is not None, \"Updated movie should exist\"\n        assert abs(updated_movie[\u0027info\u0027][\u0027rating\u0027] - new_rating) \u003c 0.01, \"Rating should be updated\"\n    \n    def test_top_rated_movies_filtering(self):\n        \"\"\"Test filtering movies by rating threshold.\"\"\"\n        # Import all test movies\n        self.service.bulk_import_movies(self.sample_movies)\n        \n        # Get top-rated movies (rating \u003e= 8.0)\n        top_movies = self.service.get_top_rated_movies(min_rating=8.0)\n        \n        assert len(top_movies) \u003e 0, \"Should find top-rated movies\"\n        for movie in top_movies:\n            rating = movie[\u0027info\u0027][\u0027rating\u0027]\n            assert rating \u003e= 8.0, f\"Movie {movie[\u0027title\u0027]} rating {rating} should be \u003e= 8.0\"\n        \n        # Verify sorting (highest rating first)\n        if len(top_movies) \u003e 1:\n            for i in range(len(top_movies) - 1):\n                current_rating = top_movies[i][\u0027info\u0027][\u0027rating\u0027]\n                next_rating = top_movies[i + 1][\u0027info\u0027][\u0027rating\u0027]\n                assert current_rating \u003e= next_rating, \"Movies should be sorted by rating descending\"\n    \n    def test_movie_statistics_calculation(self):\n        \"\"\"Test calculation of movie collection statistics.\"\"\"\n        # Import test movies\n        self.service.bulk_import_movies(self.sample_movies)\n        \n        stats = self.service.get_movie_statistics()\n        \n        assert stats[\u0027total_movies\u0027] == len(self.sample_movies), \"Total count should match imported movies\"\n        assert stats[\u0027average_rating\u0027] \u003e 0, \"Average rating should be calculated\"\n        assert isinstance(stats[\u0027genres\u0027], dict), \"Genres should be a dictionary\"\n        assert isinstance(stats[\u0027years\u0027], dict), \"Years should be a dictionary\"\n        \n        # Verify genre distribution\n        expected_genres = {movie[\u0027info\u0027][\u0027genre\u0027] for movie in self.sample_movies}\n        actual_genres = set(stats[\u0027genres\u0027].keys())\n        assert expected_genres.issubset(actual_genres), \"All genres should be represented\"\n        \n        # Verify year distribution\n        expected_years = {str(movie[\u0027year\u0027]) for movie in self.sample_movies}\n        actual_years = set(stats[\u0027years\u0027].keys())\n        assert expected_years.issubset(actual_years), \"All years should be represented\"\n    \n    def test_error_handling_invalid_movie_data(self):\n        \"\"\"Test error handling with invalid movie data.\"\"\"\n        # Test missing required fields\n        invalid_movie = {\"title\": \"Incomplete Movie\"}\n        \n        with pytest.raises(Exception):\n            self.service.add_movie_via_api(invalid_movie)\n        \n        # Test invalid year type\n        invalid_movie2 = {\n            \"year\": \"not_a_number\",\n            \"title\": \"Bad Year Movie\",\n            \"info\": {\"genre\": \"Drama\"}\n        }\n        \n        with pytest.raises(Exception):\n            self.service.add_movie_via_api(invalid_movie2)\n    \n    def test_movie_schema_validation(self):\n        \"\"\"Test movie data schema validation.\"\"\"\n        # Valid movie should pass\n        valid_movie = self.sample_movies[0]\n        assert self.service.validate_movie_schema(valid_movie) is True\n        \n        # Invalid movies should fail\n        invalid_cases = [\n            {\"title\": \"Missing Year\", \"info\": {}},  # Missing year\n            {\"year\": 2023, \"info\": {}},  # Missing title\n            {\"year\": 2023, \"title\": \"Missing Info\"},  # Missing info\n            {\"year\": \"2023\", \"title\": \"Bad Year\", \"info\": {}},  # Wrong year type\n            {\"year\": 2023, \"title\": \"\", \"info\": {}},  # Empty title\n            {\"year\": 2023, \"title\": \"Bad Info\", \"info\": \"not_dict\"},  # Wrong info type\n        ]\n        \n        for invalid_movie in invalid_cases:\n            with pytest.raises(ValueError):\n                self.service.validate_movie_schema(invalid_movie)\n    \n    def test_duplicate_movie_handling(self):\n        \"\"\"Test handling of duplicate movie entries.\"\"\"\n        movie = self.sample_movies[0].copy()\n        \n        # Add movie first time\n        result1 = self.service.add_movie_via_api(movie)\n        assert result1 is not None\n        \n        # Add same movie again (should update or handle gracefully)\n        movie[\u0027info\u0027][\u0027rating\u0027] = 9.9  # Modify rating\n        result2 = self.service.add_movie_via_api(movie)\n        assert result2 is not None\n        \n        # Verify movie exists with updated data\n        stored_movie = self.service.get_movie_from_db(movie[\u0027year\u0027], movie[\u0027title\u0027])\n        assert stored_movie is not None\n        assert abs(stored_movie[\u0027info\u0027][\u0027rating\u0027] - 9.9) \u003c 0.01, \"Should have updated rating\"\n    \n    def test_empty_database_statistics(self):\n        \"\"\"Test statistics calculation on empty database.\"\"\"\n        stats = self.service.get_movie_statistics()\n        \n        assert stats[\u0027total_movies\u0027] == 0, \"Empty database should have zero movies\"\n        assert stats[\u0027average_rating\u0027] == 0, \"Empty database should have zero average rating\"\n        assert stats[\u0027genres\u0027] == {}, \"Empty database should have no genres\"\n        assert stats[\u0027years\u0027] == {}, \"Empty database should have no years\"\n    \n    def test_nonexistent_movie_retrieval(self):\n        \"\"\"Test retrieving movies that don\u0027t exist.\"\"\"\n        # Try to get a movie that doesn\u0027t exist\n        movie = self.service.get_movie_from_db(1999, \"Nonexistent Movie\")\n        assert movie is None, \"Should return None for nonexistent movie\"\n        \n        # Try to get movies for a year with no movies\n        movies = self.service.get_movies_by_year(1900)\n        assert len(movies) == 0, \"Should return empty list for year with no movies\""}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/ad03f95fc72b1791", "duration": 11.441941, "failure_analysis": {"affected_resource": null, "affected_service": "Lambda", "aws_error_code": null, "category": "failed", "error_message": "expected runtime to be one of [\"nodejs\" \"nodejs4.3\" \"nodejs6.10\" \"nodejs8.10\" \"nodejs10.x\" \"nodejs12.x\" \"nodejs14.x\" \"nodejs16.x\" \"java8\" \"java8.al2\" \"java11\" \"python2.7\" \"python3.6\" \"python3.7\" \"python3.8\" \"python3.9\" \"dotnetcore1.0\" \"dotnetcore2.0\" \"dotnetcore2.1\" \"dotnetcore3.1\" \"dotnet6\" \"dotnet", "is_localstack_issue": true}, "hash": "ad03f95fc72b1791", "logs": "\nLocalStack version: 4.12.1.dev56\nLocalStack build date: 2026-01-09\nLocalStack build git hash: 0b2a5d188\n\nReady.\n", "name": "aws-samples/serverless-patterns/apigw-lambda-dynamodb-terraform", "original_format": null, "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["dynamodb", "cloudwatch", "lambda", "apigateway", "iam", "s3"], "source_type": "github_repos", "source_url": "https://github.com/aws-samples/serverless-patterns/tree/main/apigw-lambda-dynamodb-terraform", "status": "FAILED", "terraform_files": {"main.tf": "terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~\u003e 5.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~\u003e 3.1.0\"\n    }\n    archive = {\n      source  = \"hashicorp/archive\"\n      version = \"~\u003e 2.2.0\"\n    }\n  }\n\n  required_version = \"\u003e= 0.14.9\"\n}\n\nprovider \"aws\" {\n  profile = \"default\"\n  region = var.aws_region\n}\n\nresource \"random_string\" \"random\" {\n  length           = 4\n  special          = false\n}\n\nresource \"aws_dynamodb_table\" \"movie_table\" {\n  name           = var.dynamodb_table\n  billing_mode   = \"PROVISIONED\"\n  read_capacity  = 20\n  write_capacity = 20\n  hash_key       = \"year\"\n  range_key      = \"title\"\n\n  attribute {\n    name = \"year\"\n    type = \"N\"\n  }\n  \n  attribute {\n    name = \"title\"\n    type = \"S\"\n  }\n\n}\n\n#========================================================================\n// lambda setup\n#========================================================================\n\nresource \"aws_s3_bucket\" \"lambda_bucket\" {\n  bucket_prefix = var.s3_bucket_prefix\n  force_destroy = true\n}\n\nresource \"aws_s3_bucket_public_access_block\" \"private_bucket\" {\n  bucket = aws_s3_bucket.lambda_bucket.id\n\n  block_public_acls       = true\n  block_public_policy     = true\n  ignore_public_acls      = true\n  restrict_public_buckets = true\n}\n\ndata \"archive_file\" \"lambda_zip\" {\n  type = \"zip\"\n\n  source_dir  = \"${path.module}/src\"\n  output_path = \"${path.module}/src.zip\"\n}\n\nresource \"aws_s3_object\" \"this\" {\n  bucket = aws_s3_bucket.lambda_bucket.id\n\n  key    = \"src.zip\"\n  source = data.archive_file.lambda_zip.output_path\n\n  etag = filemd5(data.archive_file.lambda_zip.output_path)\n}\n\n//Define lambda function\nresource \"aws_lambda_function\" \"apigw_lambda_ddb\" {\n  function_name = \"${var.lambda_name}-${random_string.random.id}\"\n  description = \"serverlessland pattern\"\n\n  s3_bucket = aws_s3_bucket.lambda_bucket.id\n  s3_key    = aws_s3_object.this.key\n\n  runtime = \"python3.14\"\n  handler = \"app.lambda_handler\"\n\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  role = aws_iam_role.lambda_exec.arn\n  \n  environment {\n    variables = {\n      DDB_TABLE = var.dynamodb_table\n    }\n  }\n  depends_on = [aws_cloudwatch_log_group.lambda_logs]\n  \n}\n\nresource \"aws_cloudwatch_log_group\" \"lambda_logs\" {\n  name = \"/aws/lambda/${var.lambda_name}-${random_string.random.id}\"\n\n  retention_in_days = var.lambda_log_retention\n}\n\nresource \"aws_iam_role\" \"lambda_exec\" {\n  name = \"LambdaDdbPost\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Sid    = \"\"\n      Principal = {\n        Service = \"lambda.amazonaws.com\"\n      }\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_policy\" \"lambda_exec_role\" {\n  name = \"lambda-tf-pattern-ddb-post\"\n\n  policy = \u003c\u003cPOLICY\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"dynamodb:GetItem\",\n                \"dynamodb:PutItem\",\n                \"dynamodb:UpdateItem\"\n            ],\n            \"Resource\": \"arn:aws:dynamodb:*:*:table/${var.dynamodb_table}\"\n        },\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"logs:CreateLogGroup\",\n                \"logs:CreateLogStream\",\n                \"logs:PutLogEvents\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\nPOLICY\n}\n\nresource \"aws_iam_role_policy_attachment\" \"lambda_policy\" {\n  role       = aws_iam_role.lambda_exec.name\n  policy_arn = aws_iam_policy.lambda_exec_role.arn\n}\n\n#========================================================================\n// API Gateway section\n#========================================================================\n\nresource \"aws_apigatewayv2_api\" \"http_lambda\" {\n  name          = \"${var.apigw_name}-${random_string.random.id}\"\n  protocol_type = \"HTTP\"\n}\n\nresource \"aws_apigatewayv2_stage\" \"default\" {\n  api_id = aws_apigatewayv2_api.http_lambda.id\n\n  name        = \"$default\"\n  auto_deploy = true\n\n  access_log_settings {\n    destination_arn = aws_cloudwatch_log_group.api_gw.arn\n\n    format = jsonencode({\n      requestId               = \"$context.requestId\"\n      sourceIp                = \"$context.identity.sourceIp\"\n      requestTime             = \"$context.requestTime\"\n      protocol                = \"$context.protocol\"\n      httpMethod              = \"$context.httpMethod\"\n      resourcePath            = \"$context.resourcePath\"\n      routeKey                = \"$context.routeKey\"\n      status                  = \"$context.status\"\n      responseLength          = \"$context.responseLength\"\n      integrationErrorMessage = \"$context.integrationErrorMessage\"\n      }\n    )\n  }\n  depends_on = [aws_cloudwatch_log_group.api_gw]\n}\n\nresource \"aws_apigatewayv2_integration\" \"apigw_lambda\" {\n  api_id = aws_apigatewayv2_api.http_lambda.id\n\n  integration_uri    = aws_lambda_function.apigw_lambda_ddb.invoke_arn\n  integration_type   = \"AWS_PROXY\"\n  integration_method = \"POST\"\n}\n\nresource \"aws_apigatewayv2_route\" \"post\" {\n  api_id = aws_apigatewayv2_api.http_lambda.id\n\n  route_key = \"POST /movies\"\n  target    = \"integrations/${aws_apigatewayv2_integration.apigw_lambda.id}\"\n}\n\nresource \"aws_cloudwatch_log_group\" \"api_gw\" {\n  name = \"/aws/api_gw/${var.apigw_name}-${random_string.random.id}\"\n\n  retention_in_days = var.apigw_log_retention\n}\n\nresource \"aws_lambda_permission\" \"api_gw\" {\n  statement_id  = \"AllowExecutionFromAPIGateway\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.apigw_lambda_ddb.function_name\n  principal     = \"apigateway.amazonaws.com\"\n\n  source_arn = \"${aws_apigatewayv2_api.http_lambda.execution_arn}/*/*\"\n}\n", "outputs.tf": "# Output value definitions\n\noutput \"apigwy_url\" {\n  description = \"URL for API Gateway stage\"\n\n  value = aws_apigatewayv2_stage.default.invoke_url\n}\n\noutput \"lambda_log_group\" {\n  description = \"Name of the CloudWatch logs group for the lambda function\"\n\n  value = aws_cloudwatch_log_group.lambda_logs.id\n}\n\noutput \"apigwy_log_group\" {\n  description = \"Name of the CloudWatch logs group for the lambda function\"\n\n  value = aws_cloudwatch_log_group.api_gw.id\n}", "variables.tf": "# Input variable definitions\n\nvariable \"aws_region\" {\n  description = \"AWS region for all resources.\"\n\n  type    = string\n  default = \"us-east-1\"\n}\n\nvariable \"s3_bucket_prefix\" {\n  description = \"S3 bucket prefix\"\n  type = string\n  default = \"apigw-lambda-ddb\"\n  \n}\n\nvariable \"dynamodb_table\" {\n  description = \"name of the ddb table\"\n  type = string\n  default = \"Movies\"\n  \n}\n\nvariable \"lambda_name\" {\n  description = \"name of the lambda function\"\n  type = string\n  default = \"pattern-movies-post\"\n  \n}\n\nvariable \"apigw_name\" {\n  description = \"name of the lambda function\"\n  type = string\n  default = \"apigw-http-lambda\"\n  \n}\n\nvariable \"lambda_log_retention\" {\n  description = \"lambda log retention in days\"\n  type = number\n  default = 7\n}\n\nvariable \"apigw_log_retention\" {\n  description = \"api gwy log retention in days\"\n  type = number\n  default = 7\n}"}, "terraform_output": "Apply failed:\nSTDOUT: \u2577\n\u2502 Error: expected runtime to be one of [\"nodejs\" \"nodejs4.3\" \"nodejs6.10\" \"nodejs8.10\" \"nodejs10.x\" \"nodejs12.x\" \"nodejs14.x\" \"nodejs16.x\" \"java8\" \"java8.al2\" \"java11\" \"python2.7\" \"python3.6\" \"python3.7\" \"python3.8\" \"python3.9\" \"dotnetcore1.0\" \"dotnetcore2.0\" \"dotnetcore2.1\" \"dotnetcore3.1\" \"dotnet6\" \"dotnet8\" \"nodejs4.3-edge\" \"go1.x\" \"ruby2.5\" \"ruby2.7\" \"provided\" \"provided.al2\" \"nodejs18.x\" \"python3.10\" \"java17\" \"ruby3.2\" \"ruby3.3\" \"ruby3.4\" \"python3.11\" \"nodejs20.x\" \"provided.al2023\" \"python3.12\" \"java21\" \"python3.13\" \"nodejs22.x\"], got python3.14\n\u2502 \n\u2502   with aws_lambda_function.apigw_lambda_ddb,\n\u2502   on main.tf line 92, in resource \"aws_lambda_function\" \"apigw_lambda_ddb\":\n\u2502   92:   runtime = \"python3.14\"\n\u2502 \n\u2575\n::error::Terraform exited with code 1.\n\nSTDERR: ", "test_cases": [{"description": "Test that all infrastructure components are healthy and accessible.", "name": "test_infrastructure_health_check", "readable_name": "Infrastructure Health Check"}, {"description": "Test API Gateway endpoint discovery.", "name": "test_discover_api_endpoint", "readable_name": "Discover Api Endpoint"}, {"description": "Test adding a single movie through API Gateway.", "name": "test_add_single_movie_via_api", "readable_name": "Add Single Movie Via Api"}, {"description": "Test bulk importing multiple movies.", "name": "test_bulk_movie_import", "readable_name": "Bulk Movie Import"}, {"description": "Test retrieving and querying movies from the database.", "name": "test_movie_retrieval_and_querying", "readable_name": "Movie Retrieval And Querying"}, {"description": "Test updating movie ratings.", "name": "test_movie_rating_update", "readable_name": "Movie Rating Update"}, {"description": "Test filtering movies by rating threshold.", "name": "test_top_rated_movies_filtering", "readable_name": "Top Rated Movies Filtering"}, {"description": "Test calculation of movie collection statistics.", "name": "test_movie_statistics_calculation", "readable_name": "Movie Statistics Calculation"}, {"description": "Test error handling with invalid movie data.", "name": "test_error_handling_invalid_movie_data", "readable_name": "Error Handling Invalid Movie Data"}, {"description": "Test movie data schema validation.", "name": "test_movie_schema_validation", "readable_name": "Movie Schema Validation"}, {"description": "Test handling of duplicate movie entries.", "name": "test_duplicate_movie_handling", "readable_name": "Duplicate Movie Handling"}, {"description": "Test statistics calculation on empty database.", "name": "test_empty_database_statistics", "readable_name": "Empty Database Statistics"}, {"description": "Test retrieving movies that don\u0027t exist.", "name": "test_nonexistent_movie_retrieval", "readable_name": "Nonexistent Movie Retrieval"}], "test_features": ["AWS SDK", "Assertions", "DynamoDB Operations", "Fixtures"]}, {"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/331b83bdbfe63d75", "app_files": {"app.py": "import json\nimport boto3\nimport requests\nimport os\nimport logging\nimport time\nfrom datetime import datetime\nfrom typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, asdict\nimport uuid\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@dataclass\nclass User:\n    \"\"\"User data model for registration system.\"\"\"\n    email: str\n    name: str\n    company: str\n    role: str\n    registration_id: str = None\n    timestamp: str = None\n    \n    def __post_init__(self):\n        if not self.registration_id:\n            self.registration_id = str(uuid.uuid4())\n        if not self.timestamp:\n            self.timestamp = datetime.utcnow().isoformat()\n\nclass UserRegistrationService:\n    \"\"\"Service for handling user registrations through API Gateway and Lambda.\"\"\"\n    \n    def __init__(self, api_endpoint: str, localstack_endpoint: str = None):\n        self.api_endpoint = api_endpoint.rstrip(\u0027/\u0027)\n        self.localstack_endpoint = localstack_endpoint or os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n        \n        # Initialize AWS clients\n        self.lambda_client = boto3.client(\n            \"lambda\",\n            endpoint_url=self.localstack_endpoint,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.s3_client = boto3.client(\n            \"s3\",\n            endpoint_url=self.localstack_endpoint,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.logs_client = boto3.client(\n            \"logs\",\n            endpoint_url=self.localstack_endpoint,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n    \n    def register_user(self, user_data: Dict[str, str]) -\u003e Dict[str, Any]:\n        \"\"\"Register a new user through the API Gateway endpoint.\"\"\"\n        user = User(**user_data)\n        \n        payload = {\n            \"action\": \"register\",\n            \"user\": asdict(user)\n        }\n        \n        try:\n            response = requests.post(\n                f\"{self.api_endpoint}/register\",\n                json=payload,\n                headers={\"Content-Type\": \"application/json\"},\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                result = response.json()\n                logger.info(f\"User registered successfully: {user.email}\")\n                return result\n            else:\n                logger.error(f\"Registration failed: {response.status_code} - {response.text}\")\n                raise Exception(f\"Registration failed with status {response.status_code}\")\n                \n        except requests.RequestException as e:\n            logger.error(f\"Request failed: {str(e)}\")\n            raise\n    \n    def get_user(self, registration_id: str) -\u003e Dict[str, Any]:\n        \"\"\"Retrieve user information by registration ID.\"\"\"\n        try:\n            response = requests.get(\n                f\"{self.api_endpoint}/user/{registration_id}\",\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.json()\n            elif response.status_code == 404:\n                return None\n            else:\n                raise Exception(f\"Failed to retrieve user with status {response.status_code}\")\n                \n        except requests.RequestException as e:\n            logger.error(f\"Request failed: {str(e)}\")\n            raise\n    \n    def list_registrations(self, company: Optional[str] = None) -\u003e List[Dict[str, Any]]:\n        \"\"\"List all registrations, optionally filtered by company.\"\"\"\n        params = {}\n        if company:\n            params[\u0027company\u0027] = company\n            \n        try:\n            response = requests.get(\n                f\"{self.api_endpoint}/registrations\",\n                params=params,\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.json().get(\u0027registrations\u0027, [])\n            else:\n                raise Exception(f\"Failed to list registrations with status {response.status_code}\")\n                \n        except requests.RequestException as e:\n            logger.error(f\"Request failed: {str(e)}\")\n            raise\n    \n    def update_user_role(self, registration_id: str, new_role: str) -\u003e Dict[str, Any]:\n        \"\"\"Update a user\u0027s role.\"\"\"\n        payload = {\n            \"action\": \"update_role\",\n            \"registration_id\": registration_id,\n            \"new_role\": new_role\n        }\n        \n        try:\n            response = requests.put(\n                f\"{self.api_endpoint}/user/{registration_id}/role\",\n                json=payload,\n                headers={\"Content-Type\": \"application/json\"},\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.json()\n            else:\n                raise Exception(f\"Role update failed with status {response.status_code}\")\n                \n        except requests.RequestException as e:\n            logger.error(f\"Request failed: {str(e)}\")\n            raise\n    \n    def delete_registration(self, registration_id: str) -\u003e bool:\n        \"\"\"Delete a user registration.\"\"\"\n        try:\n            response = requests.delete(\n                f\"{self.api_endpoint}/user/{registration_id}\",\n                timeout=30\n            )\n            \n            return response.status_code == 200\n                \n        except requests.RequestException as e:\n            logger.error(f\"Request failed: {str(e)}\")\n            raise\n    \n    def get_registration_analytics(self) -\u003e Dict[str, Any]:\n        \"\"\"Get analytics about registrations.\"\"\"\n        try:\n            response = requests.get(\n                f\"{self.api_endpoint}/analytics\",\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.json()\n            else:\n                raise Exception(f\"Analytics request failed with status {response.status_code}\")\n                \n        except requests.RequestException as e:\n            logger.error(f\"Request failed: {str(e)}\")\n            raise\n    \n    def invoke_lambda_directly(self, function_name: str, payload: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Directly invoke the Lambda function for testing purposes.\"\"\"\n        try:\n            response = self.lambda_client.invoke(\n                FunctionName=function_name,\n                InvocationType=\u0027RequestResponse\u0027,\n                Payload=json.dumps(payload)\n            )\n            \n            result = json.loads(response[\u0027Payload\u0027].read().decode())\n            logger.info(f\"Lambda invoked successfully: {function_name}\")\n            return result\n            \n        except Exception as e:\n            logger.error(f\"Lambda invocation failed: {str(e)}\")\n            raise\n    \n    def check_s3_registration_backup(self, bucket_name: str) -\u003e List[str]:\n        \"\"\"Check if registration backups are being stored in S3.\"\"\"\n        try:\n            response = self.s3_client.list_objects_v2(\n                Bucket=bucket_name,\n                Prefix=\u0027registrations/\u0027\n            )\n            \n            if \u0027Contents\u0027 in response:\n                return [obj[\u0027Key\u0027] for obj in response[\u0027Contents\u0027]]\n            else:\n                return []\n                \n        except Exception as e:\n            logger.error(f\"S3 check failed: {str(e)}\")\n            raise\n    \n    def get_lambda_logs(self, log_group: str, hours_back: int = 1) -\u003e List[Dict[str, Any]]:\n        \"\"\"Retrieve recent Lambda logs for debugging.\"\"\"\n        try:\n            # Calculate time range\n            end_time = int(time.time() * 1000)\n            start_time = end_time - (hours_back * 3600 * 1000)\n            \n            response = self.logs_client.filter_log_events(\n                logGroupName=log_group,\n                startTime=start_time,\n                endTime=end_time\n            )\n            \n            events = []\n            for event in response.get(\u0027events\u0027, []):\n                events.append({\n                    \u0027timestamp\u0027: datetime.fromtimestamp(event[\u0027timestamp\u0027] / 1000).isoformat(),\n                    \u0027message\u0027: event[\u0027message\u0027].strip()\n                })\n            \n            return events\n            \n        except Exception as e:\n            logger.error(f\"Log retrieval failed: {str(e)}\")\n            return []\n    \n    def health_check(self) -\u003e Dict[str, Any]:\n        \"\"\"Perform a health check on the API.\"\"\"\n        try:\n            response = requests.get(\n                f\"{self.api_endpoint}/health\",\n                timeout=10\n            )\n            \n            return {\n                \u0027status\u0027: \u0027healthy\u0027 if response.status_code == 200 else \u0027unhealthy\u0027,\n                \u0027status_code\u0027: response.status_code,\n                \u0027response_time_ms\u0027: response.elapsed.total_seconds() * 1000,\n                \u0027timestamp\u0027: datetime.utcnow().isoformat()\n            }\n            \n        except Exception as e:\n            return {\n                \u0027status\u0027: \u0027unhealthy\u0027,\n                \u0027error\u0027: str(e),\n                \u0027timestamp\u0027: datetime.utcnow().isoformat()\n            }\n    \n    def bulk_register_users(self, users: List[Dict[str, str]]) -\u003e Dict[str, Any]:\n        \"\"\"Register multiple users in a batch operation.\"\"\"\n        results = {\n            \u0027successful\u0027: [],\n            \u0027failed\u0027: [],\n            \u0027total_processed\u0027: len(users)\n        }\n        \n        for user_data in users:\n            try:\n                result = self.register_user(user_data)\n                results[\u0027successful\u0027].append({\n                    \u0027email\u0027: user_data[\u0027email\u0027],\n                    \u0027registration_id\u0027: result.get(\u0027registration_id\u0027)\n                })\n            except Exception as e:\n                results[\u0027failed\u0027].append({\n                    \u0027email\u0027: user_data[\u0027email\u0027],\n                    \u0027error\u0027: str(e)\n                })\n        \n        results[\u0027success_rate\u0027] = len(results[\u0027successful\u0027]) / len(users) if users else 0\n        return results", "conftest.py": "import pytest\nimport boto3\nimport os\nimport logging\nfrom typing import Generator\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n@pytest.fixture(scope=\"session\")\ndef aws_credentials():\n    \"\"\"Mocked AWS Credentials for LocalStack.\"\"\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"test\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"test\"\n    os.environ[\"AWS_SECURITY_TOKEN\"] = \"test\"\n    os.environ[\"AWS_SESSION_TOKEN\"] = \"test\"\n    os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n\n@pytest.fixture(scope=\"session\")\ndef localstack_endpoint() -\u003e str:\n    \"\"\"Get LocalStack endpoint URL.\"\"\"\n    return os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n\n@pytest.fixture(scope=\"session\")\ndef s3_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create S3 client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"s3\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n@pytest.fixture(scope=\"session\")\ndef lambda_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create Lambda client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"lambda\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n@pytest.fixture(scope=\"session\")\ndef apigateway_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create API Gateway v2 client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"apigatewayv2\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n@pytest.fixture(scope=\"session\")\ndef logs_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create CloudWatch Logs client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"logs\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n@pytest.fixture(scope=\"session\")\ndef iam_client(aws_credentials, localstack_endpoint) -\u003e Generator[boto3.client, None, None]:\n    \"\"\"Create IAM client for LocalStack.\"\"\"\n    client = boto3.client(\n        \"iam\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n    yield client\n\n@pytest.fixture(scope=\"session\")\ndef sample_user_data():\n    \"\"\"Sample user registration data for testing.\"\"\"\n    return {\n        \"users\": [\n            {\n                \"email\": \"john.doe@example.com\",\n                \"name\": \"John Doe\",\n                \"company\": \"Tech Corp\",\n                \"role\": \"developer\"\n            },\n            {\n                \"email\": \"jane.smith@example.com\",\n                \"name\": \"Jane Smith\",\n                \"company\": \"Data Inc\",\n                \"role\": \"analyst\"\n            },\n            {\n                \"email\": \"bob.wilson@example.com\",\n                \"name\": \"Bob Wilson\",\n                \"company\": \"Startup LLC\",\n                \"role\": \"manager\"\n            }\n        ]\n    }\n\n@pytest.fixture(scope=\"session\")\ndef terraform_outputs():\n    \"\"\"Expected Terraform resource names and configurations.\"\"\"\n    return {\n        \"lambda_function_name\": \"test_apigw_integration\",\n        \"s3_bucket_prefix\": \"apigw-http-api-lambda\",\n        \"api_name\": \"apigw-http-lambda\",\n        \"iam_role_name\": \"serverless_lambda\",\n        \"lambda_log_group\": \"/aws/lambda/test_apigw_integration\",\n        \"api_log_group_prefix\": \"/aws/api_gw/apigw-http-lambda\"\n    }", "requirements.txt": "boto3\u003e=1.26.0\npytest\u003e=7.0.0\npytest-asyncio\u003e=0.21.0\nrequests\u003e=2.28.0\ndataclasses-json\u003e=0.5.0\ntyping-extensions\u003e=4.0.0", "test_app.py": "import pytest\nimport json\nimport time\nfrom typing import Dict, List\nimport requests\nfrom app import UserRegistrationService, User\n\nclass TestInfrastructureProvisioning:\n    \"\"\"Test that all AWS resources are properly provisioned by Terraform.\"\"\"\n    \n    def test_lambda_function_exists(self, lambda_client, terraform_outputs):\n        \"\"\"Test that the Lambda function was created successfully.\"\"\"\n        function_name = terraform_outputs[\"lambda_function_name\"]\n        \n        try:\n            response = lambda_client.get_function(FunctionName=function_name)\n            assert response[\u0027Configuration\u0027][\u0027FunctionName\u0027] == function_name\n            assert response[\u0027Configuration\u0027][\u0027Runtime\u0027].startswith(\u0027python\u0027)\n            assert response[\u0027Configuration\u0027][\u0027Handler\u0027] == \u0027app.lambda_handler\u0027\n            assert response[\u0027Configuration\u0027][\u0027State\u0027] == \u0027Active\u0027\n        except lambda_client.exceptions.ResourceNotFoundException:\n            pytest.fail(f\"Lambda function {function_name} not found\")\n    \n    def test_s3_bucket_exists(self, s3_client, terraform_outputs):\n        \"\"\"Test that the S3 bucket for Lambda code exists.\"\"\"\n        # List all buckets and check for one with the correct prefix\n        response = s3_client.list_buckets()\n        bucket_prefix = terraform_outputs[\"s3_bucket_prefix\"]\n        \n        matching_buckets = [\n            bucket[\u0027Name\u0027] for bucket in response[\u0027Buckets\u0027]\n            if bucket[\u0027Name\u0027].startswith(bucket_prefix)\n        ]\n        \n        assert len(matching_buckets) \u003e 0, f\"No S3 bucket found with prefix {bucket_prefix}\"\n        \n        # Verify the Lambda source code is uploaded\n        bucket_name = matching_buckets[0]\n        objects = s3_client.list_objects_v2(Bucket=bucket_name)\n        \n        assert \u0027Contents\u0027 in objects, \"S3 bucket is empty\"\n        object_keys = [obj[\u0027Key\u0027] for obj in objects[\u0027Contents\u0027]]\n        assert \u0027source.zip\u0027 in object_keys, \"Lambda source code not found in S3\"\n    \n    def test_api_gateway_exists(self, apigateway_client, terraform_outputs):\n        \"\"\"Test that the API Gateway was created successfully.\"\"\"\n        api_name = terraform_outputs[\"api_name\"]\n        \n        response = apigateway_client.get_apis()\n        matching_apis = [\n            api for api in response[\u0027Items\u0027]\n            if api[\u0027Name\u0027] == api_name\n        ]\n        \n        assert len(matching_apis) == 1, f\"API Gateway {api_name} not found or multiple found\"\n        \n        api = matching_apis[0]\n        assert api[\u0027ProtocolType\u0027] == \u0027HTTP\u0027\n        assert \u0027ApiEndpoint\u0027 in api\n    \n    def test_iam_role_exists(self, iam_client, terraform_outputs):\n        \"\"\"Test that the IAM role for Lambda exists.\"\"\"\n        role_name = terraform_outputs[\"iam_role_name\"]\n        \n        try:\n            response = iam_client.get_role(RoleName=role_name)\n            assert response[\u0027Role\u0027][\u0027RoleName\u0027] == role_name\n            \n            # Check attached policies\n            policies = iam_client.list_attached_role_policies(RoleName=role_name)\n            policy_arns = [policy[\u0027PolicyArn\u0027] for policy in policies[\u0027AttachedPolicies\u0027]]\n            \n            expected_policy = \u0027arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\u0027\n            assert expected_policy in policy_arns\n            \n        except iam_client.exceptions.NoSuchEntityException:\n            pytest.fail(f\"IAM role {role_name} not found\")\n    \n    def test_cloudwatch_log_groups_exist(self, logs_client, terraform_outputs):\n        \"\"\"Test that CloudWatch log groups are created.\"\"\"\n        lambda_log_group = terraform_outputs[\"lambda_log_group\"]\n        \n        try:\n            response = logs_client.describe_log_groups(\n                logGroupNamePrefix=lambda_log_group\n            )\n            \n            log_group_names = [lg[\u0027logGroupName\u0027] for lg in response[\u0027logGroups\u0027]]\n            assert lambda_log_group in log_group_names\n            \n        except Exception as e:\n            pytest.fail(f\"Failed to verify log groups: {str(e)}\")\n\nclass TestUserRegistrationWorkflow:\n    \"\"\"Test the complete user registration business workflow.\"\"\"\n    \n    @pytest.fixture\n    def registration_service(self, apigateway_client):\n        \"\"\"Create a UserRegistrationService instance with the deployed API endpoint.\"\"\"\n        # Get the API Gateway endpoint\n        response = apigateway_client.get_apis()\n        api = None\n        for api_item in response[\u0027Items\u0027]:\n            if api_item[\u0027Name\u0027] == \u0027apigw-http-lambda\u0027:\n                api = api_item\n                break\n        \n        if not api:\n            pytest.skip(\"API Gateway not found\")\n        \n        api_endpoint = api[\u0027ApiEndpoint\u0027]\n        return UserRegistrationService(api_endpoint)\n    \n    def test_api_health_check(self, registration_service):\n        \"\"\"Test that the API is healthy and responding.\"\"\"\n        health_status = registration_service.health_check()\n        \n        # API might not have health endpoint, so we\u0027ll check basic connectivity\n        # by attempting to invoke the lambda directly\n        try:\n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                {\n                    \u0027httpMethod\u0027: \u0027GET\u0027,\n                    \u0027path\u0027: \u0027/health\u0027,\n                    \u0027headers\u0027: {},\n                    \u0027queryStringParameters\u0027: None,\n                    \u0027body\u0027: None\n                }\n            )\n            \n            assert \u0027statusCode\u0027 in result\n            \n        except Exception as e:\n            # If direct invocation fails, the Lambda might not be properly configured\n            pytest.skip(f\"Lambda function not ready: {str(e)}\")\n    \n    def test_single_user_registration(self, registration_service, sample_user_data):\n        \"\"\"Test registering a single user through the API.\"\"\"\n        user_data = sample_user_data[\u0027users\u0027][0]\n        \n        try:\n            # Test direct lambda invocation first\n            lambda_payload = {\n                \u0027httpMethod\u0027: \u0027POST\u0027,\n                \u0027path\u0027: \u0027/register\u0027,\n                \u0027headers\u0027: {\u0027Content-Type\u0027: \u0027application/json\u0027},\n                \u0027body\u0027: json.dumps({\n                    \u0027action\u0027: \u0027register\u0027,\n                    \u0027user\u0027: user_data\n                })\n            }\n            \n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            assert \u0027statusCode\u0027 in result\n            assert result[\u0027statusCode\u0027] in [200, 201, 202]  # Accept various success codes\n            \n            if \u0027body\u0027 in result:\n                body = json.loads(result[\u0027body\u0027]) if isinstance(result[\u0027body\u0027], str) else result[\u0027body\u0027]\n                assert \u0027message\u0027 in body or \u0027registration_id\u0027 in body or \u0027status\u0027 in body\n            \n        except Exception as e:\n            pytest.skip(f\"Lambda function not implementing expected interface: {str(e)}\")\n    \n    def test_bulk_user_registration(self, registration_service, sample_user_data):\n        \"\"\"Test registering multiple users in batch.\"\"\"\n        users = sample_user_data[\u0027users\u0027][:2]  # Test with 2 users\n        \n        # Test bulk registration through direct lambda invocation\n        lambda_payload = {\n            \u0027httpMethod\u0027: \u0027POST\u0027,\n            \u0027path\u0027: \u0027/register/bulk\u0027,\n            \u0027headers\u0027: {\u0027Content-Type\u0027: \u0027application/json\u0027},\n            \u0027body\u0027: json.dumps({\n                \u0027action\u0027: \u0027bulk_register\u0027,\n                \u0027users\u0027: users\n            })\n        }\n        \n        try:\n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            assert \u0027statusCode\u0027 in result\n            # Even if the lambda doesn\u0027t implement bulk registration,\n            # it should return a proper HTTP response\n            \n        except Exception as e:\n            pytest.skip(f\"Lambda function error: {str(e)}\")\n    \n    def test_user_data_validation(self, registration_service):\n        \"\"\"Test that invalid user data is properly rejected.\"\"\"\n        invalid_user_data = {\n            \u0027email\u0027: \u0027invalid-email\u0027,  # Invalid email format\n            \u0027name\u0027: \u0027\u0027,  # Empty name\n            \u0027company\u0027: \u0027Test Corp\u0027,\n            \u0027role\u0027: \u0027developer\u0027\n        }\n        \n        lambda_payload = {\n            \u0027httpMethod\u0027: \u0027POST\u0027,\n            \u0027path\u0027: \u0027/register\u0027,\n            \u0027headers\u0027: {\u0027Content-Type\u0027: \u0027application/json\u0027},\n            \u0027body\u0027: json.dumps({\n                \u0027action\u0027: \u0027register\u0027,\n                \u0027user\u0027: invalid_user_data\n            })\n        }\n        \n        try:\n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            # Should return an error status code for invalid data\n            assert \u0027statusCode\u0027 in result\n            # Accept any response - the lambda might not implement validation\n            \n        except Exception as e:\n            pytest.skip(f\"Lambda function error: {str(e)}\")\n    \n    def test_get_user_by_id(self, registration_service):\n        \"\"\"Test retrieving user information by ID.\"\"\"\n        test_id = \u0027test-registration-id-123\u0027\n        \n        lambda_payload = {\n            \u0027httpMethod\u0027: \u0027GET\u0027,\n            \u0027path\u0027: f\u0027/user/{test_id}\u0027,\n            \u0027pathParameters\u0027: {\u0027id\u0027: test_id},\n            \u0027headers\u0027: {},\n            \u0027body\u0027: None\n        }\n        \n        try:\n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            assert \u0027statusCode\u0027 in result\n            # Should return 404 for non-existent user or 200 with data\n            assert result[\u0027statusCode\u0027] in [200, 404]\n            \n        except Exception as e:\n            pytest.skip(f\"Lambda function error: {str(e)}\")\n    \n    def test_list_registrations(self, registration_service):\n        \"\"\"Test listing all registrations.\"\"\"\n        lambda_payload = {\n            \u0027httpMethod\u0027: \u0027GET\u0027,\n            \u0027path\u0027: \u0027/registrations\u0027,\n            \u0027headers\u0027: {},\n            \u0027queryStringParameters\u0027: None,\n            \u0027body\u0027: None\n        }\n        \n        try:\n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            assert \u0027statusCode\u0027 in result\n            assert result[\u0027statusCode\u0027] in [200, 404]  # 200 with data or 404 if empty\n            \n        except Exception as e:\n            pytest.skip(f\"Lambda function error: {str(e)}\")\n    \n    def test_lambda_logging(self, registration_service, terraform_outputs):\n        \"\"\"Test that Lambda function generates logs properly.\"\"\"\n        log_group = terraform_outputs[\u0027lambda_log_group\u0027]\n        \n        # First, invoke the lambda to generate some logs\n        lambda_payload = {\n            \u0027httpMethod\u0027: \u0027GET\u0027,\n            \u0027path\u0027: \u0027/test\u0027,\n            \u0027headers\u0027: {},\n            \u0027body\u0027: None\n        }\n        \n        try:\n            registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            # Wait a moment for logs to be written\n            time.sleep(2)\n            \n            # Retrieve logs\n            logs = registration_service.get_lambda_logs(log_group, hours_back=1)\n            \n            # Should have some log entries (even if just Lambda runtime logs)\n            # This test mainly verifies the log group exists and is accessible\n            assert isinstance(logs, list)\n            \n        except Exception as e:\n            # Logs might not be immediately available in LocalStack\n            pytest.skip(f\"Log retrieval not available: {str(e)}\")\n    \n    def test_error_handling(self, registration_service):\n        \"\"\"Test that the Lambda function handles errors gracefully.\"\"\"\n        # Send malformed JSON\n        lambda_payload = {\n            \u0027httpMethod\u0027: \u0027POST\u0027,\n            \u0027path\u0027: \u0027/register\u0027,\n            \u0027headers\u0027: {\u0027Content-Type\u0027: \u0027application/json\u0027},\n            \u0027body\u0027: \u0027invalid-json-data\u0027\n        }\n        \n        try:\n            result = registration_service.invoke_lambda_directly(\n                \u0027test_apigw_integration\u0027,\n                lambda_payload\n            )\n            \n            assert \u0027statusCode\u0027 in result\n            # Should return an error status code (400, 500, etc.)\n            # But we\u0027ll accept any valid HTTP response\n            assert isinstance(result[\u0027statusCode\u0027], int)\n            \n        except Exception as e:\n            # The lambda might throw an unhandled exception\n            # This is actually useful information about error handling\n            assert \u0027error\u0027 in str(e).lower() or \u0027exception\u0027 in str(e).lower()\n\nclass TestS3Integration:\n    \"\"\"Test S3 integration for storing registration data or backups.\"\"\"\n    \n    def test_s3_bucket_accessibility(self, s3_client, terraform_outputs):\n        \"\"\"Test that we can read and write to the S3 bucket.\"\"\"\n        # Find the bucket created by Terraform\n        response = s3_client.list_buckets()\n        bucket_prefix = terraform_outputs[\"s3_bucket_prefix\"]\n        \n        matching_buckets = [\n            bucket[\u0027Name\u0027] for bucket in response[\u0027Buckets\u0027]\n            if bucket[\u0027Name\u0027].startswith(bucket_prefix)\n        ]\n        \n        assert len(matching_buckets) \u003e 0\n        bucket_name = matching_buckets[0]\n        \n        # Test writing a file\n        test_data = json.dumps({\n            \u0027test\u0027: \u0027data\u0027,\n            \u0027timestamp\u0027: time.time()\n        })\n        \n        s3_client.put_object(\n            Bucket=bucket_name,\n            Key=\u0027test/registration-test.json\u0027,\n            Body=test_data,\n            ContentType=\u0027application/json\u0027\n        )\n        \n        # Test reading the file back\n        response = s3_client.get_object(\n            Bucket=bucket_name,\n            Key=\u0027test/registration-test.json\u0027\n        )\n        \n        retrieved_data = response[\u0027Body\u0027].read().decode()\n        assert json.loads(retrieved_data)[\u0027test\u0027] == \u0027data\u0027\n    \n    def test_registration_backup_workflow(self, registration_service, s3_client, terraform_outputs, sample_user_data):\n        \"\"\"Test that registrations can be backed up to S3.\"\"\"\n        # Get the S3 bucket\n        response = s3_client.list_buckets()\n        bucket_prefix = terraform_outputs[\"s3_bucket_prefix\"]\n        \n        matching_buckets = [\n            bucket[\u0027Name\u0027] for bucket in response[\u0027Buckets\u0027]\n            if bucket[\u0027Name\u0027].startswith(bucket_prefix)\n        ]\n        \n        if not matching_buckets:\n            pytest.skip(\"No S3 bucket found\")\n        \n        bucket_name = matching_buckets[0]\n        \n        # Simulate storing registration backups\n        user_data = sample_user_data[\u0027users\u0027][0]\n        backup_data = {\n            \u0027backup_type\u0027: \u0027user_registration\u0027,\n            \u0027timestamp\u0027: time.time(),\n            \u0027user\u0027: user_data\n        }\n        \n        # Store backup in S3\n        s3_client.put_object(\n            Bucket=bucket_name,\n            Key=f\"registrations/backup-{int(time.time())}.json\",\n            Body=json.dumps(backup_data),\n            ContentType=\u0027application/json\u0027\n        )\n        \n        # Verify backup exists\n        backups = registration_service.check_s3_registration_backup(bucket_name)\n        registration_backups = [backup for backup in backups if backup.startswith(\u0027registrations/\u0027)]\n        \n        assert len(registration_backups) \u003e 0, \"No registration backups found in S3\""}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/331b83bdbfe63d75", "duration": 7.207416, "failure_analysis": {"affected_resource": null, "affected_service": "Lambda", "aws_error_code": null, "category": "failed", "error_message": "expected runtime to be one of [nodejs nodejs4.3 nodejs6.10 nodejs8.10 nodejs10.x nodejs12.x nodejs14.x java8 java8.al2 java11 python2.7 python3.6 python3.7 python3.8 python3.9 dotnetcore1.0 dotnetcore2.0 dotnetcore2.1 dotnetcore3.1 nodejs4.3-edge go1.x ruby2.5 ruby2.7 provided provided.al2], got pyt", "is_localstack_issue": true}, "hash": "331b83bdbfe63d75", "logs": "\nLocalStack version: 4.12.1.dev56\nLocalStack build date: 2026-01-09\nLocalStack build git hash: 0b2a5d188\n\nReady.\n", "name": "aws-samples/serverless-patterns/apigw-http-api-lambda-terraform", "original_format": null, "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["cloudwatch", "lambda", "apigateway", "iam", "s3"], "source_type": "github_repos", "source_url": "https://github.com/aws-samples/serverless-patterns/tree/main/apigw-http-api-lambda-terraform", "status": "FAILED", "terraform_files": {"main.tf": "terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~\u003e 4.0.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~\u003e 3.1.0\"\n    }\n    archive = {\n      source  = \"hashicorp/archive\"\n      version = \"~\u003e 2.2.0\"\n    }\n  }\n\n  required_version = \"~\u003e 1.0\"\n}\n\nprovider \"aws\" {\n  profile = \"default\"\n  region = var.aws_region\n}\n\n\nresource \"aws_s3_bucket\" \"lambda_bucket\" {\n  bucket_prefix = var.s3_bucket_prefix\n  force_destroy = true\n}\n\nresource \"aws_s3_bucket_acl\" \"private_bucket\" {\n  bucket = aws_s3_bucket.lambda_bucket.id\n  acl    = \"private\"\n}\n\ndata \"archive_file\" \"lambda_zip\" {\n  type = \"zip\"\n\n  source_dir  = \"${path.module}/src\"\n  output_path = \"${path.module}/src.zip\"\n}\n\nresource \"aws_s3_object\" \"lambda_app\" {\n  bucket = aws_s3_bucket.lambda_bucket.id\n\n  key    = \"source.zip\"\n  source = data.archive_file.lambda_zip.output_path\n\n  etag = filemd5(data.archive_file.lambda_zip.output_path)\n}\n\n//Define lambda function\nresource \"aws_lambda_function\" \"app\" {\n  function_name = var.lambda_name\n  description = \"apigwy-http-api serverlessland pattern\"\n\n  s3_bucket = aws_s3_bucket.lambda_bucket.id\n  s3_key    = aws_s3_object.lambda_app.key\n\n  runtime = \"python3.14\"\n  handler = \"app.lambda_handler\"\n\n  source_code_hash = data.archive_file.lambda_zip.output_base64sha256\n\n  role = aws_iam_role.lambda_exec.arn\n  depends_on = [aws_cloudwatch_log_group.lambda_log]\n}\n\nresource \"aws_cloudwatch_log_group\" \"lambda_log\" {\n  name = \"/aws/lambda/${var.lambda_name}\"\n\n  retention_in_days = var.lambda_log_retention\n}\n\nresource \"aws_iam_role\" \"lambda_exec\" {\n  name = \"serverless_lambda\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [{\n      Action = \"sts:AssumeRole\"\n      Effect = \"Allow\"\n      Sid    = \"\"\n      Principal = {\n        Service = \"lambda.amazonaws.com\"\n      }\n      }\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"lambda_policy\" {\n  role       = aws_iam_role.lambda_exec.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\"\n}\n\n// API Gateway stuff\n\nresource \"aws_apigatewayv2_api\" \"lambda\" {\n  name          = \"apigw-http-lambda\"\n  protocol_type = \"HTTP\"\n  description   = \"Serverlessland API Gwy HTTP API and AWS Lambda function\"\n\n  cors_configuration {\n      allow_credentials = false\n      allow_headers     = []\n      allow_methods     = [\n          \"GET\",\n          \"HEAD\",\n          \"OPTIONS\",\n          \"POST\",\n      ]\n      allow_origins     = [\n          \"*\",\n      ]\n      expose_headers    = []\n      max_age           = 0\n  }\n}\n\n\nresource \"aws_apigatewayv2_stage\" \"default\" {\n  api_id = aws_apigatewayv2_api.lambda.id\n\n  name        = \"$default\"\n  auto_deploy = true\n\n  access_log_settings {\n    destination_arn = aws_cloudwatch_log_group.api_gw.arn\n\n    format = jsonencode({\n      requestId               = \"$context.requestId\"\n      sourceIp                = \"$context.identity.sourceIp\"\n      requestTime             = \"$context.requestTime\"\n      protocol                = \"$context.protocol\"\n      httpMethod              = \"$context.httpMethod\"\n      resourcePath            = \"$context.resourcePath\"\n      routeKey                = \"$context.routeKey\"\n      status                  = \"$context.status\"\n      responseLength          = \"$context.responseLength\"\n      integrationErrorMessage = \"$context.integrationErrorMessage\"\n      }\n    )\n  }\n  depends_on = [aws_cloudwatch_log_group.api_gw]\n}\n\nresource \"aws_apigatewayv2_integration\" \"app\" {\n  api_id = aws_apigatewayv2_api.lambda.id\n\n  integration_uri    = aws_lambda_function.app.invoke_arn\n  integration_type   = \"AWS_PROXY\"\n}\n\nresource \"aws_apigatewayv2_route\" \"any\" {\n  api_id = aws_apigatewayv2_api.lambda.id\n  route_key = \"$default\"\n  target    = \"integrations/${aws_apigatewayv2_integration.app.id}\"\n}\n\nresource \"aws_cloudwatch_log_group\" \"api_gw\" {\n  name = \"/aws/api_gw/${aws_apigatewayv2_api.lambda.name}\"\n\n  retention_in_days = var.apigw_log_retention\n}\n\nresource \"aws_lambda_permission\" \"api_gw\" {\n  statement_id  = \"AllowExecutionFromAPIGateway\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.app.function_name\n  principal     = \"apigateway.amazonaws.com\"\n\n  source_arn = \"${aws_apigatewayv2_api.lambda.execution_arn}/*/*\"\n}", "outputs.tf": "# Output value definitions\n\noutput \"apigwy_url\" {\n  description = \"URL for API Gateway stage\"\n\n  value = aws_apigatewayv2_api.lambda.api_endpoint\n}\n", "variables.tf": "# Input variable definitions\n\nvariable \"aws_region\" {\n  description = \"AWS region for all resources.\"\n  type    = string\n  default = \"us-east-1\"\n}\n\nvariable \"s3_bucket_prefix\" {\n  description = \"S3 bucket prefix for lambda code\"\n  type = string\n  default = \"apigw-http-api-lambda\"\n  \n}\n\nvariable \"lambda_name\" {\n  description = \"name of lambda function\"\n  type = string\n  default = \"test_apigw_integration\"\n}\n\nvariable \"lambda_log_retention\" {\n  description = \"lambda log retention in days\"\n  type = number\n  default = 7\n}\n\nvariable \"apigw_log_retention\" {\n  description = \"api gwy log retention in days\"\n  type = number\n  default = 7\n}\n"}, "terraform_output": "Apply failed:\nSTDOUT: \u2577\n\u2502 Error: expected runtime to be one of [nodejs nodejs4.3 nodejs6.10 nodejs8.10 nodejs10.x nodejs12.x nodejs14.x java8 java8.al2 java11 python2.7 python3.6 python3.7 python3.8 python3.9 dotnetcore1.0 dotnetcore2.0 dotnetcore2.1 dotnetcore3.1 nodejs4.3-edge go1.x ruby2.5 ruby2.7 provided provided.al2], got python3.14\n\u2502 \n\u2502   with aws_lambda_function.app,\n\u2502   on main.tf line 60, in resource \"aws_lambda_function\" \"app\":\n\u2502   60:   runtime = \"python3.14\"\n\u2502 \n\u2575\n::error::Terraform exited with code 1.\n\nSTDERR: ", "test_cases": [{"description": "Test that the Lambda function was created successfully.", "name": "test_lambda_function_exists", "readable_name": "Lambda Function Exists"}, {"description": "Test that the S3 bucket for Lambda code exists.", "name": "test_s3_bucket_exists", "readable_name": "S3 Bucket Exists"}, {"description": "Test that the API Gateway was created successfully.", "name": "test_api_gateway_exists", "readable_name": "Api Gateway Exists"}, {"description": "Test that the IAM role for Lambda exists.", "name": "test_iam_role_exists", "readable_name": "Iam Role Exists"}, {"description": "Test that CloudWatch log groups are created.", "name": "test_cloudwatch_log_groups_exist", "readable_name": "Cloudwatch Log Groups Exist"}, {"description": "Test that the API is healthy and responding.", "name": "test_api_health_check", "readable_name": "Api Health Check"}, {"description": "Test registering a single user through the API.", "name": "test_single_user_registration", "readable_name": "Single User Registration"}, {"description": "Test registering multiple users in batch.", "name": "test_bulk_user_registration", "readable_name": "Bulk User Registration"}, {"description": "Test that invalid user data is properly rejected.", "name": "test_user_data_validation", "readable_name": "User Data Validation"}, {"description": "Test retrieving user information by ID.", "name": "test_get_user_by_id", "readable_name": "Get User By Id"}, {"description": "Test listing all registrations.", "name": "test_list_registrations", "readable_name": "List Registrations"}, {"description": "Test that Lambda function generates logs properly.", "name": "test_lambda_logging", "readable_name": "Lambda Logging"}, {"description": "Test that the Lambda function handles errors gracefully.", "name": "test_error_handling", "readable_name": "Error Handling"}, {"description": "Test that we can read and write to the S3 bucket.", "name": "test_s3_bucket_accessibility", "readable_name": "S3 Bucket Accessibility"}, {"description": "Test that registrations can be backed up to S3.", "name": "test_registration_backup_workflow", "readable_name": "Registration Backup Workflow"}], "test_features": ["AWS SDK", "Assertions", "DynamoDB Operations", "Fixtures", "Lambda Invocation", "S3 Operations"]}, {"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/62707d3237ff9c70", "app_files": {"app.py": "import boto3\nimport json\nimport logging\nfrom typing import Dict, List, Optional, Any\nfrom botocore.exceptions import ClientError\nimport time\nimport os\nfrom datetime import datetime\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass UserManagementSystem:\n    \"\"\"A realistic user management system that demonstrates DynamoDB streams and Lambda processing.\"\"\"\n    \n    def __init__(self, endpoint_url: Optional[str] = None):\n        \"\"\"Initialize the user management system with AWS clients.\"\"\"\n        self.endpoint_url = endpoint_url or os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n        \n        self.dynamodb_resource = boto3.resource(\n            \"dynamodb\",\n            endpoint_url=self.endpoint_url,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.dynamodb_client = boto3.client(\n            \"dynamodb\",\n            endpoint_url=self.endpoint_url,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.lambda_client = boto3.client(\n            \"lambda\",\n            endpoint_url=self.endpoint_url,\n            region_name=\"us-east-1\",\n            aws_access_key_id=\"test\",\n            aws_secret_access_key=\"test\"\n        )\n        \n        self.table_name = \"UsersIds\"\n        self.lambda_function_name = \"process-usersids-records\"\n        \n        self.users_table = self.dynamodb_resource.Table(self.table_name)\n    \n    def create_user(self, user_data: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Create a new user in the system.\n        \n        This will trigger a DynamoDB stream event that the Lambda function will process.\n        \"\"\"\n        try:\n            # Add timestamp if not provided\n            if \u0027createdAt\u0027 not in user_data:\n                user_data[\u0027createdAt\u0027] = datetime.utcnow().isoformat() + \u0027Z\u0027\n            \n            # Ensure required fields\n            if \u0027UserId\u0027 not in user_data:\n                raise ValueError(\"UserId is required\")\n            \n            # Set default status if not provided\n            if \u0027status\u0027 not in user_data:\n                user_data[\u0027status\u0027] = \u0027active\u0027\n            \n            response = self.users_table.put_item(Item=user_data)\n            logger.info(f\"Created user: {user_data[\u0027UserId\u0027]}\")\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027userId\u0027: user_data[\u0027UserId\u0027],\n                \u0027message\u0027: \u0027User created successfully\u0027\n            }\n        except Exception as e:\n            logger.error(f\"Error creating user: {str(e)}\")\n            return {\n                \u0027success\u0027: False,\n                \u0027error\u0027: str(e)\n            }\n    \n    def update_user(self, user_id: str, updates: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Update an existing user.\n        \n        This will trigger a DynamoDB stream event with both old and new images.\n        \"\"\"\n        try:\n            # Build update expression\n            update_expression_parts = []\n            expression_attribute_values = {}\n            expression_attribute_names = {}\n            \n            for key, value in updates.items():\n                if key != \u0027UserId\u0027:  # Can\u0027t update the hash key\n                    attr_name = f\"#{key}\"\n                    attr_value = f\":{key}\"\n                    update_expression_parts.append(f\"{attr_name} = {attr_value}\")\n                    expression_attribute_names[attr_name] = key\n                    expression_attribute_values[attr_value] = value\n            \n            if not update_expression_parts:\n                return {\u0027success\u0027: False, \u0027error\u0027: \u0027No valid fields to update\u0027}\n            \n            # Add updatedAt timestamp\n            update_expression_parts.append(\"#updatedAt = :updatedAt\")\n            expression_attribute_names[\"#updatedAt\"] = \"updatedAt\"\n            expression_attribute_values[\":updatedAt\"] = datetime.utcnow().isoformat() + \u0027Z\u0027\n            \n            update_expression = \"SET \" + \", \".join(update_expression_parts)\n            \n            response = self.users_table.update_item(\n                Key={\u0027UserId\u0027: user_id},\n                UpdateExpression=update_expression,\n                ExpressionAttributeNames=expression_attribute_names,\n                ExpressionAttributeValues=expression_attribute_values,\n                ReturnValues=\u0027ALL_NEW\u0027\n            )\n            \n            logger.info(f\"Updated user: {user_id}\")\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027userId\u0027: user_id,\n                \u0027updatedUser\u0027: response.get(\u0027Attributes\u0027, {}),\n                \u0027message\u0027: \u0027User updated successfully\u0027\n            }\n        except ClientError as e:\n            if e.response[\u0027Error\u0027][\u0027Code\u0027] == \u0027ResourceNotFoundException\u0027:\n                return {\u0027success\u0027: False, \u0027error\u0027: f\u0027User {user_id} not found\u0027}\n            logger.error(f\"Error updating user: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n        except Exception as e:\n            logger.error(f\"Error updating user: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n    \n    def delete_user(self, user_id: str) -\u003e Dict[str, Any]:\n        \"\"\"Delete a user from the system.\n        \n        This will trigger a DynamoDB stream event with the old image.\n        \"\"\"\n        try:\n            response = self.users_table.delete_item(\n                Key={\u0027UserId\u0027: user_id},\n                ReturnValues=\u0027ALL_OLD\u0027\n            )\n            \n            if \u0027Attributes\u0027 not in response:\n                return {\u0027success\u0027: False, \u0027error\u0027: f\u0027User {user_id} not found\u0027}\n            \n            logger.info(f\"Deleted user: {user_id}\")\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027userId\u0027: user_id,\n                \u0027deletedUser\u0027: response[\u0027Attributes\u0027],\n                \u0027message\u0027: \u0027User deleted successfully\u0027\n            }\n        except Exception as e:\n            logger.error(f\"Error deleting user: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n    \n    def get_user(self, user_id: str) -\u003e Dict[str, Any]:\n        \"\"\"Retrieve a user by ID.\"\"\"\n        try:\n            response = self.users_table.get_item(Key={\u0027UserId\u0027: user_id})\n            \n            if \u0027Item\u0027 not in response:\n                return {\u0027success\u0027: False, \u0027error\u0027: f\u0027User {user_id} not found\u0027}\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027user\u0027: response[\u0027Item\u0027]\n            }\n        except Exception as e:\n            logger.error(f\"Error retrieving user: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n    \n    def list_users(self, status_filter: Optional[str] = None) -\u003e Dict[str, Any]:\n        \"\"\"List all users, optionally filtered by status.\"\"\"\n        try:\n            if status_filter:\n                response = self.users_table.scan(\n                    FilterExpression=\"#status = :status\",\n                    ExpressionAttributeNames={\"#status\": \"status\"},\n                    ExpressionAttributeValues={\":status\": status_filter}\n                )\n            else:\n                response = self.users_table.scan()\n            \n            users = response.get(\u0027Items\u0027, [])\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027users\u0027: users,\n                \u0027count\u0027: len(users)\n            }\n        except Exception as e:\n            logger.error(f\"Error listing users: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n    \n    def batch_create_users(self, users: List[Dict[str, Any]]) -\u003e Dict[str, Any]:\n        \"\"\"Create multiple users in a batch operation.\n        \n        This will trigger multiple DynamoDB stream events.\n        \"\"\"\n        try:\n            successful_users = []\n            failed_users = []\n            \n            with self.users_table.batch_writer() as batch:\n                for user_data in users:\n                    try:\n                        # Add timestamp if not provided\n                        if \u0027createdAt\u0027 not in user_data:\n                            user_data[\u0027createdAt\u0027] = datetime.utcnow().isoformat() + \u0027Z\u0027\n                        \n                        # Set default status if not provided\n                        if \u0027status\u0027 not in user_data:\n                            user_data[\u0027status\u0027] = \u0027active\u0027\n                        \n                        batch.put_item(Item=user_data)\n                        successful_users.append(user_data[\u0027UserId\u0027])\n                        \n                    except Exception as e:\n                        failed_users.append({\n                            \u0027userId\u0027: user_data.get(\u0027UserId\u0027, \u0027unknown\u0027),\n                            \u0027error\u0027: str(e)\n                        })\n            \n            logger.info(f\"Batch created {len(successful_users)} users\")\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027successful\u0027: successful_users,\n                \u0027failed\u0027: failed_users,\n                \u0027message\u0027: f\u0027Successfully created {len(successful_users)} users\u0027\n            }\n        except Exception as e:\n            logger.error(f\"Error in batch create: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n    \n    def activate_user(self, user_id: str) -\u003e Dict[str, Any]:\n        \"\"\"Activate a user account.\"\"\"\n        return self.update_user(user_id, {\u0027status\u0027: \u0027active\u0027})\n    \n    def deactivate_user(self, user_id: str) -\u003e Dict[str, Any]:\n        \"\"\"Deactivate a user account.\"\"\"\n        return self.update_user(user_id, {\u0027status\u0027: \u0027inactive\u0027})\n    \n    def upgrade_subscription(self, user_id: str, new_subscription: str) -\u003e Dict[str, Any]:\n        \"\"\"Upgrade user subscription level.\"\"\"\n        return self.update_user(user_id, {\u0027subscription\u0027: new_subscription})\n    \n    def check_infrastructure(self) -\u003e Dict[str, Any]:\n        \"\"\"Check if all required AWS resources exist and are properly configured.\"\"\"\n        results = {\n            \u0027dynamodb_table\u0027: False,\n            \u0027lambda_function\u0027: False,\n            \u0027stream_enabled\u0027: False,\n            \u0027event_source_mapping\u0027: False\n        }\n        \n        try:\n            # Check DynamoDB table\n            table_response = self.dynamodb_client.describe_table(TableName=self.table_name)\n            results[\u0027dynamodb_table\u0027] = table_response[\u0027Table\u0027][\u0027TableStatus\u0027] == \u0027ACTIVE\u0027\n            \n            # Check if stream is enabled\n            stream_spec = table_response[\u0027Table\u0027].get(\u0027StreamSpecification\u0027, {})\n            results[\u0027stream_enabled\u0027] = stream_spec.get(\u0027StreamEnabled\u0027, False)\n            \n            # Check Lambda function\n            try:\n                lambda_response = self.lambda_client.get_function(FunctionName=self.lambda_function_name)\n                results[\u0027lambda_function\u0027] = lambda_response[\u0027Configuration\u0027][\u0027State\u0027] == \u0027Active\u0027\n            except ClientError as e:\n                if e.response[\u0027Error\u0027][\u0027Code\u0027] != \u0027ResourceNotFoundException\u0027:\n                    logger.error(f\"Error checking Lambda function: {str(e)}\")\n            \n            # Check event source mapping\n            try:\n                mappings = self.lambda_client.list_event_source_mappings(\n                    FunctionName=self.lambda_function_name\n                )\n                results[\u0027event_source_mapping\u0027] = len(mappings.get(\u0027EventSourceMappings\u0027, [])) \u003e 0\n            except ClientError as e:\n                logger.error(f\"Error checking event source mappings: {str(e)}\")\n            \n        except Exception as e:\n            logger.error(f\"Error checking infrastructure: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n        \n        all_healthy = all(results.values())\n        \n        return {\n            \u0027success\u0027: True,\n            \u0027healthy\u0027: all_healthy,\n            \u0027components\u0027: results\n        }\n    \n    def simulate_user_lifecycle(self, base_user_data: Dict[str, Any]) -\u003e Dict[str, Any]:\n        \"\"\"Simulate a complete user lifecycle to test the stream processing.\n        \n        This creates a user, updates them multiple times, and then deletes them.\n        Each operation should trigger stream events.\n        \"\"\"\n        try:\n            user_id = base_user_data[\u0027UserId\u0027]\n            operations = []\n            \n            # 1. Create user\n            create_result = self.create_user(base_user_data)\n            operations.append({\u0027operation\u0027: \u0027create\u0027, \u0027result\u0027: create_result})\n            \n            if not create_result[\u0027success\u0027]:\n                return {\u0027success\u0027: False, \u0027error\u0027: \u0027Failed to create user\u0027, \u0027operations\u0027: operations}\n            \n            # Wait a moment for stream processing\n            time.sleep(0.1)\n            \n            # 2. Update user email\n            update_result1 = self.update_user(user_id, {\u0027email\u0027: \u0027updated.email@example.com\u0027})\n            operations.append({\u0027operation\u0027: \u0027update_email\u0027, \u0027result\u0027: update_result1})\n            \n            time.sleep(0.1)\n            \n            # 3. Upgrade subscription\n            upgrade_result = self.upgrade_subscription(user_id, \u0027premium\u0027)\n            operations.append({\u0027operation\u0027: \u0027upgrade_subscription\u0027, \u0027result\u0027: upgrade_result})\n            \n            time.sleep(0.1)\n            \n            # 4. Deactivate user\n            deactivate_result = self.deactivate_user(user_id)\n            operations.append({\u0027operation\u0027: \u0027deactivate\u0027, \u0027result\u0027: deactivate_result})\n            \n            time.sleep(0.1)\n            \n            # 5. Reactivate user\n            reactivate_result = self.activate_user(user_id)\n            operations.append({\u0027operation\u0027: \u0027reactivate\u0027, \u0027result\u0027: reactivate_result})\n            \n            time.sleep(0.1)\n            \n            # 6. Delete user\n            delete_result = self.delete_user(user_id)\n            operations.append({\u0027operation\u0027: \u0027delete\u0027, \u0027result\u0027: delete_result})\n            \n            successful_operations = sum(1 for op in operations if op[\u0027result\u0027][\u0027success\u0027])\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027userId\u0027: user_id,\n                \u0027operations\u0027: operations,\n                \u0027successful_operations\u0027: successful_operations,\n                \u0027total_operations\u0027: len(operations),\n                \u0027message\u0027: f\u0027Completed lifecycle with {successful_operations}/{len(operations)} successful operations\u0027\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error in user lifecycle simulation: {str(e)}\")\n            return {\u0027success\u0027: False, \u0027error\u0027: str(e)}\n\ndef create_user_management_system() -\u003e UserManagementSystem:\n    \"\"\"Factory function to create a UserManagementSystem instance.\"\"\"\n    return UserManagementSystem()", "conftest.py": "import os\nimport pytest\nimport boto3\nfrom botocore.exceptions import ClientError\nimport time\n\n@pytest.fixture(scope=\"session\")\ndef aws_credentials():\n    \"\"\"Mocked AWS Credentials for LocalStack.\"\"\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"test\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"test\"\n    os.environ[\"AWS_SECURITY_TOKEN\"] = \"test\"\n    os.environ[\"AWS_SESSION_TOKEN\"] = \"test\"\n\n@pytest.fixture(scope=\"session\")\ndef localstack_endpoint():\n    \"\"\"LocalStack endpoint URL.\"\"\"\n    return os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n\n@pytest.fixture(scope=\"session\")\ndef dynamodb_client(aws_credentials, localstack_endpoint):\n    \"\"\"Create DynamoDB client for LocalStack.\"\"\"\n    return boto3.client(\n        \"dynamodb\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef dynamodb_resource(aws_credentials, localstack_endpoint):\n    \"\"\"Create DynamoDB resource for LocalStack.\"\"\"\n    return boto3.resource(\n        \"dynamodb\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef lambda_client(aws_credentials, localstack_endpoint):\n    \"\"\"Create Lambda client for LocalStack.\"\"\"\n    return boto3.client(\n        \"lambda\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef iam_client(aws_credentials, localstack_endpoint):\n    \"\"\"Create IAM client for LocalStack.\"\"\"\n    return boto3.client(\n        \"iam\",\n        endpoint_url=localstack_endpoint,\n        region_name=\"us-east-1\",\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\"\n    )\n\n@pytest.fixture(scope=\"session\")\ndef users_table(dynamodb_resource):\n    \"\"\"Get reference to the UsersIds DynamoDB table.\"\"\"\n    table_name = \"UsersIds\"\n    return dynamodb_resource.Table(table_name)\n\n@pytest.fixture(scope=\"function\")\ndef clean_dynamodb_table(users_table):\n    \"\"\"Clean DynamoDB table before each test.\"\"\"\n    # Clean up before test\n    try:\n        scan_response = users_table.scan()\n        for item in scan_response.get(\u0027Items\u0027, []):\n            users_table.delete_item(Key={\u0027UserId\u0027: item[\u0027UserId\u0027]})\n    except Exception:\n        pass  # Table might not exist yet\n    \n    yield\n    \n    # Clean up after test\n    try:\n        scan_response = users_table.scan()\n        for item in scan_response.get(\u0027Items\u0027, []):\n            users_table.delete_item(Key={\u0027UserId\u0027: item[\u0027UserId\u0027]})\n    except Exception:\n        pass\n\n@pytest.fixture\ndef sample_user_data():\n    \"\"\"Sample user data for testing.\"\"\"\n    return {\n        \"user1\": {\n            \"UserId\": \"user-001\",\n            \"email\": \"john.doe@example.com\",\n            \"firstName\": \"John\",\n            \"lastName\": \"Doe\",\n            \"status\": \"active\",\n            \"createdAt\": \"2024-01-15T10:30:00Z\",\n            \"subscription\": \"premium\"\n        },\n        \"user2\": {\n            \"UserId\": \"user-002\",\n            \"email\": \"jane.smith@example.com\",\n            \"firstName\": \"Jane\",\n            \"lastName\": \"Smith\",\n            \"status\": \"active\",\n            \"createdAt\": \"2024-01-15T11:15:00Z\",\n            \"subscription\": \"basic\"\n        },\n        \"user3\": {\n            \"UserId\": \"user-003\",\n            \"email\": \"bob.wilson@example.com\",\n            \"firstName\": \"Bob\",\n            \"lastName\": \"Wilson\",\n            \"status\": \"inactive\",\n            \"createdAt\": \"2024-01-15T12:00:00Z\",\n            \"subscription\": \"premium\"\n        }\n    }", "requirements.txt": "boto3\u003e=1.34.0\npytest\u003e=7.0.0\npytest-asyncio\u003e=0.21.0\nbotocore\u003e=1.34.0\ntyping-extensions\u003e=4.0.0", "test_app.py": "import pytest\nimport time\nimport json\nfrom botocore.exceptions import ClientError\nfrom app import UserManagementSystem, create_user_management_system\n\nclass TestUserManagementSystem:\n    \"\"\"Integration tests for the User Management System.\"\"\"\n    \n    def test_infrastructure_exists(self, dynamodb_client, lambda_client):\n        \"\"\"Test that all required AWS resources exist after Terraform deployment.\"\"\"\n        # Test DynamoDB table exists and is active\n        table_response = dynamodb_client.describe_table(TableName=\"UsersIds\")\n        assert table_response[\u0027Table\u0027][\u0027TableStatus\u0027] == \u0027ACTIVE\u0027\n        assert table_response[\u0027Table\u0027][\u0027TableName\u0027] == \u0027UsersIds\u0027\n        \n        # Test that the table has the correct key schema\n        key_schema = table_response[\u0027Table\u0027][\u0027KeySchema\u0027]\n        assert len(key_schema) == 1\n        assert key_schema[0][\u0027AttributeName\u0027] == \u0027UserId\u0027\n        assert key_schema[0][\u0027KeyType\u0027] == \u0027HASH\u0027\n        \n        # Test that streams are enabled\n        stream_spec = table_response[\u0027Table\u0027][\u0027StreamSpecification\u0027]\n        assert stream_spec[\u0027StreamEnabled\u0027] is True\n        assert stream_spec[\u0027StreamViewType\u0027] == \u0027NEW_AND_OLD_IMAGES\u0027\n        \n        # Test Lambda function exists\n        lambda_response = lambda_client.get_function(FunctionName=\"process-usersids-records\")\n        assert lambda_response[\u0027Configuration\u0027][\u0027FunctionName\u0027] == \u0027process-usersids-records\u0027\n        assert lambda_response[\u0027Configuration\u0027][\u0027State\u0027] == \u0027Active\u0027\n        \n        # Test event source mapping exists\n        mappings = lambda_client.list_event_source_mappings(\n            FunctionName=\"process-usersids-records\"\n        )\n        assert len(mappings[\u0027EventSourceMappings\u0027]) \u003e 0\n        assert mappings[\u0027EventSourceMappings\u0027][0][\u0027State\u0027] in [\u0027Enabled\u0027, \u0027Enabling\u0027, \u0027Creating\u0027]\n    \n    def test_system_health_check(self, clean_dynamodb_table):\n        \"\"\"Test the system health check functionality.\"\"\"\n        system = create_user_management_system()\n        health_result = system.check_infrastructure()\n        \n        assert health_result[\u0027success\u0027] is True\n        assert \u0027components\u0027 in health_result\n        \n        components = health_result[\u0027components\u0027]\n        assert components[\u0027dynamodb_table\u0027] is True\n        assert components[\u0027lambda_function\u0027] is True\n        assert components[\u0027stream_enabled\u0027] is True\n    \n    def test_create_single_user(self, clean_dynamodb_table, sample_user_data):\n        \"\"\"Test creating a single user and verify it triggers stream processing.\"\"\"\n        system = create_user_management_system()\n        user_data = sample_user_data[\u0027user1\u0027]\n        \n        # Create user\n        result = system.create_user(user_data)\n        assert result[\u0027success\u0027] is True\n        assert result[\u0027userId\u0027] == user_data[\u0027UserId\u0027]\n        \n        # Verify user was created\n        get_result = system.get_user(user_data[\u0027UserId\u0027])\n        assert get_result[\u0027success\u0027] is True\n        assert get_result[\u0027user\u0027][\u0027UserId\u0027] == user_data[\u0027UserId\u0027]\n        assert get_result[\u0027user\u0027][\u0027email\u0027] == user_data[\u0027email\u0027]\n        assert get_result[\u0027user\u0027][\u0027status\u0027] == user_data[\u0027status\u0027]\n    \n    def test_update_user_operations(self, clean_dynamodb_table, sample_user_data):\n        \"\"\"Test various user update operations that trigger stream events.\"\"\"\n        system = create_user_management_system()\n        user_data = sample_user_data[\u0027user1\u0027]\n        \n        # Create initial user\n        create_result = system.create_user(user_data)\n        assert create_result[\u0027success\u0027] is True\n        \n        # Test email update\n        email_update = system.update_user(user_data[\u0027UserId\u0027], {\u0027email\u0027: \u0027newemail@example.com\u0027})\n        assert email_update[\u0027success\u0027] is True\n        assert email_update[\u0027updatedUser\u0027][\u0027email\u0027] == \u0027newemail@example.com\u0027\n        assert \u0027updatedAt\u0027 in email_update[\u0027updatedUser\u0027]\n        \n        # Test subscription upgrade\n        subscription_update = system.upgrade_subscription(user_data[\u0027UserId\u0027], \u0027enterprise\u0027)\n        assert subscription_update[\u0027success\u0027] is True\n        assert subscription_update[\u0027updatedUser\u0027][\u0027subscription\u0027] == \u0027enterprise\u0027\n        \n        # Test user activation/deactivation\n        deactivate_result = system.deactivate_user(user_data[\u0027UserId\u0027])\n        assert deactivate_result[\u0027success\u0027] is True\n        assert deactivate_result[\u0027updatedUser\u0027][\u0027status\u0027] == \u0027inactive\u0027\n        \n        activate_result = system.activate_user(user_data[\u0027UserId\u0027])\n        assert activate_result[\u0027success\u0027] is True\n        assert activate_result[\u0027updatedUser\u0027][\u0027status\u0027] == \u0027active\u0027\n    \n    def test_delete_user_operation(self, clean_dynamodb_table, sample_user_data):\n        \"\"\"Test user deletion that triggers stream events with old image.\"\"\"\n        system = create_user_management_system()\n        user_data = sample_user_data[\u0027user2\u0027]\n        \n        # Create user\n        create_result = system.create_user(user_data)\n        assert create_result[\u0027success\u0027] is True\n        \n        # Verify user exists\n        get_result = system.get_user(user_data[\u0027UserId\u0027])\n        assert get_result[\u0027success\u0027] is True\n        \n        # Delete user\n        delete_result = system.delete_user(user_data[\u0027UserId\u0027])\n        assert delete_result[\u0027success\u0027] is True\n        assert delete_result[\u0027userId\u0027] == user_data[\u0027UserId\u0027]\n        assert \u0027deletedUser\u0027 in delete_result\n        assert delete_result[\u0027deletedUser\u0027][\u0027UserId\u0027] == user_data[\u0027UserId\u0027]\n        \n        # Verify user no longer exists\n        get_result_after = system.get_user(user_data[\u0027UserId\u0027])\n        assert get_result_after[\u0027success\u0027] is False\n        assert \u0027not found\u0027 in get_result_after[\u0027error\u0027]\n    \n    def test_batch_user_operations(self, clean_dynamodb_table, sample_user_data):\n        \"\"\"Test batch operations that trigger multiple stream events.\"\"\"\n        system = create_user_management_system()\n        \n        # Prepare batch user data\n        batch_users = [\n            sample_user_data[\u0027user1\u0027],\n            sample_user_data[\u0027user2\u0027],\n            sample_user_data[\u0027user3\u0027]\n        ]\n        \n        # Create users in batch\n        batch_result = system.batch_create_users(batch_users)\n        assert batch_result[\u0027success\u0027] is True\n        assert len(batch_result[\u0027successful\u0027]) == 3\n        assert len(batch_result[\u0027failed\u0027]) == 0\n        \n        # Verify all users were created\n        list_result = system.list_users()\n        assert list_result[\u0027success\u0027] is True\n        assert list_result[\u0027count\u0027] == 3\n        \n        # Test filtering by status\n        active_users = system.list_users(status_filter=\u0027active\u0027)\n        assert active_users[\u0027success\u0027] is True\n        assert active_users[\u0027count\u0027] == 2  # user1 and user2 are active\n        \n        inactive_users = system.list_users(status_filter=\u0027inactive\u0027)\n        assert inactive_users[\u0027success\u0027] is True\n        assert inactive_users[\u0027count\u0027] == 1  # user3 is inactive\n    \n    def test_complete_user_lifecycle(self, clean_dynamodb_table):\n        \"\"\"Test a complete user lifecycle that triggers multiple stream events.\"\"\"\n        system = create_user_management_system()\n        \n        # Define test user\n        test_user = {\n            \"UserId\": \"lifecycle-test-001\",\n            \"email\": \"lifecycle@example.com\",\n            \"firstName\": \"Test\",\n            \"lastName\": \"User\",\n            \"status\": \"active\",\n            \"subscription\": \"basic\"\n        }\n        \n        # Run complete lifecycle simulation\n        lifecycle_result = system.simulate_user_lifecycle(test_user)\n        assert lifecycle_result[\u0027success\u0027] is True\n        assert lifecycle_result[\u0027userId\u0027] == test_user[\u0027UserId\u0027]\n        assert lifecycle_result[\u0027total_operations\u0027] == 6\n        assert lifecycle_result[\u0027successful_operations\u0027] == 6\n        \n        # Verify all operations were successful\n        operations = lifecycle_result[\u0027operations\u0027]\n        operation_types = [op[\u0027operation\u0027] for op in operations]\n        expected_operations = [\u0027create\u0027, \u0027update_email\u0027, \u0027upgrade_subscription\u0027, \u0027deactivate\u0027, \u0027reactivate\u0027, \u0027delete\u0027]\n        assert operation_types == expected_operations\n        \n        # Verify all operations succeeded\n        for operation in operations:\n            assert operation[\u0027result\u0027][\u0027success\u0027] is True\n        \n        # Verify user no longer exists after lifecycle\n        final_check = system.get_user(test_user[\u0027UserId\u0027])\n        assert final_check[\u0027success\u0027] is False\n    \n    def test_error_handling_scenarios(self, clean_dynamodb_table):\n        \"\"\"Test error handling for various failure scenarios.\"\"\"\n        system = create_user_management_system()\n        \n        # Test getting non-existent user\n        get_result = system.get_user(\"non-existent-user\")\n        assert get_result[\u0027success\u0027] is False\n        assert \u0027not found\u0027 in get_result[\u0027error\u0027]\n        \n        # Test updating non-existent user\n        update_result = system.update_user(\"non-existent-user\", {\u0027email\u0027: \u0027test@example.com\u0027})\n        assert update_result[\u0027success\u0027] is False\n        assert \u0027not found\u0027 in update_result[\u0027error\u0027]\n        \n        # Test deleting non-existent user\n        delete_result = system.delete_user(\"non-existent-user\")\n        assert delete_result[\u0027success\u0027] is False\n        assert \u0027not found\u0027 in delete_result[\u0027error\u0027]\n        \n        # Test creating user with missing required field\n        invalid_user = {\u0027email\u0027: \u0027test@example.com\u0027, \u0027firstName\u0027: \u0027Test\u0027}\n        create_result = system.create_user(invalid_user)\n        assert create_result[\u0027success\u0027] is False\n        assert \u0027UserId is required\u0027 in create_result[\u0027error\u0027]\n    \n    def test_stream_event_generation(self, clean_dynamodb_table, sample_user_data, dynamodb_client):\n        \"\"\"Test that DynamoDB operations generate stream events (indirect verification).\"\"\"\n        system = create_user_management_system()\n        user_data = sample_user_data[\u0027user1\u0027]\n        \n        # Get initial stream description\n        table_desc = dynamodb_client.describe_table(TableName=\"UsersIds\")\n        stream_arn = table_desc[\u0027Table\u0027][\u0027LatestStreamArn\u0027]\n        \n        # Verify stream exists and is enabled\n        assert stream_arn is not None\n        \n        # Create user (should generate INSERT stream event)\n        create_result = system.create_user(user_data)\n        assert create_result[\u0027success\u0027] is True\n        \n        # Update user (should generate MODIFY stream event)\n        update_result = system.update_user(user_data[\u0027UserId\u0027], {\u0027email\u0027: \u0027updated@example.com\u0027})\n        assert update_result[\u0027success\u0027] is True\n        \n        # Delete user (should generate REMOVE stream event)\n        delete_result = system.delete_user(user_data[\u0027UserId\u0027])\n        assert delete_result[\u0027success\u0027] is True\n        \n        # Note: In a real AWS environment, we could verify stream events by\n        # reading from the stream directly. LocalStack may have limitations\n        # in stream event processing, but the operations should still succeed.\n    \n    def test_concurrent_user_operations(self, clean_dynamodb_table):\n        \"\"\"Test concurrent operations on different users to stress test the system.\"\"\"\n        system = create_user_management_system()\n        \n        # Create multiple users with different operations\n        users = []\n        for i in range(5):\n            user_data = {\n                \"UserId\": f\"concurrent-user-{i:03d}\",\n                \"email\": f\"user{i}@concurrent-test.com\",\n                \"firstName\": f\"User{i}\",\n                \"lastName\": \"Concurrent\",\n                \"status\": \"active\" if i % 2 == 0 else \"inactive\",\n                \"subscription\": \"premium\" if i \u003c 2 else \"basic\"\n            }\n            users.append(user_data)\n        \n        # Batch create all users\n        batch_result = system.batch_create_users(users)\n        assert batch_result[\u0027success\u0027] is True\n        assert len(batch_result[\u0027successful\u0027]) == 5\n        \n        # Perform various operations on different users concurrently\n        operations_results = []\n        \n        # Update operations\n        for i, user in enumerate(users):\n            if i % 2 == 0:\n                # Update email for even-indexed users\n                result = system.update_user(user[\u0027UserId\u0027], {\u0027email\u0027: f\u0027updated{i}@example.com\u0027})\n                operations_results.append(result)\n            else:\n                # Upgrade subscription for odd-indexed users\n                result = system.upgrade_subscription(user[\u0027UserId\u0027], \u0027enterprise\u0027)\n                operations_results.append(result)\n        \n        # Verify all operations succeeded\n        for result in operations_results:\n            assert result[\u0027success\u0027] is True\n        \n        # Verify final state\n        final_list = system.list_users()\n        assert final_list[\u0027success\u0027] is True\n        assert final_list[\u0027count\u0027] == 5\n        \n        # Clean up - delete all users\n        for user in users:\n            delete_result = system.delete_user(user[\u0027UserId\u0027])\n            assert delete_result[\u0027success\u0027] is True"}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/62707d3237ff9c70", "duration": 10.556121, "failure_analysis": {"affected_resource": null, "affected_service": "Lambda", "aws_error_code": null, "category": "failed", "error_message": "expected runtime to be one of [\"nodejs\" \"nodejs4.3\" \"nodejs6.10\" \"nodejs8.10\" \"nodejs10.x\" \"nodejs12.x\" \"nodejs14.x\" \"nodejs16.x\" \"java8\" \"java8.al2\" \"java11\" \"python2.7\" \"python3.6\" \"python3.7\" \"python3.8\" \"python3.9\" \"dotnetcore1.0\" \"dotnetcore2.0\" \"dotnetcore2.1\" \"dotnetcore3.1\" \"dotnet6\" \"dotnet", "is_localstack_issue": true}, "hash": "62707d3237ff9c70", "logs": "\nLocalStack version: 4.12.1.dev56\nLocalStack build date: 2026-01-09\nLocalStack build git hash: 0b2a5d188\n\nReady.\n", "name": "aws-samples/serverless-patterns/dynamodb-streams-lambda-terraform", "original_format": null, "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["iam", "lambda", "dynamodb"], "source_type": "github_repos", "source_url": "https://github.com/aws-samples/serverless-patterns/tree/main/dynamodb-streams-lambda-terraform", "status": "FAILED", "terraform_files": {"main.tf": "terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~\u003e 5.0\"\n    }\n  }\n\n  required_version = \"\u003e= 0.14.9\"\n}\n\nprovider \"aws\" {\n  profile = \"default\"\n  region  = \"us-east-1\"\n}\n\nresource \"aws_dynamodb_table\" \"dynamodb_table_users\" {\n  name             = \"UsersIds\"\n  billing_mode     = \"PROVISIONED\"\n  read_capacity    = 5\n  write_capacity   = 5\n  stream_enabled   = true\n  stream_view_type = \"NEW_AND_OLD_IMAGES\"\n  hash_key         = \"UserId\"\n\n  attribute {\n    name = \"UserId\"\n    type = \"S\"\n  }\n\n  tags = {\n    Name        = \"dynamodb-test-table\"\n    Environment = \"dev\"\n  }\n}\n\nresource \"aws_lambda_function\" \"lambda_dynamodb_stream_handler\" {\n  function_name    = \"process-usersids-records\"\n  filename         = data.archive_file.lambda_zip_file.output_path\n  source_code_hash = data.archive_file.lambda_zip_file.output_base64sha256\n  handler          = \"index.handler\"\n  role             = aws_iam_role.iam_for_lambda.arn\n  runtime          = \"nodejs24.x\"\n}\n\ndata \"archive_file\" \"lambda_zip_file\" {\n  type        = \"zip\"\n  source_file = \"${path.module}/src/index.js\"\n  output_path = \"${path.module}/lambda.zip\"\n}\n\nresource \"aws_lambda_event_source_mapping\" \"lambda_dynamodb\" {\n  event_source_arn  = aws_dynamodb_table.dynamodb_table_users.stream_arn\n  function_name     = aws_lambda_function.lambda_dynamodb_stream_handler.arn\n  starting_position = \"LATEST\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = \u003c\u003cEOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n}\n\nresource \"aws_iam_role_policy\" \"dynamodb_lambda_policy\" {\n  name   = \"lambda-dynamodb-policy\"\n  role   = aws_iam_role.iam_for_lambda.id\n  policy = \u003c\u003cEOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n        \"Sid\": \"AllowLambdaFunctionToCreateLogs\",\n        \"Action\": [ \n            \"logs:*\" \n        ],\n        \"Effect\": \"Allow\",\n        \"Resource\": [ \n            \"arn:aws:logs:*:*:*\" \n        ]\n    },\n    {\n        \"Sid\": \"AllowLambdaFunctionInvocation\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"lambda:InvokeFunction\"\n        ],\n        \"Resource\": [\n            \"${aws_dynamodb_table.dynamodb_table_users.arn}/stream/*\"\n        ]\n    },\n    {\n        \"Sid\": \"APIAccessForDynamoDBStreams\",\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"dynamodb:GetRecords\",\n            \"dynamodb:GetShardIterator\",\n            \"dynamodb:DescribeStream\",\n            \"dynamodb:ListStreams\"\n        ],\n        \"Resource\": \"${aws_dynamodb_table.dynamodb_table_users.arn}/stream/*\"\n    }\n  ]\n}\nEOF\n}\n\noutput \"dynamodb_usersIds_arn\" {\n  value = aws_dynamodb_table.dynamodb_table_users.arn\n    description = \"The ARN of the DynamoDB Users Ids table\"\n}\n\noutput \"lambda_processing_arn\" {\n  value = aws_lambda_function.lambda_dynamodb_stream_handler.arn\n    description = \"The ARN of the Lambda function processing the DynamoDB stream\"\n}\n"}, "terraform_output": "Apply failed:\nSTDOUT: \u2577\n\u2502 Error: expected runtime to be one of [\"nodejs\" \"nodejs4.3\" \"nodejs6.10\" \"nodejs8.10\" \"nodejs10.x\" \"nodejs12.x\" \"nodejs14.x\" \"nodejs16.x\" \"java8\" \"java8.al2\" \"java11\" \"python2.7\" \"python3.6\" \"python3.7\" \"python3.8\" \"python3.9\" \"dotnetcore1.0\" \"dotnetcore2.0\" \"dotnetcore2.1\" \"dotnetcore3.1\" \"dotnet6\" \"dotnet8\" \"nodejs4.3-edge\" \"go1.x\" \"ruby2.5\" \"ruby2.7\" \"provided\" \"provided.al2\" \"nodejs18.x\" \"python3.10\" \"java17\" \"ruby3.2\" \"ruby3.3\" \"ruby3.4\" \"python3.11\" \"nodejs20.x\" \"provided.al2023\" \"python3.12\" \"java21\" \"python3.13\" \"nodejs22.x\"], got nodejs24.x\n\u2502 \n\u2502   with aws_lambda_function.lambda_dynamodb_stream_handler,\n\u2502   on main.tf line 43, in resource \"aws_lambda_function\" \"lambda_dynamodb_stream_handler\":\n\u2502   43:   runtime          = \"nodejs24.x\"\n\u2502 \n\u2575\n::error::Terraform exited with code 1.\n\nSTDERR: ", "test_cases": [{"description": "Test that all required AWS resources exist after Terraform deployment.", "name": "test_infrastructure_exists", "readable_name": "Infrastructure Exists"}, {"description": "Test the system health check functionality.", "name": "test_system_health_check", "readable_name": "System Health Check"}, {"description": "Test creating a single user and verify it triggers stream processing.", "name": "test_create_single_user", "readable_name": "Create Single User"}, {"description": "Test various user update operations that trigger stream events.", "name": "test_update_user_operations", "readable_name": "Update User Operations"}, {"description": "Test user deletion that triggers stream events with old image.", "name": "test_delete_user_operation", "readable_name": "Delete User Operation"}, {"description": "Test batch operations that trigger multiple stream events.", "name": "test_batch_user_operations", "readable_name": "Batch User Operations"}, {"description": "Test a complete user lifecycle that triggers multiple stream events.", "name": "test_complete_user_lifecycle", "readable_name": "Complete User Lifecycle"}, {"description": "Test error handling for various failure scenarios.", "name": "test_error_handling_scenarios", "readable_name": "Error Handling Scenarios"}, {"description": "Test that DynamoDB operations generate stream events (indirect verification).", "name": "test_stream_event_generation", "readable_name": "Stream Event Generation"}, {"description": "Test concurrent operations on different users to stress test the system.", "name": "test_concurrent_user_operations", "readable_name": "Concurrent User Operations"}], "test_features": ["AWS SDK", "Assertions", "DynamoDB Operations", "Fixtures"]}, {"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/ced9dfcb174c6a53", "app_files": {"app.py": "import boto3\nimport json\nimport os\nimport logging\nimport time\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\nimport csv\nimport io\n\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\nclass DocumentProcessingPipeline:\n    \"\"\"A document processing pipeline that handles file uploads and processing via S3 and Lambda.\"\"\"\n    \n    def __init__(self, bucket_name: str, function_name: str = \"process-s3-new-objects\"):\n        self.bucket_name = bucket_name\n        self.function_name = function_name\n        \n        # Initialize AWS clients\n        endpoint_url = os.environ.get(\u0027LOCALSTACK_ENDPOINT\u0027, \u0027http://localhost:4566\u0027)\n        \n        self.s3_client = boto3.client(\n            \u0027s3\u0027,\n            endpoint_url=endpoint_url,\n            region_name=\u0027us-east-1\u0027,\n            aws_access_key_id=\u0027test\u0027,\n            aws_secret_access_key=\u0027test\u0027\n        )\n        \n        self.lambda_client = boto3.client(\n            \u0027lambda\u0027,\n            endpoint_url=endpoint_url,\n            region_name=\u0027us-east-1\u0027,\n            aws_access_key_id=\u0027test\u0027,\n            aws_secret_access_key=\u0027test\u0027\n        )\n        \n        self.logs_client = boto3.client(\n            \u0027logs\u0027,\n            endpoint_url=endpoint_url,\n            region_name=\u0027us-east-1\u0027,\n            aws_access_key_id=\u0027test\u0027,\n            aws_secret_access_key=\u0027test\u0027\n        )\n    \n    def upload_document(self, file_content: bytes, key: str, content_type: str = \u0027application/octet-stream\u0027) -\u003e Dict[str, Any]:\n        \"\"\"Upload a document to S3, which will trigger Lambda processing.\"\"\"\n        try:\n            response = self.s3_client.put_object(\n                Bucket=self.bucket_name,\n                Key=key,\n                Body=file_content,\n                ContentType=content_type,\n                Metadata={\n                    \u0027uploaded_at\u0027: datetime.utcnow().isoformat(),\n                    \u0027file_size\u0027: str(len(file_content)),\n                    \u0027processing_status\u0027: \u0027pending\u0027\n                }\n            )\n            \n            logger.info(f\"Successfully uploaded {key} to {self.bucket_name}\")\n            return {\n                \u0027success\u0027: True,\n                \u0027key\u0027: key,\n                \u0027etag\u0027: response.get(\u0027ETag\u0027),\n                \u0027size\u0027: len(file_content)\n            }\n        except Exception as e:\n            logger.error(f\"Failed to upload {key}: {str(e)}\")\n            return {\n                \u0027success\u0027: False,\n                \u0027error\u0027: str(e)\n            }\n    \n    def upload_csv_data(self, csv_content: str, filename: str) -\u003e Dict[str, Any]:\n        \"\"\"Upload CSV data for processing.\"\"\"\n        key = f\"data/csv/{filename}\"\n        return self.upload_document(\n            csv_content.encode(\u0027utf-8\u0027),\n            key,\n            \u0027text/csv\u0027\n        )\n    \n    def upload_json_data(self, json_content: str, filename: str) -\u003e Dict[str, Any]:\n        \"\"\"Upload JSON data for processing.\"\"\"\n        key = f\"data/json/{filename}\"\n        return self.upload_document(\n            json_content.encode(\u0027utf-8\u0027),\n            key,\n            \u0027application/json\u0027\n        )\n    \n    def upload_image(self, image_content: bytes, filename: str) -\u003e Dict[str, Any]:\n        \"\"\"Upload image file for processing.\"\"\"\n        key = f\"images/{filename}\"\n        return self.upload_document(\n            image_content,\n            key,\n            \u0027image/jpeg\u0027\n        )\n    \n    def list_processed_files(self, prefix: str = \"\") -\u003e List[Dict[str, Any]]:\n        \"\"\"List files in the S3 bucket with their metadata.\"\"\"\n        try:\n            response = self.s3_client.list_objects_v2(\n                Bucket=self.bucket_name,\n                Prefix=prefix\n            )\n            \n            files = []\n            for obj in response.get(\u0027Contents\u0027, []):\n                # Get object metadata\n                head_response = self.s3_client.head_object(\n                    Bucket=self.bucket_name,\n                    Key=obj[\u0027Key\u0027]\n                )\n                \n                files.append({\n                    \u0027key\u0027: obj[\u0027Key\u0027],\n                    \u0027size\u0027: obj[\u0027Size\u0027],\n                    \u0027last_modified\u0027: obj[\u0027LastModified\u0027],\n                    \u0027etag\u0027: obj[\u0027ETag\u0027],\n                    \u0027content_type\u0027: head_response.get(\u0027ContentType\u0027),\n                    \u0027metadata\u0027: head_response.get(\u0027Metadata\u0027, {})\n                })\n            \n            return files\n        except Exception as e:\n            logger.error(f\"Failed to list files: {str(e)}\")\n            return []\n    \n    def get_file_content(self, key: str) -\u003e Optional[bytes]:\n        \"\"\"Retrieve file content from S3.\"\"\"\n        try:\n            response = self.s3_client.get_object(\n                Bucket=self.bucket_name,\n                Key=key\n            )\n            return response[\u0027Body\u0027].read()\n        except Exception as e:\n            logger.error(f\"Failed to get file {key}: {str(e)}\")\n            return None\n    \n    def wait_for_lambda_execution(self, timeout: int = 30) -\u003e bool:\n        \"\"\"Wait for Lambda function to be executed by checking CloudWatch logs.\"\"\"\n        start_time = time.time()\n        log_group_name = f\"/aws/lambda/{self.function_name}\"\n        \n        while time.time() - start_time \u003c timeout:\n            try:\n                # Check if log group exists\n                self.logs_client.describe_log_groups(\n                    logGroupNamePrefix=log_group_name\n                )\n                \n                # Get recent log streams\n                streams_response = self.logs_client.describe_log_streams(\n                    logGroupName=log_group_name,\n                    orderBy=\u0027LastEventTime\u0027,\n                    descending=True,\n                    limit=5\n                )\n                \n                if streams_response[\u0027logStreams\u0027]:\n                    return True\n                    \n            except self.logs_client.exceptions.ResourceNotFoundException:\n                pass  # Log group doesn\u0027t exist yet\n            except Exception as e:\n                logger.debug(f\"Error checking logs: {str(e)}\")\n            \n            time.sleep(2)\n        \n        return False\n    \n    def process_employee_data(self, csv_data: str) -\u003e Dict[str, Any]:\n        \"\"\"Process employee CSV data through the pipeline.\"\"\"\n        # Upload the CSV file\n        upload_result = self.upload_csv_data(csv_data, f\"employees_{int(time.time())}.csv\")\n        \n        if not upload_result[\u0027success\u0027]:\n            return upload_result\n        \n        # Wait for processing\n        processing_completed = self.wait_for_lambda_execution()\n        \n        # Parse CSV to provide summary\n        reader = csv.DictReader(io.StringIO(csv_data))\n        employees = list(reader)\n        \n        return {\n            \u0027success\u0027: True,\n            \u0027upload_key\u0027: upload_result[\u0027key\u0027],\n            \u0027processing_triggered\u0027: processing_completed,\n            \u0027summary\u0027: {\n                \u0027total_employees\u0027: len(employees),\n                \u0027departments\u0027: list(set(emp.get(\u0027department\u0027, \u0027\u0027) for emp in employees)),\n                \u0027avg_salary\u0027: sum(float(emp.get(\u0027salary\u0027, 0)) for emp in employees) / len(employees) if employees else 0\n            }\n        }\n    \n    def process_transaction_data(self, json_data: str) -\u003e Dict[str, Any]:\n        \"\"\"Process transaction JSON data through the pipeline.\"\"\"\n        # Upload the JSON file\n        upload_result = self.upload_json_data(json_data, f\"transaction_{int(time.time())}.json\")\n        \n        if not upload_result[\u0027success\u0027]:\n            return upload_result\n        \n        # Wait for processing\n        processing_completed = self.wait_for_lambda_execution()\n        \n        # Parse JSON to provide summary\n        try:\n            transaction = json.loads(json_data)\n            return {\n                \u0027success\u0027: True,\n                \u0027upload_key\u0027: upload_result[\u0027key\u0027],\n                \u0027processing_triggered\u0027: processing_completed,\n                \u0027summary\u0027: {\n                    \u0027transaction_id\u0027: transaction.get(\u0027transaction_id\u0027),\n                    \u0027amount\u0027: transaction.get(\u0027amount\u0027),\n                    \u0027currency\u0027: transaction.get(\u0027currency\u0027),\n                    \u0027items_count\u0027: len(transaction.get(\u0027items\u0027, [])),\n                    \u0027timestamp\u0027: transaction.get(\u0027timestamp\u0027)\n                }\n            }\n        except json.JSONDecodeError as e:\n            return {\n                \u0027success\u0027: False,\n                \u0027error\u0027: f\"Invalid JSON data: {str(e)}\"\n            }\n    \n    def process_image_batch(self, images: List[tuple]) -\u003e Dict[str, Any]:\n        \"\"\"Process a batch of images through the pipeline.\"\"\"\n        results = []\n        \n        for image_content, filename in images:\n            upload_result = self.upload_image(image_content, filename)\n            results.append({\n                \u0027filename\u0027: filename,\n                \u0027upload_success\u0027: upload_result[\u0027success\u0027],\n                \u0027size\u0027: len(image_content),\n                \u0027key\u0027: upload_result.get(\u0027key\u0027)\n            })\n        \n        # Wait for processing\n        processing_completed = self.wait_for_lambda_execution()\n        \n        return {\n            \u0027success\u0027: True,\n            \u0027batch_size\u0027: len(images),\n            \u0027processing_triggered\u0027: processing_completed,\n            \u0027results\u0027: results,\n            \u0027total_size\u0027: sum(len(img[0]) for img in images)\n        }\n    \n    def get_processing_summary(self) -\u003e Dict[str, Any]:\n        \"\"\"Get a summary of all processed files.\"\"\"\n        files = self.list_processed_files()\n        \n        summary = {\n            \u0027total_files\u0027: len(files),\n            \u0027total_size\u0027: sum(f[\u0027size\u0027] for f in files),\n            \u0027file_types\u0027: {},\n            \u0027by_folder\u0027: {}\n        }\n        \n        for file_info in files:\n            # Count by content type\n            content_type = file_info.get(\u0027content_type\u0027, \u0027unknown\u0027)\n            summary[\u0027file_types\u0027][content_type] = summary[\u0027file_types\u0027].get(content_type, 0) + 1\n            \n            # Count by folder\n            folder = file_info[\u0027key\u0027].split(\u0027/\u0027)[0] if \u0027/\u0027 in file_info[\u0027key\u0027] else \u0027root\u0027\n            summary[\u0027by_folder\u0027][folder] = summary[\u0027by_folder\u0027].get(folder, 0) + 1\n        \n        return summary\n    \n    def cleanup_test_data(self, prefix: str = \"\") -\u003e Dict[str, Any]:\n        \"\"\"Clean up test data from S3 bucket.\"\"\"\n        try:\n            files = self.list_processed_files(prefix)\n            deleted_count = 0\n            \n            for file_info in files:\n                self.s3_client.delete_object(\n                    Bucket=self.bucket_name,\n                    Key=file_info[\u0027key\u0027]\n                )\n                deleted_count += 1\n            \n            return {\n                \u0027success\u0027: True,\n                \u0027deleted_files\u0027: deleted_count\n            }\n        except Exception as e:\n            return {\n                \u0027success\u0027: False,\n                \u0027error\u0027: str(e)\n            }", "conftest.py": "import pytest\nimport boto3\nimport os\nimport tempfile\nimport json\nfrom typing import Generator\n\n\n@pytest.fixture\ndef aws_credentials():\n    \"\"\"Set AWS credentials for LocalStack.\"\"\"\n    os.environ[\u0027AWS_ACCESS_KEY_ID\u0027] = \u0027test\u0027\n    os.environ[\u0027AWS_SECRET_ACCESS_KEY\u0027] = \u0027test\u0027\n    os.environ[\u0027AWS_DEFAULT_REGION\u0027] = \u0027us-east-1\u0027\n\n\n@pytest.fixture\ndef s3_client(aws_credentials):\n    \"\"\"Create S3 client for LocalStack.\"\"\"\n    return boto3.client(\n        \u0027s3\u0027,\n        endpoint_url=os.environ.get(\u0027LOCALSTACK_ENDPOINT\u0027, \u0027http://localhost:4566\u0027),\n        region_name=\u0027us-east-1\u0027,\n        aws_access_key_id=\u0027test\u0027,\n        aws_secret_access_key=\u0027test\u0027\n    )\n\n\n@pytest.fixture\ndef lambda_client(aws_credentials):\n    \"\"\"Create Lambda client for LocalStack.\"\"\"\n    return boto3.client(\n        \u0027lambda\u0027,\n        endpoint_url=os.environ.get(\u0027LOCALSTACK_ENDPOINT\u0027, \u0027http://localhost:4566\u0027),\n        region_name=\u0027us-east-1\u0027,\n        aws_access_key_id=\u0027test\u0027,\n        aws_secret_access_key=\u0027test\u0027\n    )\n\n\n@pytest.fixture\ndef iam_client(aws_credentials):\n    \"\"\"Create IAM client for LocalStack.\"\"\"\n    return boto3.client(\n        \u0027iam\u0027,\n        endpoint_url=os.environ.get(\u0027LOCALSTACK_ENDPOINT\u0027, \u0027http://localhost:4566\u0027),\n        region_name=\u0027us-east-1\u0027,\n        aws_access_key_id=\u0027test\u0027,\n        aws_secret_access_key=\u0027test\u0027\n    )\n\n\n@pytest.fixture\ndef logs_client(aws_credentials):\n    \"\"\"Create CloudWatch Logs client for LocalStack.\"\"\"\n    return boto3.client(\n        \u0027logs\u0027,\n        endpoint_url=os.environ.get(\u0027LOCALSTACK_ENDPOINT\u0027, \u0027http://localhost:4566\u0027),\n        region_name=\u0027us-east-1\u0027,\n        aws_access_key_id=\u0027test\u0027,\n        aws_secret_access_key=\u0027test\u0027\n    )\n\n\n@pytest.fixture\ndef sample_image_data() -\u003e bytes:\n    \"\"\"Generate sample image data for testing.\"\"\"\n    # Simple bitmap header + data for a 2x2 pixel image\n    return b\u0027\\x42\\x4d\\x3a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x36\\x00\\x00\\x00\\x28\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x01\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xff\\x00\\x00\\x00\\x00\\xff\\x00\\x00\\x00\\xff\\x00\\xff\\x00\\x00\u0027\n\n\n@pytest.fixture\ndef sample_csv_data() -\u003e str:\n    \"\"\"Generate sample CSV data for testing.\"\"\"\n    return \"\"\"name,email,age,department,salary\nJohn Doe,john.doe@company.com,28,Engineering,75000\nJane Smith,jane.smith@company.com,32,Marketing,68000\nBob Johnson,bob.johnson@company.com,45,Sales,82000\nAlice Williams,alice.williams@company.com,29,Engineering,77000\nCharlie Brown,charlie.brown@company.com,38,Finance,71000\"\"\"\n\n\n@pytest.fixture\ndef sample_json_data() -\u003e str:\n    \"\"\"Generate sample JSON data for testing.\"\"\"\n    return json.dumps({\n        \"transaction_id\": \"txn_12345\",\n        \"user_id\": \"user_67890\",\n        \"amount\": 129.99,\n        \"currency\": \"USD\",\n        \"timestamp\": \"2024-01-15T10:30:00Z\",\n        \"items\": [\n            {\"id\": \"item_1\", \"name\": \"Product A\", \"price\": 59.99, \"quantity\": 1},\n            {\"id\": \"item_2\", \"name\": \"Product B\", \"price\": 70.00, \"quantity\": 1}\n        ],\n        \"shipping_address\": {\n            \"street\": \"123 Main St\",\n            \"city\": \"Anytown\",\n            \"state\": \"CA\",\n            \"zip\": \"12345\"\n        }\n    }, indent=2)\n\n\n@pytest.fixture\ndef temp_file() -\u003e Generator[str, None, None]:\n    \"\"\"Create a temporary file for testing.\"\"\"\n    with tempfile.NamedTemporaryFile(delete=False) as f:\n        yield f.name\n    os.unlink(f.name)", "requirements.txt": "boto3==1.34.34\npytest==7.4.4\npytest-asyncio==0.23.4\nbotocore==1.34.34", "test_app.py": "import pytest\nimport json\nimport time\nfrom app import DocumentProcessingPipeline\n\n\nclass TestDocumentProcessingPipeline:\n    \"\"\"Integration tests for the document processing pipeline.\"\"\"\n    \n    @pytest.fixture\n    def pipeline(self, s3_client, lambda_client):\n        \"\"\"Create a pipeline instance with a dynamically discovered bucket name.\"\"\"\n        # Try to find the bucket created by Terraform\n        buckets = s3_client.list_buckets()[\u0027Buckets\u0027]\n        bucket_name = None\n        \n        for bucket in buckets:\n            if bucket[\u0027Name\u0027].startswith(\u0027my-bucket-\u0027):\n                bucket_name = bucket[\u0027Name\u0027]\n                break\n        \n        if not bucket_name:\n            pytest.skip(\"S3 bucket not found - ensure Terraform has been applied\")\n        \n        return DocumentProcessingPipeline(bucket_name)\n    \n    def test_infrastructure_resources_exist(self, s3_client, lambda_client, iam_client):\n        \"\"\"Test that all required infrastructure resources exist.\"\"\"\n        # Check S3 bucket exists\n        buckets = s3_client.list_buckets()[\u0027Buckets\u0027]\n        bucket_names = [bucket[\u0027Name\u0027] for bucket in buckets]\n        assert any(name.startswith(\u0027my-bucket-\u0027) for name in bucket_names), \"S3 bucket not found\"\n        \n        # Check Lambda function exists\n        try:\n            response = lambda_client.get_function(FunctionName=\u0027process-s3-new-objects\u0027)\n            assert response[\u0027Configuration\u0027][\u0027FunctionName\u0027] == \u0027process-s3-new-objects\u0027\n            assert response[\u0027Configuration\u0027][\u0027Runtime\u0027] == \u0027nodejs16.x\u0027\n            assert response[\u0027Configuration\u0027][\u0027Handler\u0027] == \u0027index.handler\u0027\n        except lambda_client.exceptions.ResourceNotFoundException:\n            pytest.fail(\"Lambda function \u0027process-s3-new-objects\u0027 not found\")\n        \n        # Check IAM role exists\n        try:\n            response = iam_client.get_role(RoleName=\u0027iam_for_lambda\u0027)\n            assert response[\u0027Role\u0027][\u0027RoleName\u0027] == \u0027iam_for_lambda\u0027\n        except iam_client.exceptions.NoSuchEntityException:\n            pytest.fail(\"IAM role \u0027iam_for_lambda\u0027 not found\")\n    \n    def test_csv_employee_data_processing(self, pipeline, sample_csv_data):\n        \"\"\"Test processing employee CSV data through the pipeline.\"\"\"\n        result = pipeline.process_employee_data(sample_csv_data)\n        \n        assert result[\u0027success\u0027] is True\n        assert \u0027upload_key\u0027 in result\n        assert result[\u0027upload_key\u0027].startswith(\u0027data/csv/\u0027)\n        \n        # Verify summary data\n        summary = result[\u0027summary\u0027]\n        assert summary[\u0027total_employees\u0027] == 5\n        assert \u0027Engineering\u0027 in summary[\u0027departments\u0027]\n        assert \u0027Marketing\u0027 in summary[\u0027departments\u0027]\n        assert summary[\u0027avg_salary\u0027] \u003e 0\n        \n        # Verify file was uploaded to S3\n        files = pipeline.list_processed_files(\u0027data/csv/\u0027)\n        assert len(files) \u003e 0\n        csv_file = next((f for f in files if f[\u0027key\u0027] == result[\u0027upload_key\u0027]), None)\n        assert csv_file is not None\n        assert csv_file[\u0027content_type\u0027] == \u0027text/csv\u0027\n    \n    def test_json_transaction_data_processing(self, pipeline, sample_json_data):\n        \"\"\"Test processing transaction JSON data through the pipeline.\"\"\"\n        result = pipeline.process_transaction_data(sample_json_data)\n        \n        assert result[\u0027success\u0027] is True\n        assert \u0027upload_key\u0027 in result\n        assert result[\u0027upload_key\u0027].startswith(\u0027data/json/\u0027)\n        \n        # Verify summary data\n        summary = result[\u0027summary\u0027]\n        assert summary[\u0027transaction_id\u0027] == \u0027txn_12345\u0027\n        assert summary[\u0027amount\u0027] == 129.99\n        assert summary[\u0027currency\u0027] == \u0027USD\u0027\n        assert summary[\u0027items_count\u0027] == 2\n        \n        # Verify file was uploaded to S3\n        files = pipeline.list_processed_files(\u0027data/json/\u0027)\n        assert len(files) \u003e 0\n        json_file = next((f for f in files if f[\u0027key\u0027] == result[\u0027upload_key\u0027]), None)\n        assert json_file is not None\n        assert json_file[\u0027content_type\u0027] == \u0027application/json\u0027\n    \n    def test_image_batch_processing(self, pipeline, sample_image_data):\n        \"\"\"Test processing a batch of images through the pipeline.\"\"\"\n        images = [\n            (sample_image_data, \u0027test_image_1.bmp\u0027),\n            (sample_image_data, \u0027test_image_2.bmp\u0027),\n            (sample_image_data, \u0027test_image_3.bmp\u0027)\n        ]\n        \n        result = pipeline.process_image_batch(images)\n        \n        assert result[\u0027success\u0027] is True\n        assert result[\u0027batch_size\u0027] == 3\n        assert len(result[\u0027results\u0027]) == 3\n        \n        # Verify all images were uploaded successfully\n        for img_result in result[\u0027results\u0027]:\n            assert img_result[\u0027upload_success\u0027] is True\n            assert img_result[\u0027key\u0027].startswith(\u0027images/\u0027)\n            assert img_result[\u0027size\u0027] == len(sample_image_data)\n        \n        # Verify files exist in S3\n        files = pipeline.list_processed_files(\u0027images/\u0027)\n        assert len(files) \u003e= 3\n    \n    def test_file_upload_and_retrieval(self, pipeline, sample_csv_data):\n        \"\"\"Test uploading and retrieving file content.\"\"\"\n        # Upload a test file\n        test_content = \"test,data,file\\n1,2,3\\n4,5,6\"\n        upload_result = pipeline.upload_csv_data(test_content, \u0027test_retrieval.csv\u0027)\n        \n        assert upload_result[\u0027success\u0027] is True\n        \n        # Retrieve the file content\n        retrieved_content = pipeline.get_file_content(upload_result[\u0027key\u0027])\n        assert retrieved_content is not None\n        assert retrieved_content.decode(\u0027utf-8\u0027) == test_content\n    \n    def test_processing_summary_generation(self, pipeline, sample_csv_data, sample_json_data):\n        \"\"\"Test generating processing summary after uploading various files.\"\"\"\n        # Upload different types of files\n        pipeline.upload_csv_data(sample_csv_data, \u0027summary_test.csv\u0027)\n        pipeline.upload_json_data(sample_json_data, \u0027summary_test.json\u0027)\n        \n        # Get processing summary\n        summary = pipeline.get_processing_summary()\n        \n        assert summary[\u0027total_files\u0027] \u003e 0\n        assert summary[\u0027total_size\u0027] \u003e 0\n        assert \u0027file_types\u0027 in summary\n        assert \u0027by_folder\u0027 in summary\n        \n        # Should have at least CSV and JSON files\n        assert \u0027text/csv\u0027 in summary[\u0027file_types\u0027] or len([f for f in summary[\u0027file_types\u0027] if \u0027csv\u0027 in f.lower()]) \u003e 0\n        assert \u0027application/json\u0027 in summary[\u0027file_types\u0027] or len([f for f in summary[\u0027file_types\u0027] if \u0027json\u0027 in f.lower()]) \u003e 0\n    \n    def test_error_handling_invalid_json(self, pipeline):\n        \"\"\"Test error handling with invalid JSON data.\"\"\"\n        invalid_json = \u0027{\"invalid\": json data}\u0027\n        result = pipeline.process_transaction_data(invalid_json)\n        \n        assert result[\u0027success\u0027] is False\n        assert \u0027error\u0027 in result\n        assert \u0027Invalid JSON data\u0027 in result[\u0027error\u0027]\n    \n    def test_lambda_trigger_detection(self, pipeline, sample_csv_data):\n        \"\"\"Test that Lambda function execution is properly detected.\"\"\"\n        # Upload a file to trigger Lambda\n        result = pipeline.upload_csv_data(sample_csv_data, \u0027lambda_trigger_test.csv\u0027)\n        assert result[\u0027success\u0027] is True\n        \n        # Check if Lambda execution can be detected\n        # Note: In LocalStack, this might not work exactly like AWS, but we test the mechanism\n        execution_detected = pipeline.wait_for_lambda_execution(timeout=10)\n        # We don\u0027t assert this because LocalStack might not have the exact same log behavior\n        # but we verify the method works without errors\n        assert isinstance(execution_detected, bool)\n    \n    def test_file_listing_with_metadata(self, pipeline, sample_csv_data):\n        \"\"\"Test listing files with their metadata.\"\"\"\n        # Upload a test file\n        upload_result = pipeline.upload_csv_data(sample_csv_data, \u0027metadata_test.csv\u0027)\n        assert upload_result[\u0027success\u0027] is True\n        \n        # List files and check metadata\n        files = pipeline.list_processed_files(\u0027data/csv/\u0027)\n        test_file = next((f for f in files if \u0027metadata_test.csv\u0027 in f[\u0027key\u0027]), None)\n        \n        assert test_file is not None\n        assert \u0027size\u0027 in test_file\n        assert \u0027last_modified\u0027 in test_file\n        assert \u0027content_type\u0027 in test_file\n        assert test_file[\u0027content_type\u0027] == \u0027text/csv\u0027\n        assert \u0027metadata\u0027 in test_file\n    \n    def test_cleanup_functionality(self, pipeline, sample_csv_data):\n        \"\"\"Test cleanup functionality for removing test data.\"\"\"\n        # Upload some test files\n        test_prefix = \u0027cleanup_test/\u0027\n        pipeline.upload_document(\n            sample_csv_data.encode(\u0027utf-8\u0027),\n            f\u0027{test_prefix}file1.csv\u0027,\n            \u0027text/csv\u0027\n        )\n        pipeline.upload_document(\n            sample_csv_data.encode(\u0027utf-8\u0027),\n            f\u0027{test_prefix}file2.csv\u0027,\n            \u0027text/csv\u0027\n        )\n        \n        # Verify files exist\n        files_before = pipeline.list_processed_files(test_prefix)\n        assert len(files_before) \u003e= 2\n        \n        # Cleanup\n        cleanup_result = pipeline.cleanup_test_data(test_prefix)\n        assert cleanup_result[\u0027success\u0027] is True\n        assert cleanup_result[\u0027deleted_files\u0027] \u003e= 2\n        \n        # Verify files are gone\n        files_after = pipeline.list_processed_files(test_prefix)\n        assert len(files_after) == 0"}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/ced9dfcb174c6a53", "duration": 7.369603, "failure_analysis": {"affected_resource": null, "affected_service": null, "aws_error_code": null, "category": "failed", "error_message": "Unsupported argument \u2502  \u2502   on localstack_providers_override.tf line 23, in provider \"aws\": \u2502   23:     bedrock = \"http://localhost:5130\" \u2502  \u2502 An argument named \"bedrock\" is not expected here. \u2575 \u2577 \u2502 Error: Unsupported argument \u2502  \u2502   on localstack_providers_override.tf line 24, in provider \"aws\": \u2502 ", "is_localstack_issue": true}, "hash": "ced9dfcb174c6a53", "logs": "\nLocalStack version: 4.12.1.dev56\nLocalStack build date: 2026-01-09\nLocalStack build git hash: 0b2a5d188\n\nReady.\n", "name": "aws-samples/serverless-patterns/s3-lambda-terraform", "original_format": null, "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["iam", "lambda", "s3"], "source_type": "github_repos", "source_url": "https://github.com/aws-samples/serverless-patterns/tree/main/s3-lambda-terraform", "status": "FAILED", "terraform_files": {"main.tf": "terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~\u003e 3.27\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"3.1.0\"\n    }\n  }\n\n  required_version = \"\u003e= 0.14.9\"\n}\n\nprovider \"aws\" {\n  profile = \"default\"\n  region  = \"us-east-1\"\n}\n\nresource \"random_string\" \"random\" {\n  length  = 8\n  special = false\n  lower   = true\n  number  = true\n  upper   = false\n}\n\nresource \"aws_lambda_function\" \"lambda_s3_handler\" {\n  function_name    = \"process-s3-new-objects\"\n  filename         = data.archive_file.lambda_zip_file.output_path\n  source_code_hash = data.archive_file.lambda_zip_file.output_base64sha256\n  handler          = \"index.handler\"\n  role             = aws_iam_role.iam_for_lambda.arn\n  runtime          = \"nodejs16.x\"\n}\n\ndata \"archive_file\" \"lambda_zip_file\" {\n  type        = \"zip\"\n  source_file = \"${path.module}/src/index.js\"\n  output_path = \"${path.module}/lambda.zip\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = \u003c\u003cEOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": \"sts:AssumeRole\",\n      \"Principal\": {\n        \"Service\": \"lambda.amazonaws.com\"\n      },\n      \"Effect\": \"Allow\",\n      \"Sid\": \"\"\n    }\n  ]\n}\nEOF\n  inline_policy {\n    name   = \"lambda_logs_policy\"\n    policy = \u003c\u003cEOF\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n        \"Sid\": \"AllowLambdaFunctionToCreateLogs\",\n        \"Action\": [ \n            \"logs:*\" \n        ],\n        \"Effect\": \"Allow\",\n        \"Resource\": [ \n            \"arn:aws:logs:*:*:*\" \n        ]\n    }\n  ]\n}\nEOF\n  }\n}\n\nresource \"aws_lambda_permission\" \"allow_bucket_invoke_lambda\" {\n  statement_id  = \"AllowExecutionFromS3Bucket\"\n  action        = \"lambda:InvokeFunction\"\n  function_name = aws_lambda_function.lambda_s3_handler.arn\n  principal     = \"s3.amazonaws.com\"\n  source_arn    = aws_s3_bucket.my_bucket.arn\n}\n\nresource \"aws_s3_bucket\" \"my_bucket\" {\n  bucket = \"my-bucket-${random_string.random.result}\"\n}\n\nresource \"aws_s3_bucket_notification\" \"bucket_notification\" {\n  bucket = aws_s3_bucket.my_bucket.id\n\n  lambda_function {\n    lambda_function_arn = aws_lambda_function.lambda_s3_handler.arn\n    events              = [\"s3:ObjectCreated:*\"]\n  }\n\n  depends_on = [aws_lambda_permission.allow_bucket_invoke_lambda]\n}\n\noutput \"name_of_bucket\" {\n  value       = aws_s3_bucket.my_bucket.bucket\n  description = \"The name of the bucket\"\n}\n"}, "terraform_output": "Apply failed:\nSTDOUT: data.archive_file.lambda_zip_file: Reading...\n\nTerraform used the selected providers to generate the following execution\nplan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform planned the following actions, but then encountered a problem:\n\n  # random_string.random will be created\n  + resource \"random_string\" \"random\" {\n      + id          = (known after apply)\n      + length      = 8\n      + lower       = true\n      + min_lower   = 0\n      + min_numeric = 0\n      + min_special = 0\n      + min_upper   = 0\n      + number      = true\n      + result      = (known after apply)\n      + special     = false\n      + upper       = false\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 23, in provider \"aws\":\n\u2502   23:     bedrock = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"bedrock\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 24, in provider \"aws\":\n\u2502   24:     ce = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"ce\" is not expected here. Did you mean \"ds\"?\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 33, in provider \"aws\":\n\u2502   33:     codeconnections = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"codeconnections\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 38, in provider \"aws\":\n\u2502   38:     deploy = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"deploy\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 63, in provider \"aws\":\n\u2502   63:     keyspaces = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"keyspaces\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 70, in provider \"aws\":\n\u2502   70:     logs = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"logs\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 77, in provider \"aws\":\n\u2502   77:     opensearch = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"opensearch\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 80, in provider \"aws\":\n\u2502   80:     pipes = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"pipes\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 93, in provider \"aws\":\n\u2502   93:     s3tables = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"s3tables\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 95, in provider \"aws\":\n\u2502   95:     scheduler = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"scheduler\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Unsupported argument\n\u2502 \n\u2502   on localstack_providers_override.tf line 111, in provider \"aws\":\n\u2502  111:     verifiedpermissions = \"http://localhost:5130\"\n\u2502 \n\u2502 An argument named \"verifiedpermissions\" is not expected here.\n\u2575\n\u2577\n\u2502 Error: Archive creation error\n\u2502 \n\u2502   with data.archive_file.lambda_zip_file,\n\u2502   on main.tf line 38, in data \"archive_file\" \"lambda_zip_file\":\n\u2502   38: data \"archive_file\" \"lambda_zip_file\" {\n\u2502 \n\u2502 error creating archive: error archiving file: could not archive missing\n\u2502 file: ./src/index.js\n\u2575\n::error::Terraform exited with code 1.\n\nSTDERR: ", "test_cases": [{"description": "Test that all required infrastructure resources exist.", "name": "test_infrastructure_resources_exist", "readable_name": "Infrastructure Resources Exist"}, {"description": "Test processing employee CSV data through the pipeline.", "name": "test_csv_employee_data_processing", "readable_name": "Csv Employee Data Processing"}, {"description": "Test processing transaction JSON data through the pipeline.", "name": "test_json_transaction_data_processing", "readable_name": "Json Transaction Data Processing"}, {"description": "Test processing a batch of images through the pipeline.", "name": "test_image_batch_processing", "readable_name": "Image Batch Processing"}, {"description": "Test uploading and retrieving file content.", "name": "test_file_upload_and_retrieval", "readable_name": "File Upload And Retrieval"}, {"description": "Test generating processing summary after uploading various files.", "name": "test_processing_summary_generation", "readable_name": "Processing Summary Generation"}, {"description": "Test error handling with invalid JSON data.", "name": "test_error_handling_invalid_json", "readable_name": "Error Handling Invalid Json"}, {"description": "Test that Lambda function execution is properly detected.", "name": "test_lambda_trigger_detection", "readable_name": "Lambda Trigger Detection"}, {"description": "Test listing files with their metadata.", "name": "test_file_listing_with_metadata", "readable_name": "File Listing With Metadata"}, {"description": "Test cleanup functionality for removing test data.", "name": "test_cleanup_functionality", "readable_name": "Cleanup Functionality"}], "test_features": ["AWS SDK", "Assertions", "Fixtures", "S3 Operations"]}, {"app_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/apps/simple_s3_test", "app_files": {"app.py": "\"\"\"Simple S3 application code.\"\"\"\nimport os\nimport boto3\n\n\ndef get_s3_client():\n    \"\"\"Get S3 client configured for LocalStack.\"\"\"\n    endpoint = os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n    return boto3.client(\n        \"s3\",\n        endpoint_url=endpoint,\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\",\n        region_name=\"us-east-1\",\n    )\n\n\ndef list_buckets():\n    \"\"\"List all S3 buckets.\"\"\"\n    client = get_s3_client()\n    response = client.list_buckets()\n    return [b[\"Name\"] for b in response.get(\"Buckets\", [])]\n\n\ndef create_test_object(bucket_name, key, content):\n    \"\"\"Create a test object in a bucket.\"\"\"\n    client = get_s3_client()\n    client.put_object(Bucket=bucket_name, Key=key, Body=content)\n\n\ndef get_test_object(bucket_name, key):\n    \"\"\"Get a test object from a bucket.\"\"\"\n    client = get_s3_client()\n    response = client.get_object(Bucket=bucket_name, Key=key)\n    return response[\"Body\"].read().decode(\"utf-8\")\n", "conftest.py": "\"\"\"Pytest fixtures for S3 bucket testing.\"\"\"\nimport os\nimport boto3\nimport pytest\n\n\n@pytest.fixture(scope=\"session\")\ndef localstack_endpoint():\n    \"\"\"Get LocalStack endpoint from environment.\"\"\"\n    return os.environ.get(\"LOCALSTACK_ENDPOINT\", \"http://localhost:4566\")\n\n\n@pytest.fixture(scope=\"session\")\ndef s3_client(localstack_endpoint):\n    \"\"\"Create S3 client configured for LocalStack.\"\"\"\n    return boto3.client(\n        \"s3\",\n        endpoint_url=localstack_endpoint,\n        aws_access_key_id=\"test\",\n        aws_secret_access_key=\"test\",\n        region_name=\"us-east-1\",\n    )\n", "requirements.txt": "pytest\u003e=8.0\nboto3\u003e=1.35\n", "test_app.py": "\"\"\"Tests for simple S3 infrastructure.\"\"\"\nimport pytest\n\n\ndef test_s3_bucket_exists(s3_client):\n    \"\"\"Test that at least one S3 bucket exists after terraform apply.\"\"\"\n    response = s3_client.list_buckets()\n    buckets = response.get(\"Buckets\", [])\n    assert len(buckets) \u003e= 1, \"Expected at least one S3 bucket\"\n    \n    # Check that our test bucket exists (starts with lsqm-test-bucket)\n    bucket_names = [b[\"Name\"] for b in buckets]\n    test_buckets = [name for name in bucket_names if name.startswith(\"lsqm-test-bucket\")]\n    assert len(test_buckets) \u003e= 1, f\"Expected test bucket, found: {bucket_names}\"\n\n\ndef test_s3_put_and_get_object(s3_client):\n    \"\"\"Test that we can put and get objects from the bucket.\"\"\"\n    response = s3_client.list_buckets()\n    buckets = response.get(\"Buckets\", [])\n    \n    # Find our test bucket\n    bucket_names = [b[\"Name\"] for b in buckets]\n    test_bucket = next((name for name in bucket_names if name.startswith(\"lsqm-test-bucket\")), None)\n    \n    if test_bucket is None:\n        pytest.skip(\"No test bucket found\")\n    \n    # Put an object\n    test_content = \"Hello from LSQM test!\"\n    s3_client.put_object(\n        Bucket=test_bucket,\n        Key=\"test-object.txt\",\n        Body=test_content.encode()\n    )\n    \n    # Get the object back\n    response = s3_client.get_object(Bucket=test_bucket, Key=\"test-object.txt\")\n    retrieved_content = response[\"Body\"].read().decode(\"utf-8\")\n    \n    assert retrieved_content == test_content\n\n\ndef test_s3_list_objects(s3_client):\n    \"\"\"Test that we can list objects in the bucket.\"\"\"\n    response = s3_client.list_buckets()\n    buckets = response.get(\"Buckets\", [])\n    \n    bucket_names = [b[\"Name\"] for b in buckets]\n    test_bucket = next((name for name in bucket_names if name.startswith(\"lsqm-test-bucket\")), None)\n    \n    if test_bucket is None:\n        pytest.skip(\"No test bucket found\")\n    \n    # List objects\n    response = s3_client.list_objects_v2(Bucket=test_bucket)\n    # Should work without error\n    assert response[\"ResponseMetadata\"][\"HTTPStatusCode\"] == 200\n"}, "arch_artifact_url": "https://github.com/lazarkanelov/ls-arch-artifacts /tree/main/architectures/simple_s3_test", "duration": 62.328134, "failure_analysis": null, "hash": "simple_s3_test", "logs": "", "name": "Simple S3 Test", "original_format": "terraform", "pytest_failed": 0, "pytest_output": "", "pytest_passed": 0, "services": ["s3"], "source_type": "custom", "source_url": "local://simple_s3_test", "status": "PASSED", "terraform_files": {"main.tf": "# Simple S3 bucket - tflocal handles LocalStack endpoints automatically\nterraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~\u003e 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_s3_bucket\" \"test_bucket\" {\n  bucket = \"lsqm-test-bucket-simple\"\n}\n\noutput \"bucket_name\" {\n  value = aws_s3_bucket.test_bucket.id\n}\n"}, "terraform_output": "\nTerraform used the selected providers to generate the following execution\nplan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # aws_s3_bucket.test_bucket will be created\n  + resource \"aws_s3_bucket\" \"test_bucket\" {\n      + acceleration_status         = (known after apply)\n      + acl                         = (known after apply)\n      + arn                         = (known after apply)\n      + bucket                      = \"lsqm-test-bucket-simple\"\n      + bucket_domain_name          = (known after apply)\n      + bucket_prefix               = (known after apply)\n      + bucket_regional_domain_name = (known after apply)\n      + force_destroy               = false\n      + hosted_zone_id              = (known after apply)\n      + id                          = (known after apply)\n      + object_lock_enabled         = (known after apply)\n      + policy                      = (known after apply)\n      + region                      = (known after apply)\n      + request_payer               = (known after apply)\n      + tags_all                    = (known after apply)\n      + website_domain              = (known after apply)\n      + website_endpoint            = (known after apply)\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n  + bucket_name = (known after apply)\naws_s3_bucket.test_bucket: Creating...\naws_s3_bucket.test_bucket: Creation complete after 0s [id=lsqm-test-bucket-simple]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n\nOutputs:\n\nbucket_name = \"lsqm-test-bucket-simple\"\n", "test_cases": [{"description": "Test that at least one S3 bucket exists after terraform apply.", "name": "test_s3_bucket_exists", "readable_name": "S3 Bucket Exists"}, {"description": "Test that we can put and get objects from the bucket.", "name": "test_s3_put_and_get_object", "readable_name": "S3 Put And Get Object"}, {"description": "Test that we can list objects in the bucket.", "name": "test_s3_list_objects", "readable_name": "S3 List Objects"}], "test_features": ["AWS SDK", "Assertions", "Fixtures", "S3 Operations"]}],
                openDrawer(arch) {
                    this.selectedArch = arch;
                    this.drawerOpen = true;
                    // Trigger Prism highlighting after drawer opens
                    this.$nextTick(() => {
                        if (typeof Prism !== 'undefined') {
                            Prism.highlightAll();
                        }
                    });
                },
                get filteredArchitectures() {
                    let result = this.architectures.filter(arch => {
                        const matchesSearch = arch.name.toLowerCase().includes(this.searchQuery.toLowerCase()) ||
                                              arch.hash.toLowerCase().includes(this.searchQuery.toLowerCase());
                        const matchesStatus = this.statusFilter === 'all' ||
                            (this.statusFilter === 'passed' && arch.status === 'PASSED') ||
                            (this.statusFilter === 'failed' && ['FAILED', 'TIMEOUT', 'ERROR'].includes(arch.status));
                        return matchesSearch && matchesStatus;
                    });

                    if (this.sortBy === 'name') {
                        result.sort((a, b) => a.name.localeCompare(b.name));
                    } else if (this.sortBy === 'status') {
                        const order = {'FAILED': 0, 'TIMEOUT': 1, 'ERROR': 2, 'PARTIAL': 3, 'PASSED': 4};
                        result.sort((a, b) => (order[a.status] || 5) - (order[b.status] || 5));
                    } else if (this.sortBy === 'duration') {
                        result.sort((a, b) => b.duration - a.duration);
                    }

                    return result;
                }
            }
        }

        // Initialize charts when DOM is ready
        document.addEventListener('DOMContentLoaded', function() {
            // Pass Rate Trend Chart
            const trendCtx = document.getElementById('trendChart');
            if (trendCtx) {
                new Chart(trendCtx.getContext('2d'), {
                    type: 'line',
                    data: {
                        labels: ["2026-01-11", "2026-01-11", "2026-01-10", "2026-01-10", "2026-01-11", "2026-01-11", "2026-01-10", "2026-01-11"],
                        datasets: [{
                            label: 'Pass Rate %',
                            data: [14.3, 14.3, 100.0, 50.0, 50.0, 16.7, 100.0, 14.3],
                            borderColor: 'rgb(34, 197, 94)',
                            backgroundColor: 'rgba(34, 197, 94, 0.1)',
                            borderWidth: 2,
                            fill: true,
                            tension: 0.4,
                            pointBackgroundColor: 'rgb(34, 197, 94)',
                            pointBorderColor: '#fff',
                            pointBorderWidth: 2,
                            pointRadius: 4
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        plugins: {
                            legend: { display: false }
                        },
                        scales: {
                            y: {
                                beginAtZero: true,
                                max: 100,
                                grid: { color: 'rgba(100, 116, 139, 0.2)' },
                                ticks: { color: '#94a3b8', callback: val => val + '%' }
                            },
                            x: {
                                grid: { color: 'rgba(100, 116, 139, 0.1)' },
                                ticks: { color: '#94a3b8' }
                            }
                        }
                    }
                });
            }

            // Status Distribution Doughnut Chart
            const statusCtx = document.getElementById('statusChart');
            if (statusCtx) {
                new Chart(statusCtx.getContext('2d'), {
                    type: 'doughnut',
                    data: {
                        labels: ['Passed', 'Failed', 'Timeout', 'Error', 'Partial'],
                        datasets: [{
                            data: [1, 6, 0, 0, 0],
                            backgroundColor: [
                                'rgba(34, 197, 94, 0.8)',
                                'rgba(239, 68, 68, 0.8)',
                                'rgba(168, 85, 247, 0.8)',
                                'rgba(107, 114, 128, 0.8)',
                                'rgba(234, 179, 8, 0.8)'
                            ],
                            borderColor: [
                                'rgb(34, 197, 94)',
                                'rgb(239, 68, 68)',
                                'rgb(168, 85, 247)',
                                'rgb(107, 114, 128)',
                                'rgb(234, 179, 8)'
                            ],
                            borderWidth: 2
                        }]
                    },
                    options: {
                        responsive: true,
                        maintainAspectRatio: false,
                        cutout: '65%',
                        plugins: {
                            legend: {
                                position: 'bottom',
                                labels: {
                                    color: '#94a3b8',
                                    padding: 15,
                                    usePointStyle: true,
                                    filter: function(item, data) {
                                        // Hide legend items with 0 value
                                        return data.datasets[0].data[item.index] > 0;
                                    }
                                }
                            }
                        }
                    }
                });
            }
        });
    </script>
</body>
</html>